{
  "hash": "670abc86877ae2fc7fa6e6c1139457fd",
  "result": {
    "markdown": "---\ntitle: \"FASS512 - Week 2\"\nauthor: \"Matthew Ivory\"\nformat: html\n---\n\n\n\n\n## Step 0: Installing tidyverse\n\nI mentioned tidyverse in the lecture, and now we will intall and load it, before using it (mainly for pipes!)\n\nAs a one-off (on a per machine basis) the first command only needs to be run when we first want a package. As noted before, there are thousands of functions available to R, having them all pre-packaged would break your computer and you don't need every single one.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"tidyverse\")\n```\n:::\n\n\nThere is little to know about this at this stage, as the function does a lot of the legwork for us. It looks on the CRAN (The Comprehensive R Archive Network) which contains the R approved packages. It downloads it so you can use all the functions contained in a spacific package. \n\nAs stated before, tidyverse is a collection of packages, and we will need to understand that later on, but for now: no need.\n\nNow to load the package so we can use the functions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.4     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n:::\n\n\nAs above, you will get a bunch of messages in the console, we can reasonably ignore these for now.\n\n::: {.callout-note}\n\nAs a general point, we would run `install.packages()` in the console, and place `library()` at the top of a script. The next section should make this a bit clearer as to the difference\n\n:::\n\n## Step 1: Scripts\n\nA script is essentially a sequence of commands that we want R to execute. As Winter (2019) points out, we can think of our R script as the recipe and the R console as the kitchen that cooks according to this recipe. Let’s try out the script editor and write our first script. Typing commands in the console is good for one off commands (maybe to check the `class()` or to `install.packages()`), but the script is better for keeping the steps in order.\n\nWhen working in R, try to work as much as possible in the script. This will be a summary of all of your analyses, which can then be shared with other researchers, together with your data. This way, others can reproduce your analyses.\n\nThus far, you have typed your command lines in the console. This was useful to illustrate the functioning of our R, but in most of your analyses you won’t type much in the console. Instead, we will use the script editor.\n\nThe script editor is the pane on the top left of your window. If you don’t see it, you need to open a new script first. For this, press Cmd+Shift+N (Mac) or Ctrl+Shift+N (Windows). Alternatively, in the menu, click File > New File > RScript.)\n\nIn the script editor (not the console), type the following command in line 1 press Return (Mac) / Enter (Windows).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2 + 3\n```\n:::\n\n\nAs you can see, nothing happened. There is no output in the Console pane; the cursor just moved to the next line in the script editor (line 2). This is because you did not execute the script.\n\nTo execute a command in the script editor, you need to place your cursor anywhere on the line you wish to execute and then click the Run icon in the Script editor pane. If you do this, then the following output will appear in your Console.\n\nYou can also run the current command line or selection in the script by pressing Cmd+Return (Mac) or Ctrl+Enter (Windows). This will also send your command from the script editor to the console. (I suggest using the shortcut, it’s much more efficient.)\n\nIn the script, you can have as many lines of code as you wish. For example, you can add the following three commands to your script.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscores <- c(145, 234, 653, 876, 456) \n\nmean(scores)\n\nsd(scores)\n```\n:::\n\n\nTo execute each one separately, just go to the line in question and click the Run icon or, even better, press the keyboard shortcut.\n\nYou can also run multiple commands in one go. For this, you either highlight several lines and then press the Run icon (or keyboard shortcut). Try it with the above three lines.\n\nTo execute all commands in the script, you click the Source icon (next to the Run icon) in the Script editor pane. Or just use the shortcut Cmd+Option+R (Mac) or Ctrl+Alt+R (Windows).\n\n### Multiline commands\n\nUsing the script editor is particularly useful when we write long and complex commands. The example  below illustrates this nicely.\n\nThis is a fairly long command, written in the console in one line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), age = c(23, 25, 46, 19), occupation = c('doctor', 'director', 'student', 'spy'))\n```\n:::\n\n\nbut in a multiline format:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), \n                 age = c(23, 25, 46, 19), \n                 occupation = c('doctor', 'director', 'student', 'spy'))\n```\n:::\n\n\n\nNote the indentations, this is done automatically by RStudio as it recognises what is grouped according to parentheses. \n\n### Comments\n\nAn important feature of R (and other programming languages) is the option to write comments in the code files. Comments are notes, written around the code, that are ignored when the script is executed. In R, anything followed by the `#` symbol on any line is treated as a comment. This means that a line starting with # is ignored when the code is being run. And if we place a # at any point in a line, anything after the hash tag is also ignored. The following code illustrates this.\n\nComments are really useful for writing explanatory notes to ourselves or others.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here is data frame with three variables.\n# The variables refer to the names, ages, and occupations of the participants.\ndf <- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), \n                 age = c(23, 25, 46, 19),\n                 occupation = c('doctor', 'director', 'student', 'spy'))\n```\n:::\n\n\nor\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2 + 3 #This is addition in R.\n```\n:::\n\n\n### Code sections\n\nTo make your script even clearer, you can use code sections. These divide up your script into sections as in the example below. To create a code section, go the line in the script editor where you would like to create the new section, then press Cmd+Shift+R (Mac) or Ctrl+Shift+R (Windows). Alternatively, in the Menu, select Code > Insert Section.\n\nThe lines with the many hypens create the sections\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create vectors ---------------------------------------------------\n\nscores_test1 <- c(1, 5, 6, 8, 10) # These are the scores on the pre-test.\nscores_test2 <- c(25, 23, 52, 63) # These are the scores on the post-test.\n\n# A few calculations -----------------------------------------------\n\nmean_test1 <- mean(scores_test1)\nmean_test2 <- mean(scores_test2)\n\nround(mean_test1 - mean_test2) # The difference between pre and post-tests.\n```\n:::\n\n\nOnce you have created a section, you can ask R to run only the code in a specific region. This is because R recognizes script sections as distinct regions of code.\n\nTo run the code in a specific section, first go to the section in question (e.g., the section called # A few calculations ------------) and then either press Cmd+Option+T (Mac) or Ctrl+Alt+T (Windows). You can also use the menu, Code > Run Region > Run Section. Have a go to see if this works out well.\n\n### Saving scripts\n\nFinally, you can also save your script. To do this, just click the Save icon in the Script editor pane or press Cmd+S (Mac) or Ctrl+S (Windows). The script can be named anything, but it is often recommended to use lowercase letters, numbers and underscores only. (That is, no spaces, hyphens, dots, etc.)\n\nThe script is saved in the .R format in your directory. If you later double click it, the file will open in RStudio by default, but you can also view and edit the file in Word and similar programs.\n\n## Step 2: A bit more on packages\n\nIt’s important to acknowledge the important work done by the developers who make R packages available for free and open source. When you use a package for your analyses (e.g., `tidyverse` or `lme4`), you should acknowledge their work by citing them in your output (dissertation, presentation, articles, etc.).\nYou can find the reference for each package via the `citation()` function, as in the examples below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncitation(\"tidyverse\")\n\ncitation(\"lme4\")\n```\n:::\n\n\nYou can also install packages by using the Packages tab in the Files, Plots, Packages, etc. pane. As you see in the figure below, the base package is already installed. You can install more packages by scrolling through the list (or using the search option to narrow down the choices) and then selecting the tick box to the left of the package. If you do this, you will see that the click will run the install.packages() command in the console.\n\nAs I mentioned above, run `install.packages()` in the console as a one-off command, you do not need to run this every time you want to use a package. Everytime we want to use a package in a given session, we need to tell R to load it up, which is why we put `library()` at the top of the script, so we can use the functions.\n\n## Step 3: Working directories and clean workspaces\n\nEvery R session has a working directory. This is essentially the directory or folder from which\nfiles are read and to which files are written.\n\nYou can find out your working directory by typing the following command. Your output will\nobviously look different from the one below, which refers to my machine\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"/Users/ivorym/Documents/PhD/Teaching/23_24/FASS512/Week2\"\n```\n:::\n:::\n\n\nYou can also use a command to list the content in the working directory. (Alternatively, you can see your direct by using the Files tab in the Files, Packages, Plot, etc. pane.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist.files()\n```\n:::\n\n\nI suggest you create a new working directory on your computer desktop and then use it for the entire course. Important files related to your R tasks (scripts, data, etc.) should later be downloaded to this folder.\n\nThe first step is for you to create a folder called FASS512 (or similar) in a sensible place on your computer. You can do this by going to the Files tab (in the Files, Packages, etc. pane) and clicking the \"Create a new folder\" icon. Place each weekly set of weekly files in their own weekly folders.\n\nOnce you have created the \"statistics\" folder on the desktop, go to the menu to set the default working directory to the new \"statistics\" folder. The easiest way is to go to the menu, RStudio > Preferences. This should call up the following window.\n\nIn the window, click the Browse button and set the default working directory to the \"statistics\" folder in the desktop.\n\n## Step 4: Loading data\n\nWhen we are dealing with data in our analyses, we usually begin by importing a data file. R allows\nyou to important data files in many different formats, but the most likely ones are .csv and .xlsx.\n\nI have uploaded several data files to our Moodle page. Please go to folder called \"Data sets to download for this session\" in the section for today’s session, then download the files in the folder and place them in your working directory (the statistics folder you just created). The files are from Winter (2019) and Fogarty (2019).\n\nLet’s try out loading data files. In the examples below, you will import three types of files: .csv, .txt, and .xlsx. Remember: You need to download the data files from our Moodle page and place them in our working directory first. Otherwise, you cannot import the files from our directory into R.\n\n### CSV\n\nWe can use the `read_csv()` function from dplyr (part of the tidyverse) to load data that is in .csv format. The command below will load the data set ('nettle_1999_climate.csv') and create a new label for this data set (languages). There exists a `read.csv()` function in base, but it is slower and not as 'smart' as `read_csv()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlanguages <- read.csv('nettle_1999_climate.csv')\n```\n:::\n\n\nAlternatively, you can load data files by clicking File > Import Dataset > From Text (readr). In the dialogue window, then click browse and select the file nettle_1999_climate.csv. You can change the name of the data set in the text box at the bottom left, below Import Options, where it says Name.\n\n::: {.callout-note}\n\nI am giving you these alternative GUI-based methods for carrying out the same steps as what is written in the script. I offer these to highlight how things can be done in many ways, but preferably you will use the script for pretty much everything. This creates a record of the commands needed to reproduce your analysis, which is better for future researchers (which includes you in a week's time)\n\n:::\n\n### TXT\n\nThe data file you just imported is in the .csv format. You can important data from files in other formats, too. If the data is in .txt format, you can simply use the following command.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntext_file <- read_table('example_file.txt', sep = \"\\t\", header = TRUE) #(Note: Ignore the warning message in the console.)\n```\n:::\n\n\nThe command creates a new data set called text_file. The read_table() function requires you to specify a separator (the argument sep). A separator is whatever divides your columns in your table. If your data is tab-delimited, then you include sep = '\\t' in your command, as above. If you are using commas, then you need to include sep = ',' and so forth. The header = TRUE argument indicates that your data set has a head (usually the column names).\n\n### xlsx\n\nIf the data is an Excel spreadsheet (e.g., .xlsx format), you can proceed as follows. Ideally it shouldn't be, as csv are a universal file format that can be read across many machines. As a general rule, it is important to use these universal filetypes (csv, txt, pdf, html...) for better reproducibility and data management (Towse et al., 2021)^[Towse, A. S., Ellis, D. A., & Towse, J. (2021). Making data meaningful: Guidelines for good quality open data. The Journal of Social Psychology, 161(4), 395–402. https://doi.org/10.1080/00224545.2021.1938811]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl) #you may need to run install.packages(\"readxl\") first\n\nspreadsheet_exl <- read_excel('simd.xlsx', sheet = 'simd')\n```\n:::\n\n\nFirst, you need to install the readxl package. Then, you create a new data set called spreadsheet_exl by using the read_excel() function.\n\nNote: Since spreadsheets have multiple sheets, you need to specify the name of the sheet you would like to import by using the sheet argument. In our case, the sheet is called simd, hence sheet = ‘simd’.\n\nRStudio can handle many other file extensions to import datasets. You can find out information on how to import other file types by using the R help function (or by searching on Google).\n\n## Step 5: Examining datasets\n\nIf you have followed the steps above, you will have imported three data sets, languages, spreadsheet_exl, and text_file. You can now start exploring the data. We will focus on languages as an example.\n\nEvery time you import data, it’s good to check the content, just to make sure you imported the correct file.\n\nThe easiest way to do this is by using the `View()` function. This allows you to inspect the data set in the script editor. Note: The function requires a capital V. If you have tidyverse loaded, which we do, then there is a `view()` function as well. These are functionally equivalent. Use whichever, but `View()` will always work\n\nIf you run the command below, you will see that this shows the data (a table) in a tab of the script editor. It will also be displayed in the console.\n\n::: {.callout-note}\n\nRemember what I have said previously about some content being better off in the console rather than the script? This is another example of what to put in the console instead (like `class()` or `install.packages()`. \n\n**Why?** Great question, because it's a one-off command that we don't need in our script. It's a sanity check, like `class()`, and it doesn't add anything of value to the script. The script should be the minimum series of commands that are required to go from one stage to another. Taking a visual look at a dataframe is superfluous to the actual analysis\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nView(spreadsheet_exl) \nView(languages)\n```\n:::\n\n\nYou can also inspect your data by visiting the Environment tab in the Environment, History, Connections, etc. pane. As you can see in the figure below, this will tell you thatlanguageshas 74 observations (rows) and five variables (columns).\n\nIf you would like to examine variables, you can start by using the `str()` function (str for structure), as in the example below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(languages)\n```\n:::\n\n\nAs you can see above, the `str()` function will tell you many useful things about your dataset. For example, it will reveal the number of observations (rows, 74) and variables (columns, 5), and then list the variables (Country, Population, Area, MGS, Langs). For each variable, it will also indicate the variable type (chr = character strings, num = numeric, intd = integer). The `str()` function will also display the first observations of each variable (Algeria, Angola, Australia, Bangladesh, etc.).\n\nYou can also check the names of variables separately by using the `names()` function, or check the variable type by checking the `class()` function, but it’s easier to just use the `str()` function as in the example above.\n\nIf you prefer, you can restrict your inspection of to the first or final rows of the data set. You can do this by using the `head()` and `tail()` function. This is helpful if your tables has lots of rows. It complements `str()` as it shows you a sample of the actual data, not just the structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(languages) #default is six rows to display\ntail(languages, n = 5) #show last five rows\n```\n:::\n\n\nHow could you show the first 10 rows?\n\n\n::: {.cell}\n\n:::\n\n\nThere is also a very helpful function called `summary()`. As you can see in the example below,\nthis function will provide you with summary information for each of your variables.\n\nFor numeric/integer variables such as Populations, Area, MGS, and Langs, this command will calculate the minimum and maximum values, quartiles, median and mean. (We will discuss summary statistics in more detail later.)\n\nFor character variables, as in Country, the command will simply provide you with the number of observations (length) for this variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(languages)\n```\n:::\n\n\nIn large datasets, you might want to examine only a specific variable. You can do this by using the `$` as an index. For example, if you would just like to examine the variable Population in the languages dataset, you could proceed as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(languages)\n\nstr(languages$Population)\n\nclass(languages$Population)\n\nhead(languages$Population)\n\ntail(languages$Population)\n\nsummary(languages$Population)\n```\n:::\n\n\nWhich of the above six commands are best placed in the script or console?\n\n::: { .callout-note collapse='true'}\n\nUltimately, there is no right or wrong answer. Personally,\n\n`str()` belongs in the console because it should just be a quick check that it is the expected shape. It could go in the script if it was part of a more formal test. A sanity check is something that makes you go \"oh, I should just make sure\", whereas a test is more in line with thoughts of \"if it isn't have an identical shape to dataframe2, none of this works\" - a nuanced difference that we may perhaps explore in later sessions.\n\n`class()` goes in the console - it is very much a sanity check. If it transpires the class isn't what you wanted, we can coerce them into different classes, which we would include as a step in the script, but we don't need to run the check everytime in the script if we are just going to coerce it anyway...\n\n`head()` and `tails()` depends. If you're just having a little look, then console. If it is something you are then using in the analysis, the script. Most likely the console though. If you can  exit RStudio and reopen the script and it runs without errors, then it's fine to leave in the console. If it fails, maybe you need things in the script?\n\n`summary()` is one I usually keep in the script - particularly if I am reporting the summary of statistics (see a later session) because it is meaningful content that I need.\n\n:::\n\n## Step 6: Closing your R session\n\nThe last step is to close your R session. When you quit RStudio, a prompt will ask whether you want to save the content of your workspace. It is better to NOT save the workspace. When you start RStudio again, you will have a clean workspace. You then just re-run your scripts.\n\nIf you have written your scripts well, upon re-open, you should be able to produce the exact same steps without error and without odd additional windows opening (because we put `View()` in a script...).\n\nSo, I would save R scripts (especially if these are very long and are relevant to your analyses), but I would not the workspace contents.\n\n## Take home task\n\nTo complete this homework task, you will need to download the language_exams data file from our Moodle page into your working directory.\n\nIn the file, you will find the (fictional) scores and ages of 475 students who took an intermediate Portuguese language course at university. Students were tested three times: first in September to check their Portuguese proficiency at the beginning of the course, then again in January as part of their mid-term examination, and finally in June as part of their final examination. On each occasion, students had to complete three subtests to respectively assess their Portuguese vocabulary, grammar and pronunciation. The scores for exams 1, 2 and 3 are composite scores, i.e. each combines the results of the three subtests.\n\nYour task is to run a basic analysis of the exam data using an R script. \n\nIn your script, please include all the steps, including the command that loaded the data. \n\nPlease also include sections to make your script very clear, as well as comments.\n\n\n::: {.cell}\n\n:::\n\n\n1. How many observations and columns does the datafile contain?\n\n\n::: {.cell}\n\n:::\n\n\n\n2. Run commands to display the first and the last five lines of the table.\n\n\n::: {.cell}\n\n:::\n\n\n3. What is the average age of participants? Report this as a whole number\n\n\n::: {.cell}\n\n:::\n\n\n\n4. What type of variable is student_id?\n\n\n\n::: {.cell}\n\n:::\n\n\n5. What is the rounded mean score on exam 3 to 2 decimal places?\n\n::: { .callout-tip collapse='true'}\n\nNot sure how? Type `?round()` into the console and read the help page. Specifically look under the Arguments section and the examples (the second to last is the best one)\n\n:::\n\n\n::: {.cell}\n\n:::\n\n\n\n6. What is the difference between the mean scores on exams1 and 2?\n\n\n::: {.cell}\n\n:::\n\n\nPlease save the script to discuss at the next session.",
    "supporting": [
      "Worksheet_wk2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}