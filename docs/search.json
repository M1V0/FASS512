[
  {
    "objectID": "Week5/Live_code_resources/example.html",
    "href": "Week5/Live_code_resources/example.html",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.4     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# anything else goes here\n\n\n\n\nRead in key datafiles\n\ndata_raw &lt;- read_csv(\"swiss_crime_2022.csv\")\n\nRows: 19 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): crime, crime_type\ndbl (17): male, female, age18_19, age20_24, age25_29, age30_34, age35_39, ag...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCheck out the data\n\nhead(data_raw)\n\n# A tibble: 6 × 19\n  crime     crime_type  male female age18_19 age20_24 age25_29 age30_34 age35_39\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Intentio… Severe vi…    82     20        0       16       17       15       13\n2 Grievous… Severe vi…   204      6        9       53       42       32       28\n3 Female g… Severe vi…     0      0        0        0        0        0        0\n4 Hostage … Severe vi…     0      0        0        0        0        0        0\n5 Rape      Severe vi…    71      0        0        7       13       11       12\n6 Violent … Severe vi…     6      0        0        3        1        0        1\n# ℹ 10 more variables: age40_44 &lt;dbl&gt;, age45_49 &lt;dbl&gt;, age50_59 &lt;dbl&gt;,\n#   age60_69 &lt;dbl&gt;, age70plus &lt;dbl&gt;, nat_swiss &lt;dbl&gt;, nat_foreign &lt;dbl&gt;,\n#   foreign_permit &lt;dbl&gt;, foreign_other &lt;dbl&gt;, foreign_unknown &lt;dbl&gt;\n\ncolnames(data_raw)\n\n [1] \"crime\"           \"crime_type\"      \"male\"            \"female\"         \n [5] \"age18_19\"        \"age20_24\"        \"age25_29\"        \"age30_34\"       \n [9] \"age35_39\"        \"age40_44\"        \"age45_49\"        \"age50_59\"       \n[13] \"age60_69\"        \"age70plus\"       \"nat_swiss\"       \"nat_foreign\"    \n[17] \"foreign_permit\"  \"foreign_other\"   \"foreign_unknown\"\n\n\n\n\n\nWhat do we need to keep if we are wanting to visualise the differences in type of crime convicted in the Swiss Adult population?\n\ndata &lt;- data_raw |&gt; \n  select(crime, crime_type, contains(\"age\"))\n\n\n\n\n\ndata_tidy &lt;- data |&gt;\n  group_by(crime_type) |&gt; \n  mutate(age18_19 = sum(age18_19),\n         age20_24 = sum(age20_24),\n         age25_29 = sum(age25_29),\n         age30_34 = sum(age30_34),\n         age35_39 = sum(age35_39),\n         age40_44 = sum(age40_44),\n         age45_49 = sum(age45_49),\n         age50_59 = sum(age50_59),\n         age60_69 = sum(age60_69),\n         age70plus = sum(age70plus)\n         ) |&gt; \n  select(-crime) |&gt; \n  distinct()\n\n# factor the group data\ndata_tidy &lt;- data_tidy |&gt; \n  mutate(crime_type = factor(crime_type, levels = c(\"Moderate violence (threat of violence)\", \n                                                    \"Moderate violence (exercise of violence evt. threat of violence)\",\n                                                    \"Severe violence (exercise of violence)\")))\n\n\n\n\n\ndata_tidy_long &lt;- data_tidy |&gt; \n  pivot_longer(cols = age18_19:age70plus, \n               names_to = \"age_group\", \n               values_to = \"convictions\")\n\n\n\n\n\ndata_tidy_long |&gt; \n  filter(crime_type == \"Severe violence (exercise of violence)\") |&gt; \n  ggplot(aes(age_group, convictions)) +\n  geom_col()\n\n\n\n#try colour first, and then go to fill\ndata_tidy_long |&gt; \n  ggplot(aes(age_group, convictions, fill = crime_type)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nWhat can we see in the dataset (as well as the x-axis) that indicates this is a misleadingly organised dataset?\nThe age ranges are not consistent - so the above plot is misleading, just like the examples in week 4.\n\ndata_tidy_ages &lt;- data_tidy |&gt; mutate(\n  age20_29 = sum(age20_24, age25_29),\n  age30_39 = sum(age30_34, age35_39),\n  age40_49 = sum(age40_44, age45_49),\n  .before = age50_59\n) |&gt; \n  select(-c(age20_24, age25_29, age30_34, age35_39, age40_44, age45_49))\n\ndata_tidy_ages_long &lt;- data_tidy_ages |&gt; \n  pivot_longer(cols = age18_19:age70plus, \n               names_to = \"age_group\", \n               values_to = \"convictions\") \n\ndata_tidy_ages_long |&gt; \n  ggplot(aes(age_group, convictions, fill = crime_type)) +\n  geom_col(position = \"dodge\")\n\n\n\n\n\ndata_tidy_ages_long_sum &lt;- data_tidy_ages_long |&gt; \n  group_by(age_group) |&gt; \n  summarise(total = sum(convictions))\n\ndata_tidy_ages_long_percent &lt;- data_tidy_ages_long |&gt; \n  left_join(data_tidy_ages_long_sum, by = join_by(age_group)) |&gt; \n  mutate(percentage = convictions/total*100)\n\n##sanity check\n#data_tidy_ages_long_percent |&gt; \n#  filter(age_group == \"age18_19\") |&gt; \n#  pull(percentage) |&gt; sum()\n\n\ndata_tidy_ages_long_percent |&gt; \n  ggplot(aes(age_group, percentage, colour = crime_type)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nWhat inferences can we draw from this? What else could we explore?"
  },
  {
    "objectID": "Week5/Live_code_resources/example.html#set-up-environment",
    "href": "Week5/Live_code_resources/example.html#set-up-environment",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.4     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n# anything else goes here"
  },
  {
    "objectID": "Week5/Live_code_resources/example.html#import-data",
    "href": "Week5/Live_code_resources/example.html#import-data",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "Read in key datafiles\n\ndata_raw &lt;- read_csv(\"swiss_crime_2022.csv\")\n\nRows: 19 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): crime, crime_type\ndbl (17): male, female, age18_19, age20_24, age25_29, age30_34, age35_39, ag...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCheck out the data\n\nhead(data_raw)\n\n# A tibble: 6 × 19\n  crime     crime_type  male female age18_19 age20_24 age25_29 age30_34 age35_39\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Intentio… Severe vi…    82     20        0       16       17       15       13\n2 Grievous… Severe vi…   204      6        9       53       42       32       28\n3 Female g… Severe vi…     0      0        0        0        0        0        0\n4 Hostage … Severe vi…     0      0        0        0        0        0        0\n5 Rape      Severe vi…    71      0        0        7       13       11       12\n6 Violent … Severe vi…     6      0        0        3        1        0        1\n# ℹ 10 more variables: age40_44 &lt;dbl&gt;, age45_49 &lt;dbl&gt;, age50_59 &lt;dbl&gt;,\n#   age60_69 &lt;dbl&gt;, age70plus &lt;dbl&gt;, nat_swiss &lt;dbl&gt;, nat_foreign &lt;dbl&gt;,\n#   foreign_permit &lt;dbl&gt;, foreign_other &lt;dbl&gt;, foreign_unknown &lt;dbl&gt;\n\ncolnames(data_raw)\n\n [1] \"crime\"           \"crime_type\"      \"male\"            \"female\"         \n [5] \"age18_19\"        \"age20_24\"        \"age25_29\"        \"age30_34\"       \n [9] \"age35_39\"        \"age40_44\"        \"age45_49\"        \"age50_59\"       \n[13] \"age60_69\"        \"age70plus\"       \"nat_swiss\"       \"nat_foreign\"    \n[17] \"foreign_permit\"  \"foreign_other\"   \"foreign_unknown\""
  },
  {
    "objectID": "Week5/Live_code_resources/example.html#tidying-data-to-minimum-required",
    "href": "Week5/Live_code_resources/example.html#tidying-data-to-minimum-required",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "What do we need to keep if we are wanting to visualise the differences in type of crime convicted in the Swiss Adult population?\n\ndata &lt;- data_raw |&gt; \n  select(crime, crime_type, contains(\"age\"))"
  },
  {
    "objectID": "Week5/Live_code_resources/example.html#how-do-i-condense-down-all-the-specific-crimes-into-one-value",
    "href": "Week5/Live_code_resources/example.html#how-do-i-condense-down-all-the-specific-crimes-into-one-value",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "data_tidy &lt;- data |&gt;\n  group_by(crime_type) |&gt; \n  mutate(age18_19 = sum(age18_19),\n         age20_24 = sum(age20_24),\n         age25_29 = sum(age25_29),\n         age30_34 = sum(age30_34),\n         age35_39 = sum(age35_39),\n         age40_44 = sum(age40_44),\n         age45_49 = sum(age45_49),\n         age50_59 = sum(age50_59),\n         age60_69 = sum(age60_69),\n         age70plus = sum(age70plus)\n         ) |&gt; \n  select(-crime) |&gt; \n  distinct()\n\n# factor the group data\ndata_tidy &lt;- data_tidy |&gt; \n  mutate(crime_type = factor(crime_type, levels = c(\"Moderate violence (threat of violence)\", \n                                                    \"Moderate violence (exercise of violence evt. threat of violence)\",\n                                                    \"Severe violence (exercise of violence)\")))"
  },
  {
    "objectID": "Week5/Live_code_resources/example.html#pivot-so-its-ready-for-plotting",
    "href": "Week5/Live_code_resources/example.html#pivot-so-its-ready-for-plotting",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "data_tidy_long &lt;- data_tidy |&gt; \n  pivot_longer(cols = age18_19:age70plus, \n               names_to = \"age_group\", \n               values_to = \"convictions\")"
  },
  {
    "objectID": "Week5/Live_code_resources/example.html#plotting",
    "href": "Week5/Live_code_resources/example.html#plotting",
    "title": "Data Wrangling Walkthrough",
    "section": "",
    "text": "data_tidy_long |&gt; \n  filter(crime_type == \"Severe violence (exercise of violence)\") |&gt; \n  ggplot(aes(age_group, convictions)) +\n  geom_col()\n\n\n\n#try colour first, and then go to fill\ndata_tidy_long |&gt; \n  ggplot(aes(age_group, convictions, fill = crime_type)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nWhat can we see in the dataset (as well as the x-axis) that indicates this is a misleadingly organised dataset?\nThe age ranges are not consistent - so the above plot is misleading, just like the examples in week 4.\n\ndata_tidy_ages &lt;- data_tidy |&gt; mutate(\n  age20_29 = sum(age20_24, age25_29),\n  age30_39 = sum(age30_34, age35_39),\n  age40_49 = sum(age40_44, age45_49),\n  .before = age50_59\n) |&gt; \n  select(-c(age20_24, age25_29, age30_34, age35_39, age40_44, age45_49))\n\ndata_tidy_ages_long &lt;- data_tidy_ages |&gt; \n  pivot_longer(cols = age18_19:age70plus, \n               names_to = \"age_group\", \n               values_to = \"convictions\") \n\ndata_tidy_ages_long |&gt; \n  ggplot(aes(age_group, convictions, fill = crime_type)) +\n  geom_col(position = \"dodge\")\n\n\n\n\n\ndata_tidy_ages_long_sum &lt;- data_tidy_ages_long |&gt; \n  group_by(age_group) |&gt; \n  summarise(total = sum(convictions))\n\ndata_tidy_ages_long_percent &lt;- data_tidy_ages_long |&gt; \n  left_join(data_tidy_ages_long_sum, by = join_by(age_group)) |&gt; \n  mutate(percentage = convictions/total*100)\n\n##sanity check\n#data_tidy_ages_long_percent |&gt; \n#  filter(age_group == \"age18_19\") |&gt; \n#  pull(percentage) |&gt; sum()\n\n\ndata_tidy_ages_long_percent |&gt; \n  ggplot(aes(age_group, percentage, colour = crime_type)) +\n  geom_col(position = \"dodge\")\n\n\n\n\nWhat inferences can we draw from this? What else could we explore?"
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html",
    "href": "Worksheets/Worksheet_wk3.html",
    "title": "3. Exploratory Data Analysis",
    "section": "",
    "text": "Three important things to remember:"
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html#step-0-preparing-your-environment",
    "href": "Worksheets/Worksheet_wk3.html#step-0-preparing-your-environment",
    "title": "3. Exploratory Data Analysis",
    "section": "Step 0: Preparing your Environment",
    "text": "Step 0: Preparing your Environment\nFirt things first, open up a new R script and load in the Tidyverse library\n\n\n\n\n\n\nNeed a reminder?\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\n\nIn addition, please download the following data files from Moodle (see folder for session 3) and place them in your working directory.\n\nnettle_1999_climate.csv\nlanguage_exams_new.csv\nscores.csv"
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html#step-1-tibbles",
    "href": "Worksheets/Worksheet_wk3.html#step-1-tibbles",
    "title": "3. Exploratory Data Analysis",
    "section": "Step 1: Tibbles?",
    "text": "Step 1: Tibbles?\nIn the last session, you have learned how to install the tidyverse package (Wickham, 2017).\ntidyverse is a collection of packages that great facilitates data handling in R. In our session on data visualization, you will encounter the ggplot2 package (Wickham, 2016), which is part of tidyverse. Today, we will use functions from other important packages of the tidyverse, namely tibble (Müller & Wickham, 2018), readr (Wickham et al., 2022), and dplyr (Wickham et al., 2018). These are all automatically installed when you install the tidyverse.\nWe have actually used tibbles last week. When we use the function read_csv(), this reads dataframes and gives them a class of tibble as well as dataframe. We can interpret this as meaning we can apply functions or operations that can apply to both classes.\nTibbles are like the data frames but better. For example, they load much faster, which is important when you are dealing with lots of data.\nFirst, let us load in a tibble/dataframe called languages. The data set comes from Winter’s (2019) textbook.\n\nlanguages &lt;- read_csv('nettle_1999_climate.csv')\n\nclass(languages)\n\n\nWhat classes are associated with the object languages? Which one means it has been read in as a tibble?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n“tbl” is short for tibble!\n\n\n\nRealistically, in future steps/worksheets/discussions, provided we are all on the same page and using read_csv() not read.csv(), then the terms tibble and dataframe are interchangeable.\nFor completeness sake, and so we can see why working with tibbles is easier, let us read the data again using read.csv(), have a look and compare it against the stored langages object.\nFor this, let us just read the csv without saving it to an object, you may recall that in week 1, we played about getting R to output various things, we told it to print 2 + 2 and it did just that. It gave us the number 4 in the output. And notice that when we ran languages &lt;- read_csv('nettle_1999_climate.csv') above, we did not get any output. This is because R did what we asked, which was to assign the values of the file to the object called “languages”. Got it? Cool, we can get rid of the left hand side of the assignment operator and just have R read (and print) the values of a file to us. In practice, this is not a useful exercise, but as an educational step, it’s convenient.\nLet us run the following command again to have it stored in the environment properly, notice the function is read_csv.\n\nlanguages &lt;- read_csv('nettle_1999_climate.csv')\n\nAnd now:\n\nlanguages\n\nWhat’s the difference? As you can see above, the tibble has information about the number of observations (74) and variables (5), the names of the variables: Country, Population, Area, MGS (mean growing season, measured by number of months when crops grow), Langs, and the variable types (character: chr, doubles: dbl, which is a type of numeric vector, and integer: int, also a numeric vector). In addition, the command will display the first ten observations of the variables, lines 1 to 10."
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html#step-2-data-wrangling",
    "href": "Worksheets/Worksheet_wk3.html#step-2-data-wrangling",
    "title": "3. Exploratory Data Analysis",
    "section": "Step 2: Data wrangling",
    "text": "Step 2: Data wrangling\nWe will now use tidyverse functions for data wrangling. As discussed in our last session, data wrangling is also referred to as data pre-processing or data cleaning. It simply means preparing your raw data (e.g., the data files from experimental software) for statistical analyses. This entails, for example, dealing with missing values, relabeling variables, changing the variable types, etc.\nIn this part of the handout, we will look at a few tidyverse function that you can use for data wrangling. For more information, I recommend Chapter 3 of Andrews (2021), which provides a comprehensive introduction to data wrangling using tidyverse.\nLet’s look at five useful functions for data wrangling with tibbles: filter, select, rename, mutate, and arrange.\n\nFilter\nThe filter() function can be used, unsurprisingly, to filter rows in your tibble. The filter() function takes the input tibble as its first argument. The second argument is then a logical statement that you can use to filter the data as you please.\n\n\n\n\n\n\nNote\n\n\n\nWe are using pipes, as introduced last week. So here’s some more practice with them coming up. filter() takes the input as the first argument, which means we can pipe the tibble into the filter function.\n\n\nIn the following example, we are reducing the languages tibble to only those rows with countries that have more than 500 languages.\n\nlanguages |&gt; #pipe object languages\n  filter(Langs &gt; 500) # filter rows where variable (column) Langs is greater than 500\n\nOr if you are interested in the data from a specific country (say, Angola), you could simply run the following command. This will only display the rows for Angola.\n\nlanguages |&gt; \n  filter(Country == \"Angola\")\n\nWe can even start to get a little bit more adventurous and filter on more than one argument. What about finding countries with more than 500 languages and Population greater than 4?\n\n\n\n\n\n\nWarning\n\n\n\nWait! Before running the next line, think about what we are trying to find, look at the previous code we have run in this section, and decide what the expected output should be.\nHow many rows should be returned? What countries are they going to be?\nThis kind of mental engagement is critical for your own development - we should also have some kind of mental representation of the information we are getting. It won’t always be super specific, but even just being aware of the shape of a tibble, or general description of the information is important - it means we can check for issues quicker.\n\n\n\nlanguages |&gt; \n  filter(Langs &gt; 500, Population &gt; 4)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIndonesia. Look at the output for the code below and notice that it is the same code except we filtered it one step further.\n\nlanguages |&gt; #pipe object languages\n  filter(Langs &gt; 500)\n\n\n\n\n\n\nSelect\nIn contrast, you can use the select() function to select specific columns. To do this, simply add the columns you wish to select, separated by commas, as arguments in the function.\n\nlanguages |&gt; \n  select(Langs, Country)\n\nAs you might notice, the select() function can also be used to change the sequence of the columns. (In the original tibble, Country came first, followed by Langs.)\nOn the other hand, if you wish to exclude a column, you can do this by using a minus sign in front of the column in question. The command below will select the four columns Country, Population, Area and MGS, but excluded Langs as requested.\n\nlanguages |&gt; \n  select(-Langs)\n\nYou can also select consecutive columns using :. Let’s take the columns from and including Population, to and including MGS.\n\nlanguages |&gt; \n  select(Population:MGS)\n\nIt is worth noting that getting filter() and select() mixed up is pretty common. I personally do it a lot. A vaguely helpful way to remember is that filteR is for Rows and select is not. Or seleCt is for Columns? Or jsut do what I do, and get it wrong 50% of the time, and then just change it when you get the error!\n\n\nRename\nA third useful function is called rename(). This function can be used to change the name of columns. To do this, you first write the new column (here, Population) followed by an equal sign (=) and the old column name (Pop).\nrename() is useful for when we have really messy taking that comes from an online survey, government statistics, or even a PsychoPy study. We could tidy data in excel before reading into R, but that defeats the point of using R and being a successful data scientist (which is you!) - it reduces the reproduciblity and transparency of your analyses from start to finish.\n\nlanguages &lt;- languages |&gt; #here we are manipulating in place the object languages. We are overwriting the existing object\n  rename(Population = Pop)\n\n\n\n\n\n\n\nWarning\n\n\n\nWoah, woah, woah - what did I just do to the object languages? I assigned the object languages to languages? Not quite. I assigned the entire of the right hand side of the assignment operator to overwrite the same object. So I renamed a column and saved it to the existing object. Analogy: like saving over the top of a word document. Or, to see a basic example in action, make sure you have the environment pane selected in the top right and run the next command, see what shows, and then run the second and see what changed. It should be pretty clear what will happen, but just extrapolate that to tibbles and renaming (we could have also reassigned any of the previous actions we took using filter or select).\n\nx &lt;- 32\n\nx &lt;- 64\n\n\n\n\n\nMutate\nThe mutate() function can be used to change the content of a tibble. For example, you can add an additional column, which in the example below will be the Langs column divided by 100.\n\nlanguages &lt;- languages |&gt; \n  mutate(Langs100 = Langs/100)\n\nhead(languages) # show me the top 6 rows\n\nWe can also use mutate() to change specific values to something else. Look at this example dataset:\n\n#let's create a 2x3 tibble with two participants, who both took part in a study where we tested their working memory, and one was in the control group (1 for yes, 0 for no) and the other was not\ntest_data &lt;- tibble(name = c(\"Jenny\", \"Jonny\"), \n                    score = c(45, 23),\n                    control_group = c(1,0))\n\ntest_data\n\nLooking at the variable control_group it may not be clear to everyone what 1 or 0 means, so let’s use mutate() to update this variable\n\ntest_data_update &lt;- test_data |&gt; \n  mutate(control_group = str_replace(control_group, \"1\",  \"yes\"),\n         control_group = str_replace(control_group, \"0\",  \"no\"))\n\nLooks pretty complicated! Let’s break it down:\n\nThe first line tells us what the new object will be, and what data we are starting with, we are then piping that into:\nmutate() which then tells us we want to update the control_group variable. and we want to apply a new function called str_replace which replaces strings. We are saying “look in the variable control group, and if we find a ‘1’, replace it with the string ‘yes’. We end the second line with a comma telling R we are doing something more\nline three then repeats line two (still inside mutate if you follow the parentheses), and looks for a ‘0’ and replaces it with ‘no’. And we finish there.\n\nCheck out both obhjects, what’s changed?\n\ntest_data\n\ntest_data_update\n\nThe arguments in str_replace() want three things: the column it is checking, the strong it is looking for, and the string to replace it with. What if we wanted 1 to equal “control” and 0 to equal “experiment” instead? Try it out.\nWe will explore mutate() more in later weeks, but know that it is a very useful and powerful tool. It will be a common tool in your data science belt. It can be used in conjunction with other functions to do some really cool things. As a quick teaser, what if we wanted to know the population density per area unit?\n\nlanguages &lt;- languages |&gt; \n  mutate(density = Pop/Area) #We divide the total population by the area\n\nIf you took the time to calculate each row, you will see that for every row mutate() has taken the specific value of Pop and divided it by Area. Neat, that will save us a lot of time! Just know that we can make these even more complex…\n\n\nArrange\nFinally, the arrange() function can be used to order a tibble in ascending or descending order. In the example below, we are use this function to first look at the countries with the smallest number of languages (Cuba, Madagascar, etc.), followed by the countries with the largest numbers of languages (Papua New Guinea, Indonesia, Nigeria, etc.).\n\nlanguages |&gt; \n  arrange(Langs)\n\nor in descending order?\n\nlanguages |&gt; \n  arrange(desc(Langs))\n\n#which is functionally equivalent to:\n#\n#languages |&gt; \n# arrange(-Langs)\n\nBefore we move on, let’s clean up our environment and we are wanting to start with a fresh one for the rest of the worksheet.\nWe can use the function rm() to remove items from the environment pane. We should have two items, x and languages.\n\nrm(x)\nrm(languages)"
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html#step-3-exploratory-data-analysis",
    "href": "Worksheets/Worksheet_wk3.html#step-3-exploratory-data-analysis",
    "title": "3. Exploratory Data Analysis",
    "section": "Step 3: Exploratory Data Analysis",
    "text": "Step 3: Exploratory Data Analysis\nWe are now ready for some exploratory data analysis in R. First, let’s load the three data files as tibbles. To load the data sets as tibbles, we use the read_csv() function\nOnce you have loaded the data sets and created the new tibbles, it’s good to inspect the data to make sure all was imported properly. This is important before you do any analyses. Remember: “Garbage in, garbage out.”\nYou can use the View(), head(), and str() functions. Personally I suggest using head() to get a first idea.\nWe are now ready to calculate a few summary statistics! We did some of this in prior worksheets, but we will see some more here.\n\nMean\nTo calculate the arithmetic mean, you can use the mean() function.\n\nmean(test_scores$scores)\n\nIn the case of language_exams_new, we have three exams for which we might want to know the mean.\n\nmean(language_exams_new$exam_1)\n\nmean(language_exams_new$exam_2)\n\nmean(language_exams_new$exam_3)\n\nBut rather than calculating the mean for each column separately (exam_1 to exam_3), we can use the colMeans() function to calculate the mean for all columns.\n\ncolMeans(language_exams_new)\n\nNote that for student_id the output is essentially meaningless; it might be worth to filter out this variable (well, unselect the column. We could do this using two pipes:\n\nlanguage_exams_new |&gt; # take the object language_exams_new\n  select(-student_id) |&gt; # deselect the column student_id\n  colMeans() # apply the function colMeans()\n\nIf the above looks really complicated, it isn’t - don’t worry! Let us break it down. Look at the first two lines of code: we take the object language_exams_new and pipe it into the select function and remove the column student_id. We’ve done this before, this isn’t new. We are then seeing another pipe! This means that everything on the LHS of that pipe is shifted into the first spot of the RHS, so we are taken the object minus student_id and applying col_means(). That wasn’t so bad, it’s quite clear when we think about it programmatically.\nConsider that we can take this same approach and keep adding pipes for ever and ever, always doing the same thing: evaluate the first line and the bit between two pipes, then all of the LHS goes through the next pipe into the next function, and then so on, ever building in its pipeline, creating something complex at the end. That’s enough of this for now, we can get more practice later on, but it will help you to structure and read complicated code and make you into the great data scientist that you are.\n\n\nTrimmed Mean\nThe trimmed mean is useful when we want to exclude extreme values. Remember though that any data exclusion needs to be justified and it needs to be described in your report. There is a significant degree of trust that you report everything that you carried out in your analysis transparently.\nCompare the two outputs, with and without the extreme values. The trim argument here deletes the bottom and top 10% of scores.\n\nmean(test_scores$scores)\n\n\nmean(test_scores$scores, trim = 0.1)\n\n\n\nMedian\nThe median is calculated by using the following command.\n\nmedian(test_scores$scores)\n\nmedian (language_exams_new$exam_1)\n\n\n\nStandard Deviation\n\nsd(test_scores$scores)\n\nsd(language_exams_new$exam_1)\n\n\n\nRange\nThe range can provide useful information about our sample data. For example, let’s calculate the age range of participants in language_exams_new.\nThe range() function does not give you the actual range. It only provides the minimum and maximum values.\n\nrange(language_exams_new$age)\n\nTo calculate the range, we can ask R to give us the different between the two values reported by range\n\nrange(language_exams_new$age) |&gt; \n  diff()\n\ndiff() is a new function, and one we probably won’t use too much more, so it doesn’t deserve much space, diff is short for difference, so it calculates the difference between two values. That’s all really, but look how we take one output that wasn’t useful by itself and applied a new function to get something useful!\n\n\n\n\n\n\nNote\n\n\n\nIf you want to know a (not-so) fun fact, before writing this worksheet, I didn’t even know that diff() existed. I guessed it would (which is based off experience, so not helpful for you to know), but I then checked it did what I thought it did by running ?diff (in the console, NOT script) and it confirmed my suspicions. I could also have just googled “R difference between two values” and read the top two results.\n\n\n\n\nQuantiles\nQuantiles can easily be displayed by means of the quantile() function, as you can see in the example below.\n\nquantile(language_exams_new$exam_1)\n\nIn our exam_1 data, each of the quantiles above tells us how many scores are below the given the value. For example, 0% of scores are below 62, meaning that 62 is the lowest score. 50% of scores are below 68 and 50% above 68. (The 50% quantile is the median.) And 100% of scores are below 74, meaning that 74 is the highest score in the data set.\nWe can confirm that this is true by using the range() function, which confirms 62 and 74 as minimum and maximum values. Can you remember (or look back) to see how we would do this?\nSometimes, we want to calculate a specific one, e.g. a percentile. For this, you can add the following arguments to the quantile() function. For example, to display the 10% and 90% quantiles, you would add 0.1 and 0.9 respectively, as in the examples below.\n\nquantile(language_exams_new$exam_1, 0.1)\n\nquantile(language_exams_new$exam_1, 0.9)\n\n\n\nSummary\nThe summary() function is a fast way to get the key summary statistics.\n\nsummary(language_exams_new)\n\nsummary() is actually quite messy, but it is quick and sometimes that’s all we need, just to get a rough idea of the shape of the data.\n\n\nFrequencies\nSometimes it is helpful to observe the frequencies in our sample data. The freq() function is really helpful for this. Note: This function requires the descr package, which we will need to install and then load. Can you remember where we put these two respective commands? One goes in the console, and one at the top of the script.\n\ninstall.packages(\"descr\")\n\nlibrary(descr)\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\ninstall.packages(\"descr\") #in the console because it is temporary\n\nlibrary(descr) #at the top of the script because we need it to show everyone what tools they need\n\n\n\n\nThe following command will create a frequency table. On the left, you will see the score, in the middle the frequency with which the score occurs, and to the right this is express in percentage points. This tells you, for example, that the most frequent score (the mode) is 68, the least frequent score is 62.\n\nfreq(language_exams_new$exam_1, plot = FALSE)\n\n\n\nFrequencies with a twist\nIf you omit the argument plot = FALSE in the freq() function (which just default the argument plot = TRUE, check it out in the help pane and searching for the function name), R will produce both a table and a visual display of your data. Compare the table and the histogram (the graph). Which one is more informative? What are the relative advantages of either?\n\nfreq(language_exams_new$exam_1)\n\nFor now, we can keep the colour grey. Next week we can play with colours properly, but for now - just know you can make some great plots, but for basic exploration, let’s keep them fast and basic because we just need to know the basic shape of the data"
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html#step-4-our-first-graphic-explorations",
    "href": "Worksheets/Worksheet_wk3.html#step-4-our-first-graphic-explorations",
    "title": "3. Exploratory Data Analysis",
    "section": "Step 4: Our first graphic explorations",
    "text": "Step 4: Our first graphic explorations\nTo conclude, let’s try out a few basic graphics. Next week, we will go into much more detail, but here’s a preview of data visualization. The graphics below are available in the R base package. By and large, this will be your only exposure to base plots, because they aren’t as useful or smart as tidy plots, but for fast visualisation, they’re “just ok”. Don’t get too attached to them, next week we get some real exposure to graphics.\n\nBoxplot\nBoxplots are helpful to inspect the data (Tukey, 1977), as discussed in our lecture today. The following command creates a boxplot, based on exam_1 from the data set language_exams_new.\n\nboxplot(language_exams_new$exam_1)\n\nWhat if we want to compare performance on all three exams (exam_1, exam_2, exam_3) next to each other?\nOne way of doing this (there are other ways) is to first create three new objects exam_1, exam_2, exam_3, and then used the boxplot() function on the three.\nHave a go.\n\nexam_1 &lt;- c(language_exams_new$exam_1) \n\nexam_2 &lt;- c(language_exams_new$exam_2) \n\nexam_3 &lt;- c(language_exams_new$exam_3) \n\nboxplot(exam_1, exam_2, exam_3)\n\nCould you run the above using just one line? What is easier to read? What do you prefer?\n\n\nHistograms\nLast but not least, histograms are helpful ways to visually inspect your data. To create a histogram, simply use the hist() function, as in the following examples.\n\nhist(language_exams_new$exam_3)"
  },
  {
    "objectID": "Worksheets/Worksheet_wk3.html#take-home-task",
    "href": "Worksheets/Worksheet_wk3.html#take-home-task",
    "title": "3. Exploratory Data Analysis",
    "section": "Take home task",
    "text": "Take home task\nNone this week. You’ve worked hard and learnt a lot of complicated aspects of R - your task can be relish in your new found knowledge and be impressed with what you can now do in R.\nNext week we take on graphs, plots, and visualisations!"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html",
    "href": "Worksheets/Worksheet_wk4.html",
    "title": "4. Data visualization",
    "section": "",
    "text": "Three important things to remember:"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-0-preparing-your-environment",
    "href": "Worksheets/Worksheet_wk4.html#step-0-preparing-your-environment",
    "title": "4. Data visualization",
    "section": "Step 0: Preparing your Environment",
    "text": "Step 0: Preparing your Environment\nFirt things first, open up a new R script and load in the Tidyverse library\n\n\n\n\n\n\nNeed a reminder?\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\n\nIn addition, please download the following data files from Moodle and place them in your working directory.\n\nlanguage_exams_shorter.csv\nnettle_1999_climate.csv\ntitanic.csv\ncarprice.csv\n\nYou will also notice when completing the handout, we will also use a “built-in” dataset. These are datasets that come with R (or are loaded with different packages). They are a nice way to illustrate some of the features of R.\nTo see the list of pre-loaded data, execute the function data(). This will display the available datasets in the script editor.\n\ndata()\n\nThe data is already installed, you don’t need to load it with the data() function. You can just use the built-in datasets in your commands. Often, these datasets come with packages and are used to demonstrate examples in these packages."
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-1-two-plotting-systems-in-r-base-r-and-ggplot",
    "href": "Worksheets/Worksheet_wk4.html#step-1-two-plotting-systems-in-r-base-r-and-ggplot",
    "title": "4. Data visualization",
    "section": "Step 1: Two plotting systems in R: Base R and ggplot",
    "text": "Step 1: Two plotting systems in R: Base R and ggplot\nThere are fundamentally two methods for plotting in R, one that we touched on last week which was base R, and the other is via a library that comes bundled in the tidyverse called ggplot2. ggplot is currently the most widely used plotting system in R, and it can do lots of really cool things.\nBase R is called as such because it only uses functions that come with R in its most basic form. These are plots we can create without any additional packages required. You may come across examples of base plots in online resources such as StackOverflow when you go looking for help, so it is worthwhile understanding how they are created. Ultimately, you will be creating almost all your plots and graphics using ggplot, so I won’t spend much time on base R."
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-2-base-r",
    "href": "Worksheets/Worksheet_wk4.html#step-2-base-r",
    "title": "4. Data visualization",
    "section": "Step 2: Base R",
    "text": "Step 2: Base R\nFirst, load in the data for this task and have a quick look at it\n\nlanguage_exams &lt;- read_csv(\"language_exams_shorter.csv\")\n\nRows: 10 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): age_cohort, student\ndbl (5): exam_1, exam_2, exam_3, level, age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(language_exams)\n\n# A tibble: 6 × 7\n  age_cohort exam_1 exam_2 exam_3 level student    age\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 15-17          57     52     59     1 Alesha      16\n2 15-17          92     76     81     1 Chiara      15\n3 15-17          63     60     66     1 Davina      17\n4 15-17          40     24     30     1 Sallie      16\n5 18-22          25     13     19     1 Roxanne     18\n6 18-22          84     76     82     1 Maariyah    21\n\n\nNext, we want to get the mean scores of the variables exam_1, exam_2, and exam_3. We can do this using the summarise() function that comes from dplyr (part of Tidyverse). Take a look at what the help tab has to say about this function by typing ?summarise, or by going to the Help tab in the top-right, and using the search bar to look for summarise.\nIt tells us that “summarise() creates a new data frame. It returns one row for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input. It will contain one column for each grouping variable and one column for each of the summary statistics that you have specified.”\nIf we then scroll to the bottom of the help pane, we get to the examples - have a look at the very first one, which I paste below. Make sure you know where the examples are, they are invaluable for understanding how new code works.\nNote: mtcars is one of these preloaded datasets I just mentioned, and see how it lets you run example code very easily.\n\nmtcars %&gt;%\n  summarise(mean = mean(disp), n = n())\n\n      mean  n\n1 230.7219 32\n\n\nSo we can run example code, and it gives us an output. How do we go about understanding what it has just done? In this section of code, we have four components, and only one of which we have seen before. Let me break it down for you:\n\nmtcars - a prepackaged dataset, and was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). So it’s just a small “toy” datatset we can test ideas on.\nsummarise() - a new function that creates summary tables from larger datasets\nmean = mean(disp) - we have used mean() before. Here, we are telling summarise() to get the mean of the variable disp, and show it in a column called mean.\nn = n() - this is asking for the Number of observations (rows) in the dataset. n for number.\n\nCan you use this new knowledge to construct a summary table that will give you an output of the mean of exam_1, exam_2, and exam_3?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\nmean_scores &lt;- language_exams |&gt; \n  summarise(mean_1 = mean(exam_1),\n            mean_2 = mean(exam_2),\n            mean_3 = mean(exam_3))\n\nmean_scores\n\n# A tibble: 1 × 3\n  mean_1 mean_2 mean_3\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1   63.9   53.8   60.9\n\n\nNotice how after each comma I start a new line, this is for ease of reading, and R knows to look at the next line if it seems a comma at the end of a line.\n\n\n\nOkay, so we have our summary table made from summarise() but it isn’t quite in the right format to use in plots, so let’s coerce the mean_scores object to a numeric vector:\n\nclass(mean_scores) # to show it's a tibble\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nmean_scores &lt;- mean_scores |&gt; \n  as.numeric() #quite literally, telling R to read it as numbers and not a tibble.\n\nclass(mean_scores) #now it's numeric!\n\n[1] \"numeric\"\n\n\n\nBarplots\nNow let’s use it in a barplot\n\nbarplot(mean_scores)\n\n\n\n\nYou should now see the bar chart in the Plot tab of the Files, Plots, etc. pane, bottom right.\nBy default, the plot is vertical, but we can change this.\nCompare the following output to the output produced by the previous command.\n\nbarplot(mean_scores, horiz = TRUE) \n\n\n\n\nThis is all very good, but we need to add names to our columns, of course. We can do this by adding the names.arg() argument as below.\n\nbarplot(mean_scores, names.arg = c(\"Exam 1\", \"Exam 2\", \"Exam 3\"))\n\n\n\n\nWe can go on and add titles and axis labels like so. Or change colours and make it look fancy, but really Base plots should be used for very fast, basic plots for you to check things quick. We will cover these ideas properly in the ggplot section\n\nbarplot(\n  mean_scores,\n  names.arg = c(\"1\", \"2\", \"3\"),\n  # Note: We change the column names to avoid duplication\n  main = \"Performance on the exams\", # title\n  xlab = \"Exams\", #x axis\n  ylab = \"Scores\" #y axis\n)\n\n\n\nbarplot(mean_scores, col = \"turquoise\", border = \"steelblue\")\n\n\n\nbarplot(\n  mean_scores,\n  col = \"turquoise\",\n  border = \"steelblue\",\n  names.arg = c(\"1\", \"2\", \"3\"),\n  # Note: We change the column names to avoid duplication\n  main = \"Performance on the exams\",\n  xlab = \"Exams\",\n  ylab = \"Scores\"\n)\n\n\n\n\n\n\nHistograms\nLet’s quickly look at histograms in Base R. We start by creating two new objects, exam_1 and ages, both extracted from our language_exams data.\n\nexam_1 &lt;- language_exams$exam_1\n\nages &lt;- language_exams$age\n\nA histogram can be created using the hist() function. This plots the frequency of the variable ages in the our language exams dataset. You can play with colours if you want here, it’s the same as with barplot\n\nhist(ages)\n\n\n\n\nWe can change the number of breaks, i.e. the breakpoints between histogram cells. This is useful as sometimes the default breakpoint obscures the data.\n\nhist(ages, breaks = 20)"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#lineplots",
    "href": "Worksheets/Worksheet_wk4.html#lineplots",
    "title": "4. Data visualization",
    "section": "Lineplots",
    "text": "Lineplots\nTo illustrate line plots in Base R, let’s start by generating some data and creating three variables. We will create our own tibble from ideas we used in previous weeks. I’m leaving this code intentionally uncommented and a bit barebones - I would like for you to really read the code, use the help pane to understand what it is you are doing, test different components, etc.\nDon’t just run the code and assume it works - like I’ve said before, if you do that, you’ll get really good at running Matthew’s code, but not your own.\n\ntest_data &lt;- tibble(var_1 = c(1:20),\n                    var_2 = var_1^2,\n                    var_3 = 4 * var_2)\n\nTo test your understanding, can you mutate() the test_data tibble and add a new column called var_4 which is var_1 divided by var_3? Make sure to assign it as test_data still!\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\ntest_data &lt;- test_data |&gt; \n  mutate(var_4 = var_1 / var_3)\n\ntest_data\n\n# A tibble: 20 × 4\n   var_1 var_2 var_3  var_4\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1     1     4 0.25  \n 2     2     4    16 0.125 \n 3     3     9    36 0.0833\n 4     4    16    64 0.0625\n 5     5    25   100 0.05  \n 6     6    36   144 0.0417\n 7     7    49   196 0.0357\n 8     8    64   256 0.0312\n 9     9    81   324 0.0278\n10    10   100   400 0.025 \n11    11   121   484 0.0227\n12    12   144   576 0.0208\n13    13   169   676 0.0192\n14    14   196   784 0.0179\n15    15   225   900 0.0167\n16    16   256  1024 0.0156\n17    17   289  1156 0.0147\n18    18   324  1296 0.0139\n19    19   361  1444 0.0132\n20    20   400  1600 0.0125\n\n\n\n\n\nWe can use the plot() function to display variables 1 and 2.\n\nplot(test_data$var_1, test_data$var_2)\n\n\n\n\nThere are many types of line. Try out changing the line types by modifying the value for the type argument.\n\nplot(test_data$var_1, test_data$var_2, type = \"p\") # points\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"b\") # both points and lines\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"o\") # overplots points and lines\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"l\") # lines\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"n\") # no points or lines\n\n\n\n\noften we need to display more than one line. This is how it works in Base R\nFirst, we plot one line. (We’re also adding color and labels.)\n\nplot(\n  test_data$var_1,\n  test_data$var_2,\n  type = \"b\",\n  frame = FALSE,\n  pch = 20,\n  col = \"turquoise\",\n  xlab = \"Age\",\n  ylab = \"Scores\"\n)\n\n#Now, we can add a second line on top.\n\nlines(test_data$var_1,\n      test_data$var_2,\n      pch = 20,\n      col = \"darkblue\",\n      type = \"b\")\n\n\n\n# Let's add a legend to the plot to make it clear what the lines refer to.\n# Of course there are more compexities to base plots and how they look, but again, ggplot is where we are going to be heading.\n\n\nlegend(\n  \"topleft\",\n  legend = c(\"Group A\", \"Group B\"),\n  col = c(\"turquoise\", \"darkblue\"),\n  lty = 1:2,\n  cex = 0.8\n)\n\n\n\n\nOkay, enough of base R plotting. We’ve seen how it works with three basic types of plot. We could go further and do scattergraphs with plot() and we just don’t try and add in line types, or we could do boxplots with boxplot() but I would rather show you these ideas and to revisit the other plots using ggplot. Why? It is far more powerful, lends itself to the tidy process and just generally is better. Once you start making them, I wouldn’t be surprised if you start seeing ggplot-made graphs in publications you read, I know I see them all the time!"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-3-ggplot",
    "href": "Worksheets/Worksheet_wk4.html#step-3-ggplot",
    "title": "4. Data visualization",
    "section": "Step 3: ggplot",
    "text": "Step 3: ggplot\nggplot is a powerful system for producing elegant graphics. ggplot is included in the tidyverse package, so if you have loaded the latter you’re good to go. Alternatively, you can load the ggplot2 package directly as follows.\nTo learn more about the ggplot, I recommend the textbooks above, but also the following websites.\nAn excellent reference for ggplot: https://ggplot2.tidyverse.org/index.html\nA useful cheat sheet: https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\nGorgeous graphs in ggplot: https://r-graph-gallery.com/ggplot2-package.html\nThe gg in ggplot means grammar of graphics (Wickham, 2010). This is a system for mapping variables in a dataset to properties of a plot (e.g., shape, size, color position).\nWe will focus on using ggplot() to produce our visualizations.\nEvery time we use the ggplot command we need to specify three things (at least).\n\nThe dataset containing all the data. This can be a tibble, data frame, vector, etc.\nThe set of aesthetic mappings (aes). These describe how variables in the dataset are mapped to visual properties (aesthetics) of the type of graph we want to produce (geometric objects). Aesthetics is used to indicate x and y variables, to control the color, the size or the shape of points, the height of bars, and so forth.\nThe set of layers that render the aesthetic mappings. This is usually done according to prespecified geometric objects (geoms) such as lines, points, bars. The geometry defines the type of graphics we wish to plot (histogram, bar chart, boxplot, etc.)\n\nIn other words, we need to tell R what data to use for the plot, the type of graph, and the mapping between the visual cue and the variable (position, color, fill, etc.)\nTo understand how this work in practice, let’s start with a simple example.\nThe first argument accepted is the data, and then we provide the mapping and tell what we want the x and y axes to be.\n\nggplot(language_exams,\n       mapping = aes(x = exam_1, y = exam_2))\n\n\n\n\nBut wait, what do you see in the Plot tab? A blank canvas, right? This is because we did not specify the type of geometric object (geom). We need to add an additional line to specify the type of plot that we want\n\nScatter plot\n\nggplot(language_exams,\n       mapping = aes(x = exam_1, y = exam_2)) +\n  geom_point() # for a scatter plot\n\n\n\n\nAs you can see in your output, you should now see a scatterplot with the data from exam_1 and exam_2.\n\n\nLine plot\nIf you prefer a different type of plot, just change the geom. Below, we now produce a line plot.\n\nggplot(language_exams,\n       mapping = aes(x = exam_1, y = exam_2)) +\n  geom_line() # for a line plot\n\n\n\n\nThe funadamental difference between base and ggplot in terms of code layout, is that base in just “drawing thing” whereas ggplot attempts to make a coherent package where you are writing a little section of code that layers different components to create complex plots. Ggplot relies on an underlying dataframe, and encourages you to have your data in the correct format (nice and tidy) before plotting, whereas base R can be bodged quite a bit resulting in really messy sections of code.\nThe sequential nature of layering a ggplot figure is quite simplistic and I find easier to alter and manage. For further plots, let us pipe in the data frame to ggplot for improved readability.\nWe can also specify, in the mapping aes, what shape the different points in the scatterplot should have. For example, we can use a third variable (non-numeric) as a shape or as a color.\n\nlanguage_exams |&gt; \n  ggplot(mapping = aes(x = exam_1, y = exam_2, shape = age_cohort)) + \n  geom_point()\n\n\n\n\nand\n\nlanguage_exams |&gt; \n  ggplot(mapping = aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point()\n\n\n\n\nOne more thing. We actually don’t need to write mapping, nor do we need to spell out x and y. By default, ggplot will assume that the first function after you specify the dataset (language_exams) is the mapping (aes), and that the first two arguments with the aes() are the x-axis and y-axis respectively.\nCompare the following and see that they are functionally equivalent:\n\nlanguage_exams |&gt; \n  ggplot(mapping = aes(x = exam_1, y = exam_2)) + geom_point() #explicit\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(exam_1, exam_2)) + geom_point() #condensed\n\n\n\n\nWe will use the condensed version of writing, because why wouldn’t we?"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-4-histograms-and-frequency-polygons-with-ggplot",
    "href": "Worksheets/Worksheet_wk4.html#step-4-histograms-and-frequency-polygons-with-ggplot",
    "title": "4. Data visualization",
    "section": "Step 4: Histograms and frequency polygons with ggplot",
    "text": "Step 4: Histograms and frequency polygons with ggplot\nLet’s do some plotting with ggplot. We begin with histograms.\nWe first load the data from the Nettle (1999) book about language diversity and create a new object called languages.\n\nlanguages &lt;- read_csv(\"nettle_1999_climate.csv\")\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nHistograms are plotted if we use geom_histogram() in the ggplot() command.\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNotice that we only supply an x axis for a histogram, because it does the y-axis automatically based on count data.\n\nThemes\nLet’s pause for a second to consider themes(). In ggplot, we can make many, many, many, many detailed changes to our graphs, which we cannot cover here. Check out the graph gallery here. https://r-graph-gallery.com/ggplot2-package.html\nBut we can also make bigger changes easily by adding themes() to our ggplot() commands.\nLet’s compare the following four types of themes. (There are many other themes.)\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() # No theme\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() + \n  theme_gray() # Same as before, the default\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() + \n  theme_minimal()   # Theme minimal\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() + \n  theme_classic()   # Theme classic\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nBack to histograms\nWe can also format the different elements of the histogram. Below, we change the widths of the bins and later add some color, too. Again, compare what the commands do.\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + \n  geom_histogram(binwidth = 50)\n\n\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + \n  geom_histogram(binwidth = 50,\n                 color = 'turquoise4',\n                 fill = 'paleturquoise')\n\n\n\n\nSometimes you might prefer using a frequency polygon to display data rather than a histogram. For this, just use the geom_freqpoly() command.\nCompare. First, a histogram. (You can see the plot above.)\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + geom_histogram(binwidth = 50,\n                                      color = 'turquoise4',\n                                      fill = 'paleturquoise') \n\n\n\n\nThen, a frequency polygon.\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + geom_freqpoly(binwidth = 50,\n                                     color = 'turquoise4',\n                                     fill = 'paleturquoise') \n\nWarning in geom_freqpoly(binwidth = 50, color = \"turquoise4\", fill =\n\"paleturquoise\"): Ignoring unknown parameters: `fill`\n\n\n\n\n\n\n\nBar charts\nLet’s try out bar charts now. Again, we load data first. This comes from the Andrews (2021) textbook. Make sure to load it in, and have a look at the data to get an idea for it.\n\ntitanic &lt;- read_csv(\"titanic.csv\")\n\nRows: 1309 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): name, survived, sex, passengerClass\ndbl (1): age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nHow many columns?\nHow many rows?\nWhat kind of data is in the object?\n\nTo do bar charts, we use geom_bar().\nCompare what the different commands do.\n\ntitanic |&gt; \n  ggplot(aes(passengerClass)) + \n  geom_bar()\n\n\n\ntitanic |&gt; \n  ggplot(aes(passengerClass, fill = survived)) + \n  geom_bar()\n\n\n\ntitanic |&gt; \n  ggplot(aes(passengerClass, fill = survived)) + \n  geom_bar(position =   \"dodge\")\n\n\n\n\nAs you can see, we can use nominal categories as fill in aesthetic mapping (fill = survived), and we can manipulate the position of the bars (position = “dodge”).\nLet’s more data before we illustrate further. This dataset is also from Andrew (2021), it displays information about cars (lots of them).\n\ncar_prices &lt;- read_csv(\"carprice.csv\")  \n\nNew names:\nRows: 48 Columns: 10\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): Type dbl (9): ...1, Min.Price, Price, Max.Price, Range.Price, RoughRange,\ngpm100,...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\nThe following command creates a bar chart visualizing the prices (y-axis) according to type of car (x-axis).\n\ncar_prices |&gt; \n  ggplot(aes(Type, Price)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nWe can also group the data to further explore. The command below creates a new object called cars_prices_grouped, loads the car price data, groups it by car type, and calculates the mean prices for each car type.\nWe’ve seen something as complex as the below before, but take a look and make sure you know what’s happening, on the LHS and RHS of each pipe.\n\ncars_prices_grouped &lt;- car_prices %&gt;%\n  group_by(Type) %&gt;%\n  summarise(Price = mean(Price))\n\nIf you now type the name of the new object cars_prices_grouped, you will get a tibble with the average price.\n\ncars_prices_grouped # Compare to car_prices above\n\n# A tibble: 6 × 2\n  Type    Price\n  &lt;chr&gt;   &lt;dbl&gt;\n1 Compact  12.8\n2 Large    24.3\n3 Midsize  21.8\n4 Small    10.0\n5 Sporty   19.4\n6 Van      18.3\n\n\nWe can now do another bar chart with the grouped data.\n\ncars_prices_grouped |&gt; \n  ggplot(aes(Type, Price)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nWe can even combine the grouping process into the plotting too, bear with me on this next chunk of code, it’ll be the longest pipeline we’ve done so far\n\ncar_prices  |&gt; \n  group_by(Type)  |&gt; \n  summarise(Price = mean(Price)) |&gt; \n  ggplot(aes(Type, Price)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nThree pipes and a plot, that’s a lot. But break it down, compare it against the previous lines of code we have seen, and can you understand exactly how we went from the dataset car_prices through to a barplot? Could you take the above code and split it out into the two separate actions again?\nWhy might we want to pipe all these different commands together? What benefit does it give us?\n\n\nBoxplots\nFor the boxplots, we will use the built-in dataset ToothGrowth.\nFirst, let’s convert the variable dose from a numeric to a factor variable. These are categorical variables that can be either numeric or string variables and that can be used more easily in different types of graphics. We can do this in one of two ways, there is the base option which is the first line but commented out (as it is only to show you), and the tidy version.\n\n#ToothGrowth$dose &lt;- as.factor(ToothGrowth$dose) ## just as an example\n\nToothGrowth &lt;- ToothGrowth |&gt; \n  mutate(dose = as.factor(dose))\n\nIn an ideal world, we want to keep our writing style either in base or in tidy, I will teach you tidy because it means you can pipe things together and have really well-written, easily understandable code that can be run using one button press, rather than multiple. It helps to keep our code programmatic, logical, and easily understood where multiple functions are used to complete one meta-action.\nIn the above, the base version may seen to be more easily written, but when things get more complicated, then tidy is better. It is best to understand the priciples now, because it’ll be easier to carry out in your own analyses later on. I am not teaching you anything that I don’t personally do in my own coding. There is no pedagogically-motivated reason for me to teach Tidy over Base, beyond that the Tidy style is one of the most common ways of writing R code.\nLet’s look at generating a boxplot\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) + \n  geom_boxplot()\n\n\n\n\nTo make our life a bit easier, let’s assign the command above (which produces a plot) to a new object called our_boxplot. This command creates an object called our_boxplot, which consists of, well, a boxplot.\n\nour_boxplot &lt;- ggplot(ToothGrowth, aes(x = dose, y = len)) + \n  geom_boxplot()\n\nIf you now run this command, you create the boxplot.\n\nour_boxplot\n\n\n\n\nTo rotate a boxplot, just coord_flip()to your boxplot, as in the example below.\n\nour_boxplot + coord_flip()\n\n\n\n\nNotched box plots are also useful. The notch refers to the narrowing around the median. You can create a notched box plots as follows. Did you notice that there is an outlier? (See above the top whisker.) By default, outliers are in the color of the box. But we can change color, shape and size of the outlier.\nLet’s try out different shapes. See how the different values for the outlier.shape argument affect the plot. What happens when you run the following commands?\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) +\n  geom_boxplot(\n    outlier.colour = \"darkblue\",\n    outlier.shape = 0, # square\n    outlier.size = 4)\n\n\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) +\n  geom_boxplot(\n    outlier.colour = \"darkblue\",\n    outlier.shape = 1, # circle\n    outlier.size = 4)\n\n\n\n\nTry out some other numbers for outlier.shape, what do they produce?\nThe function stat_summary() can be used to add mean points to a box plot, as in the following command.\n\nour_boxplot + stat_summary(\n  fun.y = mean,\n  geom = \"point\",\n  shape = 23,\n  size = 4\n)\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\nWe can add points to a box plot by using the functions geom_dotplot() or geom_jitter().\nIn the following example, our box plot also has a dot plot.\n\nour_boxplot + \n  geom_dotplot(binaxis = 'y',\n               stackdir = 'center',\n               dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nAnd in this example, it has jittered points with 0.2 degree of jitter in x direction. The jitter geom adds a bit of random variation to the location of each point. This is useful when too many points are overlapping.\n\nour_boxplot + \n  geom_jitter(shape = 16, position = position_jitter(0.2))\n\n\n\n\nWe can also use special types of boxplots that combine a density plot with the boxplot. These are called violin plots, becasue they look like violins, if you squint a lot.\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) + \n  geom_violin()\n\n\n\n\nThese plots show you where the central tendency is and how the distribution sits.\n\n\nScatterplots again\nLet’s now turn to scatterplots. Again, let’s some data, this time the Nettle (1999) data about language diversity, used in Winter (2019).\n\nlanguages &lt;- read_csv(\"nettle_1999_climate.csv\")\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe geom_point() command creates scatterplots. This first one below uses points.\n\nggplot(languages, aes(MGS, Langs)) + geom_point()\n\n\n\n\nBut this one uses the text, drawn from the Country variable in our dataset languages.\n\nggplot(languages, aes(MGS, Langs, label = Country)) + geom_text()\n\n\n\n\nLet’s load some additional data.\n\nlanguage_exams &lt;- read_csv(\"language_exams_shorter.csv\")\n\nRows: 10 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): age_cohort, student\ndbl (5): exam_1, exam_2, exam_3, level, age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIn the following scatterplots, we will use the variable age cohort for color.\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) + \n  geom_point()\n\n\n\n\nThere are many parameters you can add, delete or edit in your plots. The cheat sheet is very helpful in that regard.\nBy default, the size of your points are in size 2. You can see this by comparing the scatterplot above, which doesn’t have a size specification, to the one created by the following command. (The plot looks the same, so we won’t plot this here.)\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) + \n  geom_point(size = 2)\n\n\n\n\nLet’s play around with size and shapes in scatterplots. See what happens when you run these commands.\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort))   +\n  geom_point(size = 3)\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) + \n  geom_point(size = 4)\n\n\n\n\nAnd now let’s try out different shapes. How do the commands change your plots?\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point(size = 3, shape = 'triangle') # Same as writing 2\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point(size = 4, shape = 'diamond') # Same as writing 5\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point(size = 3, shape = 'square') # Same as writing 0\n\n\n\n\nWe can also use labels for data points.\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1,\n             y = exam_2,\n             label = student,\n             color = age_cohort)) + \n  geom_point(size = 3, shape = 'triangle') +\n  geom_text(size = 4)\n\n\n\n\nThe geom_text_repel() function is useful if we intend to use labels.\nWe need to install and load it first. It comes from a package called ggrepel - can you remember how to install and load libraries? Check on previous week’s content if you can’t remember exactly.\n\n#|echo: false\n\n\nlibrary(ggrepel)\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1,\n             y = exam_2,\n             label = student,\n             color = age_cohort)) + \n  geom_point(size = 3) +\n  geom_text_repel(size = 4, segment.alpha = 2)"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-5-saving-plots",
    "href": "Worksheets/Worksheet_wk4.html#step-5-saving-plots",
    "title": "4. Data visualization",
    "section": "Step 5: Saving plots",
    "text": "Step 5: Saving plots\nThis is the ggsave() command. Let’s try saving our plots in a few different file formats (png, pdf, jpeg). Have a look at the working directory to see if you can find your three new files.\n\nggsave('our_plot.png', width = 8, height = 6)\n\nggsave('our_plot.pdf', width = 8, height = 6)\n\nggsave('our_plot.jpeg', width = 8, height = 6)\n\nYou can also save plots with specific resolutions. They default is dpi = 300.\nAlternatively, you can also write string input: “retina” (dpi 320), “print” (dpi 300), or “screen” (dpi 72). Have a go at the following.\n\nggsave(\n  'our_plot_300.jpeg',\n  width = 8,\n  height = 6,\n  dpi = 300\n)\n\nggsave(\n  'our_plot_screen.jpeg',\n  width = 8,\n  height = 6,\n  dpi = 'screen'\n)\n\nggsave(\n  'our_plot_retina.jpeg',\n  width = 8,\n  height = 6,\n  dpi = 'retina'\n)\n\nThis may have seemed like a deep dive into ggplot, but honestly, we have only touched very lightly on ggplot. I recommend you check out online materials and start exploring! The best thing is that components layer upon each other, and you can learn and add new things as you go. The tidy structure of the syntax also means things can be changed or swapped out easily."
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#step-6-colours",
    "href": "Worksheets/Worksheet_wk4.html#step-6-colours",
    "title": "4. Data visualization",
    "section": "Step 6: Colours",
    "text": "Step 6: Colours\nIn R, you can either specify colors by writing their names (e.g., “mistyrose”) or you can write the hexadecimal code (#FFE4E1).\nYou can try out compare the following.\nThe first uses the color names. The second uses the same colors but refers to them hexadecimal code.\n\nbarplot(c(2,5), col=c(\"paleturquoise\", \"mistyrose\"))\n\n\n\nbarplot(c(2,5), col=c(\"#30D5C8\", \"#FFE4E1\"))\n\n\n\n\nThe following website provides color names and a hex code finder:\nhttps://r-graph-gallery.com/ggplot2-color.html"
  },
  {
    "objectID": "Worksheets/Worksheet_wk4.html#take-home-task",
    "href": "Worksheets/Worksheet_wk4.html#take-home-task",
    "title": "4. Data visualization",
    "section": "Take home task",
    "text": "Take home task\n\nCan you create a plot using the language_exams object to draw a scatter plot between exam_1 and exam_2 scores?\n\n\nDraw a boxplot using ToothGrowth to show the differences between the supplement type and tooth length.\n\nHint: take a look at ?ToothGrowth to see what each column means.\n\nCan you update the code for question 2 in order to plot only the dose differences for the OJ supplement? Hint, you’ll need to use filter on the dataset before creating the plot. We learnt about filter() in last week’s worksheet, or look at ?filter (second option, the one from dplyr “Keep rows that match a condition”) and check out examples at the bottom.\n\nThe plot should only show data from OJ tests for each level of dose.\n\nCan you turn this into a violin plot? What do you think is better for commuicating the information?"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html",
    "href": "Worksheets/Answers/Worksheet_wk4.html",
    "title": "4. Data visualization",
    "section": "",
    "text": "Three important things to remember:"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-0-preparing-your-environment",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-0-preparing-your-environment",
    "title": "4. Data visualization",
    "section": "Step 0: Preparing your Environment",
    "text": "Step 0: Preparing your Environment\nFirt things first, open up a new R script and load in the Tidyverse library\n\n\n\n\n\n\nNeed a reminder?\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\n\nIn addition, please download the following data files from Moodle and place them in your working directory.\n\nlanguage_exams_shorter.csv\nnettle_1999_climate.csv\ntitanic.csv\ncarprice.csv\n\nYou will also notice when completing the handout, we will also use a “built-in” dataset. These are datasets that come with R (or are loaded with different packages). They are a nice way to illustrate some of the features of R.\nTo see the list of pre-loaded data, execute the function data(). This will display the available datasets in the script editor.\n\ndata()\n\nThe data is already installed, you don’t need to load it with the data() function. You can just use the built-in datasets in your commands. Often, these datasets come with packages and are used to demonstrate examples in these packages."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-1-two-plotting-systems-in-r-base-r-and-ggplot",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-1-two-plotting-systems-in-r-base-r-and-ggplot",
    "title": "4. Data visualization",
    "section": "Step 1: Two plotting systems in R: Base R and ggplot",
    "text": "Step 1: Two plotting systems in R: Base R and ggplot\nThere are fundamentally two methods for plotting in R, one that we touched on last week which was base R, and the other is via a library that comes bundled in the tidyverse called ggplot2. ggplot is currently the most widely used plotting system in R, and it can do lots of really cool things.\nBase R is called as such because it only uses functions that come with R in its most basic form. These are plots we can create without any additional packages required. You may come across examples of base plots in online resources such as StackOverflow when you go looking for help, so it is worthwhile understanding how they are created. Ultimately, you will be creating almost all your plots and graphics using ggplot, so I won’t spend much time on base R."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-2-base-r",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-2-base-r",
    "title": "4. Data visualization",
    "section": "Step 2: Base R",
    "text": "Step 2: Base R\nFirst, load in the data for this task and have a quick look at it\n\nlanguage_exams &lt;- read_csv(\"language_exams_shorter.csv\")\n\nRows: 10 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): age_cohort, student\ndbl (5): exam_1, exam_2, exam_3, level, age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(language_exams)\n\n# A tibble: 6 × 7\n  age_cohort exam_1 exam_2 exam_3 level student    age\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1 15-17          57     52     59     1 Alesha      16\n2 15-17          92     76     81     1 Chiara      15\n3 15-17          63     60     66     1 Davina      17\n4 15-17          40     24     30     1 Sallie      16\n5 18-22          25     13     19     1 Roxanne     18\n6 18-22          84     76     82     1 Maariyah    21\n\n\nNext, we want to get the mean scores of the variables exam_1, exam_2, and exam_3. We can do this using the summarise() function that comes from dplyr (part of Tidyverse). Take a look at what the help tab has to say about this function by typing ?summarise, or by going to the Help tab in the top-right, and using the search bar to look for summarise.\nIt tells us that “summarise() creates a new data frame. It returns one row for each combination of grouping variables; if there are no grouping variables, the output will have a single row summarising all observations in the input. It will contain one column for each grouping variable and one column for each of the summary statistics that you have specified.”\nIf we then scroll to the bottom of the help pane, we get to the examples - have a look at the very first one, which I paste below. Make sure you know where the examples are, they are invaluable for understanding how new code works.\nNote: mtcars is one of these preloaded datasets I just mentioned, and see how it lets you run example code very easily.\n\nmtcars %&gt;%\n  summarise(mean = mean(disp), n = n())\n\n      mean  n\n1 230.7219 32\n\n\nSo we can run example code, and it gives us an output. How do we go about understanding what it has just done? In this section of code, we have four components, and only one of which we have seen before. Let me break it down for you:\n\nmtcars - a prepackaged dataset, and was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models). So it’s just a small “toy” datatset we can test ideas on.\nsummarise() - a new function that creates summary tables from larger datasets\nmean = mean(disp) - we have used mean() before. Here, we are telling summarise() to get the mean of the variable disp, and show it in a column called mean.\nn = n() - this is asking for the Number of observations (rows) in the dataset. n for number.\n\nCan you use this new knowledge to construct a summary table that will give you an output of the mean of exam_1, exam_2, and exam_3?\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\nmean_scores &lt;- language_exams |&gt; \n  summarise(mean_1 = mean(exam_1),\n            mean_2 = mean(exam_2),\n            mean_3 = mean(exam_3))\n\nmean_scores\n\n# A tibble: 1 × 3\n  mean_1 mean_2 mean_3\n   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1   63.9   53.8   60.9\n\n\nNotice how after each comma I start a new line, this is for ease of reading, and R knows to look at the next line if it seems a comma at the end of a line.\n\n\n\nOkay, so we have our summary table made from summarise() but it isn’t quite in the right format to use in plots, so let’s coerce the mean_scores object to a numeric vector:\n\nclass(mean_scores) # to show it's a tibble\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nmean_scores &lt;- mean_scores |&gt; \n  as.numeric() #quite literally, telling R to read it as numbers and not a tibble.\n\nclass(mean_scores) #now it's numeric!\n\n[1] \"numeric\"\n\n\n\nBarplots\nNow let’s use it in a barplot\n\nbarplot(mean_scores)\n\n\n\n\nYou should now see the bar chart in the Plot tab of the Files, Plots, etc. pane, bottom right.\nBy default, the plot is vertical, but we can change this.\nCompare the following output to the output produced by the previous command.\n\nbarplot(mean_scores, horiz = TRUE) \n\n\n\n\nThis is all very good, but we need to add names to our columns, of course. We can do this by adding the names.arg() argument as below.\n\nbarplot(mean_scores, names.arg = c(\"Exam 1\", \"Exam 2\", \"Exam 3\"))\n\n\n\n\nWe can go on and add titles and axis labels like so. Or change colours and make it look fancy, but really Base plots should be used for very fast, basic plots for you to check things quick. We will cover these ideas properly in the ggplot section\n\nbarplot(\n  mean_scores,\n  names.arg = c(\"1\", \"2\", \"3\"),\n  # Note: We change the column names to avoid duplication\n  main = \"Performance on the exams\", # title\n  xlab = \"Exams\", #x axis\n  ylab = \"Scores\" #y axis\n)\n\n\n\nbarplot(mean_scores, col = \"turquoise\", border = \"steelblue\")\n\n\n\nbarplot(\n  mean_scores,\n  col = \"turquoise\",\n  border = \"steelblue\",\n  names.arg = c(\"1\", \"2\", \"3\"),\n  # Note: We change the column names to avoid duplication\n  main = \"Performance on the exams\",\n  xlab = \"Exams\",\n  ylab = \"Scores\"\n)\n\n\n\n\n\n\nHistograms\nLet’s quickly look at histograms in Base R. We start by creating two new objects, exam_1 and ages, both extracted from our language_exams data.\n\nexam_1 &lt;- language_exams$exam_1\n\nages &lt;- language_exams$age\n\nA histogram can be created using the hist() function. This plots the frequency of the variable ages in the our language exams dataset. You can play with colours if you want here, it’s the same as with barplot\n\nhist(ages)\n\n\n\n\nWe can change the number of breaks, i.e. the breakpoints between histogram cells. This is useful as sometimes the default breakpoint obscures the data.\n\nhist(ages, breaks = 20)"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#lineplots",
    "href": "Worksheets/Answers/Worksheet_wk4.html#lineplots",
    "title": "4. Data visualization",
    "section": "Lineplots",
    "text": "Lineplots\nTo illustrate line plots in Base R, let’s start by generating some data and creating three variables. We will create our own tibble from ideas we used in previous weeks. I’m leaving this code intentionally uncommented and a bit barebones - I would like for you to really read the code, use the help pane to understand what it is you are doing, test different components, etc.\nDon’t just run the code and assume it works - like I’ve said before, if you do that, you’ll get really good at running Matthew’s code, but not your own.\n\ntest_data &lt;- tibble(var_1 = c(1:20),\n                    var_2 = var_1^2,\n                    var_3 = 4 * var_2)\n\nTo test your understanding, can you mutate() the test_data tibble and add a new column called var_4 which is var_1 divided by var_3? Make sure to assign it as test_data still!\n\n\n\n\n\n\nanswer\n\n\n\n\n\n\ntest_data &lt;- test_data |&gt; \n  mutate(var_4 = var_1 / var_3)\n\ntest_data\n\n# A tibble: 20 × 4\n   var_1 var_2 var_3  var_4\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1     1     1     4 0.25  \n 2     2     4    16 0.125 \n 3     3     9    36 0.0833\n 4     4    16    64 0.0625\n 5     5    25   100 0.05  \n 6     6    36   144 0.0417\n 7     7    49   196 0.0357\n 8     8    64   256 0.0312\n 9     9    81   324 0.0278\n10    10   100   400 0.025 \n11    11   121   484 0.0227\n12    12   144   576 0.0208\n13    13   169   676 0.0192\n14    14   196   784 0.0179\n15    15   225   900 0.0167\n16    16   256  1024 0.0156\n17    17   289  1156 0.0147\n18    18   324  1296 0.0139\n19    19   361  1444 0.0132\n20    20   400  1600 0.0125\n\n\n\n\n\nWe can use the plot() function to display variables 1 and 2.\n\nplot(test_data$var_1, test_data$var_2)\n\n\n\n\nThere are many types of line. Try out changing the line types by modifying the value for the type argument.\n\nplot(test_data$var_1, test_data$var_2, type = \"p\") # points\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"b\") # both points and lines\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"o\") # overplots points and lines\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"l\") # lines\n\n\n\nplot(test_data$var_1, test_data$var_2, type = \"n\") # no points or lines\n\n\n\n\noften we need to display more than one line. This is how it works in Base R\nFirst, we plot one line. (We’re also adding color and labels.)\n\nplot(\n  test_data$var_1,\n  test_data$var_2,\n  type = \"b\",\n  frame = FALSE,\n  pch = 20,\n  col = \"turquoise\",\n  xlab = \"Age\",\n  ylab = \"Scores\"\n)\n\n#Now, we can add a second line on top.\n\nlines(test_data$var_1,\n      test_data$var_2,\n      pch = 20,\n      col = \"darkblue\",\n      type = \"b\")\n\n\n\n# Let's add a legend to the plot to make it clear what the lines refer to.\n# Of course there are more compexities to base plots and how they look, but again, ggplot is where we are going to be heading.\n\n\nlegend(\n  \"topleft\",\n  legend = c(\"Group A\", \"Group B\"),\n  col = c(\"turquoise\", \"darkblue\"),\n  lty = 1:2,\n  cex = 0.8\n)\n\n\n\n\nOkay, enough of base R plotting. We’ve seen how it works with three basic types of plot. We could go further and do scattergraphs with plot() and we just don’t try and add in line types, or we could do boxplots with boxplot() but I would rather show you these ideas and to revisit the other plots using ggplot. Why? It is far more powerful, lends itself to the tidy process and just generally is better. Once you start making them, I wouldn’t be surprised if you start seeing ggplot-made graphs in publications you read, I know I see them all the time!"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-3-ggplot",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-3-ggplot",
    "title": "4. Data visualization",
    "section": "Step 3: ggplot",
    "text": "Step 3: ggplot\nggplot is a powerful system for producing elegant graphics. ggplot is included in the tidyverse package, so if you have loaded the latter you’re good to go. Alternatively, you can load the ggplot2 package directly as follows.\nTo learn more about the ggplot, I recommend the textbooks above, but also the following websites.\nAn excellent reference for ggplot: https://ggplot2.tidyverse.org/index.html\nA useful cheat sheet: https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf\nGorgeous graphs in ggplot: https://r-graph-gallery.com/ggplot2-package.html\nThe gg in ggplot means grammar of graphics (Wickham, 2010). This is a system for mapping variables in a dataset to properties of a plot (e.g., shape, size, color position).\nWe will focus on using ggplot() to produce our visualizations.\nEvery time we use the ggplot command we need to specify three things (at least).\n\nThe dataset containing all the data. This can be a tibble, data frame, vector, etc.\nThe set of aesthetic mappings (aes). These describe how variables in the dataset are mapped to visual properties (aesthetics) of the type of graph we want to produce (geometric objects). Aesthetics is used to indicate x and y variables, to control the color, the size or the shape of points, the height of bars, and so forth.\nThe set of layers that render the aesthetic mappings. This is usually done according to prespecified geometric objects (geoms) such as lines, points, bars. The geometry defines the type of graphics we wish to plot (histogram, bar chart, boxplot, etc.)\n\nIn other words, we need to tell R what data to use for the plot, the type of graph, and the mapping between the visual cue and the variable (position, color, fill, etc.)\nTo understand how this work in practice, let’s start with a simple example.\nThe first argument accepted is the data, and then we provide the mapping and tell what we want the x and y axes to be.\n\nggplot(language_exams,\n       mapping = aes(x = exam_1, y = exam_2))\n\n\n\n\nBut wait, what do you see in the Plot tab? A blank canvas, right? This is because we did not specify the type of geometric object (geom). We need to add an additional line to specify the type of plot that we want\n\nScatter plot\n\nggplot(language_exams,\n       mapping = aes(x = exam_1, y = exam_2)) +\n  geom_point() # for a scatter plot\n\n\n\n\nAs you can see in your output, you should now see a scatterplot with the data from exam_1 and exam_2.\n\n\nLine plot\nIf you prefer a different type of plot, just change the geom. Below, we now produce a line plot.\n\nggplot(language_exams,\n       mapping = aes(x = exam_1, y = exam_2)) +\n  geom_line() # for a line plot\n\n\n\n\nThe funadamental difference between base and ggplot in terms of code layout, is that base in just “drawing thing” whereas ggplot attempts to make a coherent package where you are writing a little section of code that layers different components to create complex plots. Ggplot relies on an underlying dataframe, and encourages you to have your data in the correct format (nice and tidy) before plotting, whereas base R can be bodged quite a bit resulting in really messy sections of code.\nThe sequential nature of layering a ggplot figure is quite simplistic and I find easier to alter and manage. For further plots, let us pipe in the data frame to ggplot for improved readability.\nWe can also specify, in the mapping aes, what shape the different points in the scatterplot should have. For example, we can use a third variable (non-numeric) as a shape or as a color.\n\nlanguage_exams |&gt; \n  ggplot(mapping = aes(x = exam_1, y = exam_2, shape = age_cohort)) + \n  geom_point()\n\n\n\n\nand\n\nlanguage_exams |&gt; \n  ggplot(mapping = aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point()\n\n\n\n\nOne more thing. We actually don’t need to write mapping, nor do we need to spell out x and y. By default, ggplot will assume that the first function after you specify the dataset (language_exams) is the mapping (aes), and that the first two arguments with the aes() are the x-axis and y-axis respectively.\nCompare the following and see that they are functionally equivalent:\n\nlanguage_exams |&gt; \n  ggplot(mapping = aes(x = exam_1, y = exam_2)) + geom_point() #explicit\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(exam_1, exam_2)) + geom_point() #condensed\n\n\n\n\nWe will use the condensed version of writing, because why wouldn’t we?"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-4-histograms-and-frequency-polygons-with-ggplot",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-4-histograms-and-frequency-polygons-with-ggplot",
    "title": "4. Data visualization",
    "section": "Step 4: Histograms and frequency polygons with ggplot",
    "text": "Step 4: Histograms and frequency polygons with ggplot\nLet’s do some plotting with ggplot. We begin with histograms.\nWe first load the data from the Nettle (1999) book about language diversity and create a new object called languages.\n\nlanguages &lt;- read_csv(\"nettle_1999_climate.csv\")\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nHistograms are plotted if we use geom_histogram() in the ggplot() command.\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNotice that we only supply an x axis for a histogram, because it does the y-axis automatically based on count data.\n\nThemes\nLet’s pause for a second to consider themes(). In ggplot, we can make many, many, many, many detailed changes to our graphs, which we cannot cover here. Check out the graph gallery here. https://r-graph-gallery.com/ggplot2-package.html\nBut we can also make bigger changes easily by adding themes() to our ggplot() commands.\nLet’s compare the following four types of themes. (There are many other themes.)\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() # No theme\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() + \n  theme_gray() # Same as before, the default\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() + \n  theme_minimal()   # Theme minimal\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(mapping = aes(x = Langs)) + \n  geom_histogram() + \n  theme_classic()   # Theme classic\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nBack to histograms\nWe can also format the different elements of the histogram. Below, we change the widths of the bins and later add some color, too. Again, compare what the commands do.\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + \n  geom_histogram(binwidth = 50)\n\n\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + \n  geom_histogram(binwidth = 50,\n                 color = 'turquoise4',\n                 fill = 'paleturquoise')\n\n\n\n\nSometimes you might prefer using a frequency polygon to display data rather than a histogram. For this, just use the geom_freqpoly() command.\nCompare. First, a histogram. (You can see the plot above.)\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + geom_histogram(binwidth = 50,\n                                      color = 'turquoise4',\n                                      fill = 'paleturquoise') \n\n\n\n\nThen, a frequency polygon.\n\nlanguages |&gt; \n  ggplot(aes(Langs)) + geom_freqpoly(binwidth = 50,\n                                     color = 'turquoise4',\n                                     fill = 'paleturquoise') \n\nWarning in geom_freqpoly(binwidth = 50, color = \"turquoise4\", fill =\n\"paleturquoise\"): Ignoring unknown parameters: `fill`\n\n\n\n\n\n\n\nBar charts\nLet’s try out bar charts now. Again, we load data first. This comes from the Andrews (2021) textbook. Make sure to load it in, and have a look at the data to get an idea for it.\n\ntitanic &lt;- read_csv(\"titanic.csv\")\n\nRows: 1309 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): name, survived, sex, passengerClass\ndbl (1): age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nHow many columns?\nHow many rows?\nWhat kind of data is in the object?\n\nTo do bar charts, we use geom_bar().\nCompare what the different commands do.\n\ntitanic |&gt; \n  ggplot(aes(passengerClass)) + \n  geom_bar()\n\n\n\ntitanic |&gt; \n  ggplot(aes(passengerClass, fill = survived)) + \n  geom_bar()\n\n\n\ntitanic |&gt; \n  ggplot(aes(passengerClass, fill = survived)) + \n  geom_bar(position =   \"dodge\")\n\n\n\n\nAs you can see, we can use nominal categories as fill in aesthetic mapping (fill = survived), and we can manipulate the position of the bars (position = “dodge”).\nLet’s more data before we illustrate further. This dataset is also from Andrew (2021), it displays information about cars (lots of them).\n\ncar_prices &lt;- read_csv(\"carprice.csv\")  \n\nNew names:\nRows: 48 Columns: 10\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(1): Type dbl (9): ...1, Min.Price, Price, Max.Price, Range.Price, RoughRange,\ngpm100,...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n\nThe following command creates a bar chart visualizing the prices (y-axis) according to type of car (x-axis).\n\ncar_prices |&gt; \n  ggplot(aes(Type, Price)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nWe can also group the data to further explore. The command below creates a new object called cars_prices_grouped, loads the car price data, groups it by car type, and calculates the mean prices for each car type.\nWe’ve seen something as complex as the below before, but take a look and make sure you know what’s happening, on the LHS and RHS of each pipe.\n\ncars_prices_grouped &lt;- car_prices %&gt;%\n  group_by(Type) %&gt;%\n  summarise(Price = mean(Price))\n\nIf you now type the name of the new object cars_prices_grouped, you will get a tibble with the average price.\n\ncars_prices_grouped # Compare to car_prices above\n\n# A tibble: 6 × 2\n  Type    Price\n  &lt;chr&gt;   &lt;dbl&gt;\n1 Compact  12.8\n2 Large    24.3\n3 Midsize  21.8\n4 Small    10.0\n5 Sporty   19.4\n6 Van      18.3\n\n\nWe can now do another bar chart with the grouped data.\n\ncars_prices_grouped |&gt; \n  ggplot(aes(Type, Price)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nWe can even combine the grouping process into the plotting too, bear with me on this next chunk of code, it’ll be the longest pipeline we’ve done so far\n\ncar_prices  |&gt; \n  group_by(Type)  |&gt; \n  summarise(Price = mean(Price)) |&gt; \n  ggplot(aes(Type, Price)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nThree pipes and a plot, that’s a lot. But break it down, compare it against the previous lines of code we have seen, and can you understand exactly how we went from the dataset car_prices through to a barplot? Could you take the above code and split it out into the two separate actions again?\nWhy might we want to pipe all these different commands together? What benefit does it give us?\n\n\nBoxplots\nFor the boxplots, we will use the built-in dataset ToothGrowth.\nFirst, let’s convert the variable dose from a numeric to a factor variable. These are categorical variables that can be either numeric or string variables and that can be used more easily in different types of graphics. We can do this in one of two ways, there is the base option which is the first line but commented out (as it is only to show you), and the tidy version.\n\n#ToothGrowth$dose &lt;- as.factor(ToothGrowth$dose) ## just as an example\n\nToothGrowth &lt;- ToothGrowth |&gt; \n  mutate(dose = as.factor(dose))\n\nIn an ideal world, we want to keep our writing style either in base or in tidy, I will teach you tidy because it means you can pipe things together and have really well-written, easily understandable code that can be run using one button press, rather than multiple. It helps to keep our code programmatic, logical, and easily understood where multiple functions are used to complete one meta-action.\nIn the above, the base version may seen to be more easily written, but when things get more complicated, then tidy is better. It is best to understand the priciples now, because it’ll be easier to carry out in your own analyses later on. I am not teaching you anything that I don’t personally do in my own coding. There is no pedagogically-motivated reason for me to teach Tidy over Base, beyond that the Tidy style is one of the most common ways of writing R code.\nLet’s look at generating a boxplot\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) + \n  geom_boxplot()\n\n\n\n\nTo make our life a bit easier, let’s assign the command above (which produces a plot) to a new object called our_boxplot. This command creates an object called our_boxplot, which consists of, well, a boxplot.\n\nour_boxplot &lt;- ggplot(ToothGrowth, aes(x = dose, y = len)) + \n  geom_boxplot()\n\nIf you now run this command, you create the boxplot.\n\nour_boxplot\n\n\n\n\nTo rotate a boxplot, just coord_flip()to your boxplot, as in the example below.\n\nour_boxplot + coord_flip()\n\n\n\n\nNotched box plots are also useful. The notch refers to the narrowing around the median. You can create a notched box plots as follows. Did you notice that there is an outlier? (See above the top whisker.) By default, outliers are in the color of the box. But we can change color, shape and size of the outlier.\nLet’s try out different shapes. See how the different values for the outlier.shape argument affect the plot. What happens when you run the following commands?\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) +\n  geom_boxplot(\n    outlier.colour = \"darkblue\",\n    outlier.shape = 0, # square\n    outlier.size = 4)\n\n\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) +\n  geom_boxplot(\n    outlier.colour = \"darkblue\",\n    outlier.shape = 1, # circle\n    outlier.size = 4)\n\n\n\n\nTry out some other numbers for outlier.shape, what do they produce?\nThe function stat_summary() can be used to add mean points to a box plot, as in the following command.\n\nour_boxplot + stat_summary(\n  fun.y = mean,\n  geom = \"point\",\n  shape = 23,\n  size = 4\n)\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\n\n\n\nWe can add points to a box plot by using the functions geom_dotplot() or geom_jitter().\nIn the following example, our box plot also has a dot plot.\n\nour_boxplot + \n  geom_dotplot(binaxis = 'y',\n               stackdir = 'center',\n               dotsize = 0.5)\n\nBin width defaults to 1/30 of the range of the data. Pick better value with\n`binwidth`.\n\n\n\n\n\nAnd in this example, it has jittered points with 0.2 degree of jitter in x direction. The jitter geom adds a bit of random variation to the location of each point. This is useful when too many points are overlapping.\n\nour_boxplot + \n  geom_jitter(shape = 16, position = position_jitter(0.2))\n\n\n\n\nWe can also use special types of boxplots that combine a density plot with the boxplot. These are called violin plots, becasue they look like violins, if you squint a lot.\n\nToothGrowth |&gt; \n  ggplot(aes(x = dose, y = len)) + \n  geom_violin()\n\n\n\n\nThese plots show you where the central tendency is and how the distribution sits.\n\n\nScatterplots again\nLet’s now turn to scatterplots. Again, let’s some data, this time the Nettle (1999) data about language diversity, used in Winter (2019).\n\nlanguages &lt;- read_csv(\"nettle_1999_climate.csv\")\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe geom_point() command creates scatterplots. This first one below uses points.\n\nggplot(languages, aes(MGS, Langs)) + geom_point()\n\n\n\n\nBut this one uses the text, drawn from the Country variable in our dataset languages.\n\nggplot(languages, aes(MGS, Langs, label = Country)) + geom_text()\n\n\n\n\nLet’s load some additional data.\n\nlanguage_exams &lt;- read_csv(\"language_exams_shorter.csv\")\n\nRows: 10 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): age_cohort, student\ndbl (5): exam_1, exam_2, exam_3, level, age\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nIn the following scatterplots, we will use the variable age cohort for color.\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) + \n  geom_point()\n\n\n\n\nThere are many parameters you can add, delete or edit in your plots. The cheat sheet is very helpful in that regard.\nBy default, the size of your points are in size 2. You can see this by comparing the scatterplot above, which doesn’t have a size specification, to the one created by the following command. (The plot looks the same, so we won’t plot this here.)\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) + \n  geom_point(size = 2)\n\n\n\n\nLet’s play around with size and shapes in scatterplots. See what happens when you run these commands.\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort))   +\n  geom_point(size = 3)\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) + \n  geom_point(size = 4)\n\n\n\n\nAnd now let’s try out different shapes. How do the commands change your plots?\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point(size = 3, shape = 'triangle') # Same as writing 2\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point(size = 4, shape = 'diamond') # Same as writing 5\n\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1, y = exam_2, color = age_cohort)) +\n  geom_point(size = 3, shape = 'square') # Same as writing 0\n\n\n\n\nWe can also use labels for data points.\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1,\n             y = exam_2,\n             label = student,\n             color = age_cohort)) + \n  geom_point(size = 3, shape = 'triangle') +\n  geom_text(size = 4)\n\n\n\n\nThe geom_text_repel() function is useful if we intend to use labels.\nWe need to install and load it first. It comes from a package called ggrepel - can you remember how to install and load libraries? Check on previous week’s content if you can’t remember exactly.\n\n#|echo: false\n\n\nlibrary(ggrepel)\n\n\nlanguage_exams |&gt; \n  ggplot(aes(x = exam_1,\n             y = exam_2,\n             label = student,\n             color = age_cohort)) + \n  geom_point(size = 3) +\n  geom_text_repel(size = 4, segment.alpha = 2)"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-5-saving-plots",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-5-saving-plots",
    "title": "4. Data visualization",
    "section": "Step 5: Saving plots",
    "text": "Step 5: Saving plots\nThis is the ggsave() command. Let’s try saving our plots in a few different file formats (png, pdf, jpeg). Have a look at the working directory to see if you can find your three new files.\n\nggsave('our_plot.png', width = 8, height = 6)\n\nggsave('our_plot.pdf', width = 8, height = 6)\n\nggsave('our_plot.jpeg', width = 8, height = 6)\n\nYou can also save plots with specific resolutions. They default is dpi = 300.\nAlternatively, you can also write string input: “retina” (dpi 320), “print” (dpi 300), or “screen” (dpi 72). Have a go at the following.\n\nggsave(\n  'our_plot_300.jpeg',\n  width = 8,\n  height = 6,\n  dpi = 300\n)\n\nggsave(\n  'our_plot_screen.jpeg',\n  width = 8,\n  height = 6,\n  dpi = 'screen'\n)\n\nggsave(\n  'our_plot_retina.jpeg',\n  width = 8,\n  height = 6,\n  dpi = 'retina'\n)\n\nThis may have seemed like a deep dive into ggplot, but honestly, we have only touched very lightly on ggplot. I recommend you check out online materials and start exploring! The best thing is that components layer upon each other, and you can learn and add new things as you go. The tidy structure of the syntax also means things can be changed or swapped out easily."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#step-6-colours",
    "href": "Worksheets/Answers/Worksheet_wk4.html#step-6-colours",
    "title": "4. Data visualization",
    "section": "Step 6: Colours",
    "text": "Step 6: Colours\nIn R, you can either specify colors by writing their names (e.g., “mistyrose”) or you can write the hexadecimal code (#FFE4E1).\nYou can try out compare the following.\nThe first uses the color names. The second uses the same colors but refers to them hexadecimal code.\n\nbarplot(c(2,5), col=c(\"paleturquoise\", \"mistyrose\"))\n\n\n\nbarplot(c(2,5), col=c(\"#30D5C8\", \"#FFE4E1\"))\n\n\n\n\nThe following website provides color names and a hex code finder:\nhttps://r-graph-gallery.com/ggplot2-color.html"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk4.html#take-home-task",
    "href": "Worksheets/Answers/Worksheet_wk4.html#take-home-task",
    "title": "4. Data visualization",
    "section": "Take home task",
    "text": "Take home task\n\nCan you create a plot using the language_exams object to draw a scatter plot between exam_1 and exam_2 scores?\n\n\nlanguage_exams |&gt; \n  ggplot(aes(exam_1, exam_2)) +\n  geom_point()\n\n\n\n\n\nDraw a boxplot using ToothGrowth to show the differences between the supplement type and tooth length.\n\nHint: take a look at ?ToothGrowth to see what each column means.\n\nToothGrowth |&gt; \n  ggplot(aes(supp, len)) +\n  geom_boxplot()\n\n\n\n\n\nCan you update the code for question 2 in order to plot only the dose differences for the OJ supplement? Hint, you’ll need to use filter on the dataset before creating the plot. We learnt about filter() in last week’s worksheet, or look at ?filter (second option, the one from dplyr “Keep rows that match a condition”) and check out examples at the bottom.\n\nThe plot should only show data from OJ tests for each level of dose.\n\nToothGrowth |&gt; \n  filter(supp == \"OJ\") |&gt;  # keep only content OJ observations\n  ggplot(aes(dose, len)) +\n  geom_boxplot()\n\n\n\n\n\nCan you turn this into a violin plot? What do you think is better for commuicating the information?\n\n\nToothGrowth |&gt; \n  filter(supp == \"OJ\") |&gt; \n  ggplot(aes(dose, len)) +\n  geom_violin()\n\n\n\n\nAs for which is better, it’s subjective and depends on what you need to convey as part of your narrative."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html",
    "title": "2. Data management and data wrangling",
    "section": "",
    "text": "Three important things to remember:"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-0-installing-tidyverse",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-0-installing-tidyverse",
    "title": "2. Data management and data wrangling",
    "section": "Step 0: Installing tidyverse",
    "text": "Step 0: Installing tidyverse\nI mentioned tidyverse in the lecture, and now we will intall and load it, before using it (mainly for pipes!)\nAs a one-off (on a per machine basis) the first command only needs to be run when we first want a package. As noted before, there are thousands of functions available to R, having them all pre-packaged would break your computer and you don’t need every single one.\n\ninstall.packages(\"tidyverse\")\n\nThere is little to know about this at this stage, as the function does a lot of the legwork for us. It looks on the CRAN (The Comprehensive R Archive Network) which contains the R approved packages. It downloads it so you can use all the functions contained in a spacific package.\nAs stated before, tidyverse is a collection of packages, and we will need to understand that later on, but for now: no need.\nNow to load the package so we can use the functions:\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.4     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nAs above, you will get a bunch of messages in the console, we can reasonably ignore these for now.\n\n\n\n\n\n\nNote\n\n\n\nAs a general point, we would run install.packages() in the console, and place library() at the top of a script. The next section should make this a bit clearer as to the difference"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-1-scripts",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-1-scripts",
    "title": "2. Data management and data wrangling",
    "section": "Step 1: Scripts",
    "text": "Step 1: Scripts\nA script is essentially a sequence of commands that we want R to execute. As Winter (2019) points out, we can think of our R script as the recipe and the R console as the kitchen that cooks according to this recipe. Let’s try out the script editor and write our first script. Typing commands in the console is good for one off commands (maybe to check the class() or to install.packages()), but the script is better for keeping the steps in order.\nWhen working in R, try to work as much as possible in the script. This will be a summary of all of your analyses, which can then be shared with other researchers, together with your data. This way, others can reproduce your analyses.\nThus far, you have typed your command lines in the console. This was useful to illustrate the functioning of our R, but in most of your analyses you won’t type much in the console. Instead, we will use the script editor.\nThe script editor is the pane on the top left of your window. If you don’t see it, you need to open a new script first. For this, press Cmd+Shift+N (Mac) or Ctrl+Shift+N (Windows). Alternatively, in the menu, click File &gt; New File &gt; RScript.)\nIn the script editor (not the console), type the following command in line 1 press Return (Mac) / Enter (Windows).\n\n2 + 3\n\n[1] 5\n\n\nAs you can see, nothing happened. There is no output in the Console pane; the cursor just moved to the next line in the script editor (line 2). This is because you did not execute the script.\nTo execute a command in the script editor, you need to place your cursor anywhere on the line you wish to execute and then click the Run icon in the Script editor pane. If you do this, then the following output will appear in your Console.\nYou can also run the current command line or selection in the script by pressing Cmd+Return (Mac) or Ctrl+Enter (Windows). This will also send your command from the script editor to the console. (I suggest using the shortcut, it’s much more efficient.)\nIn the script, you can have as many lines of code as you wish. For example, you can add the following three commands to your script.\n\nscores &lt;- c(145, 234, 653, 876, 456) \n\nmean(scores)\n\n[1] 472.8\n\nsd(scores)\n\n[1] 299.9178\n\n\nTo execute each one separately, just go to the line in question and click the Run icon or, even better, press the keyboard shortcut.\nYou can also run multiple commands in one go. For this, you either highlight several lines and then press the Run icon (or keyboard shortcut). Try it with the above three lines.\nTo execute all commands in the script, you click the Source icon (next to the Run icon) in the Script editor pane. Or just use the shortcut Cmd+Option+R (Mac) or Ctrl+Alt+R (Windows).\n\nMultiline commands\nUsing the script editor is particularly useful when we write long and complex commands. The example below illustrates this nicely.\nThis is a fairly long command, written in the console in one line.\n\ndf &lt;- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), age = c(23, 25, 46, 19), occupation = c('doctor', 'director', 'student', 'spy'))\n\nbut in a multiline format:\n\ndf &lt;- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), \n                 age = c(23, 25, 46, 19), \n                 occupation = c('doctor', 'director', 'student', 'spy'))\n\nNote the indentations, this is done automatically by RStudio as it recognises what is grouped according to parentheses.\n\n\nComments\nAn important feature of R (and other programming languages) is the option to write comments in the code files. Comments are notes, written around the code, that are ignored when the script is executed. In R, anything followed by the # symbol on any line is treated as a comment. This means that a line starting with # is ignored when the code is being run. And if we place a # at any point in a line, anything after the hash tag is also ignored. The following code illustrates this.\nComments are really useful for writing explanatory notes to ourselves or others.\n\n# Here is data frame with three variables.\n# The variables refer to the names, ages, and occupations of the participants.\ndf &lt;- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), \n                 age = c(23, 25, 46, 19),\n                 occupation = c('doctor', 'director', 'student', 'spy'))\n\nor\n\n2 + 3 #This is addition in R.\n\n[1] 5\n\n\n\n\nCode sections\nTo make your script even clearer, you can use code sections. These divide up your script into sections as in the example below. To create a code section, go the line in the script editor where you would like to create the new section, then press Cmd+Shift+R (Mac) or Ctrl+Shift+R (Windows). Alternatively, in the Menu, select Code &gt; Insert Section.\nThe lines with the many hypens create the sections\n\n# Create vectors ---------------------------------------------------\n\nscores_test1 &lt;- c(1, 5, 6, 8, 10) # These are the scores on the pre-test.\nscores_test2 &lt;- c(25, 23, 52, 63) # These are the scores on the post-test.\n\n# A few calculations -----------------------------------------------\n\nmean_test1 &lt;- mean(scores_test1)\nmean_test2 &lt;- mean(scores_test2)\n\nround(mean_test1 - mean_test2) # The difference between pre and post-tests.\n\n[1] -35\n\n\nOnce you have created a section, you can ask R to run only the code in a specific region. This is because R recognizes script sections as distinct regions of code.\nTo run the code in a specific section, first go to the section in question (e.g., the section called # A few calculations ————) and then either press Cmd+Option+T (Mac) or Ctrl+Alt+T (Windows). You can also use the menu, Code &gt; Run Region &gt; Run Section. Have a go to see if this works out well.\n\n\nSaving scripts\nFinally, you can also save your script. To do this, just click the Save icon in the Script editor pane or press Cmd+S (Mac) or Ctrl+S (Windows). The script can be named anything, but it is often recommended to use lowercase letters, numbers and underscores only. (That is, no spaces, hyphens, dots, etc.)\nThe script is saved in the .R format in your directory. If you later double click it, the file will open in RStudio by default, but you can also view and edit the file in Word and similar programs."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-2-a-bit-more-on-packages",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-2-a-bit-more-on-packages",
    "title": "2. Data management and data wrangling",
    "section": "Step 2: A bit more on packages",
    "text": "Step 2: A bit more on packages\nIt’s important to acknowledge the important work done by the developers who make R packages available for free and open source. When you use a package for your analyses (e.g., tidyverse or lme4), you should acknowledge their work by citing them in your output (dissertation, presentation, articles, etc.). You can find the reference for each package via the citation() function, as in the examples below.\n\ncitation(\"tidyverse\")\n\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\ncitation(\"lme4\")\n\n\nTo cite lme4 in publications use:\n\n  Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015).\n  Fitting Linear Mixed-Effects Models Using lme4. Journal of\n  Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Fitting Linear Mixed-Effects Models Using {lme4}},\n    author = {Douglas Bates and Martin M{\\\"a}chler and Ben Bolker and Steve Walker},\n    journal = {Journal of Statistical Software},\n    year = {2015},\n    volume = {67},\n    number = {1},\n    pages = {1--48},\n    doi = {10.18637/jss.v067.i01},\n  }\n\n\nYou can also install packages by using the Packages tab in the Files, Plots, Packages, etc. pane. As you see in the figure below, the base package is already installed. You can install more packages by scrolling through the list (or using the search option to narrow down the choices) and then selecting the tick box to the left of the package. If you do this, you will see that the click will run the install.packages() command in the console.\nAs I mentioned above, run install.packages() in the console as a one-off command, you do not need to run this every time you want to use a package. Everytime we want to use a package in a given session, we need to tell R to load it up, which is why we put library() at the top of the script, so we can use the functions."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-3-working-directories-and-clean-workspaces",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-3-working-directories-and-clean-workspaces",
    "title": "2. Data management and data wrangling",
    "section": "Step 3: Working directories and clean workspaces",
    "text": "Step 3: Working directories and clean workspaces\nEvery R session has a working directory. This is essentially the directory or folder from which files are read and to which files are written.\nYou can find out your working directory by typing the following command. Your output will obviously look different from the one below, which refers to my machine\n\ngetwd()\n\n[1] \"/Users/ivorym/Documents/PhD/Teaching/23_24/FASS512/Worksheets/Answers\"\n\n\nYou can also use a command to list the content in the working directory. (Alternatively, you can see your direct by using the Files tab in the Files, Packages, Plot, etc. pane.)\n\nlist.files()\n\n [1] \"carprice.csv\"                    \"example_file.txt\"               \n [3] \"language_exams_new.csv\"          \"language_exams_shorter.csv\"     \n [5] \"language_exams.csv\"              \"nettle_1999_climate.csv\"        \n [7] \"our_plot_300.jpeg\"               \"our_plot_retina.jpeg\"           \n [9] \"our_plot_screen.jpeg\"            \"our_plot.jpeg\"                  \n[11] \"our_plot.pdf\"                    \"our_plot.png\"                   \n[13] \"scores.csv\"                      \"simd.xlsx\"                      \n[15] \"titanic.csv\"                     \"Worksheet_wk1_Answers.qmd\"      \n[17] \"Worksheet_wk2_Answers.qmd\"       \"Worksheet_wk2_Answers.rmarkdown\"\n[19] \"Worksheet_wk3.qmd\"               \"Worksheet_wk4.qmd\"              \n\n\nI suggest you create a new working directory on your computer desktop and then use it for the entire course. Important files related to your R tasks (scripts, data, etc.) should later be downloaded to this folder.\nThe first step is for you to create a folder called FASS512 (or similar) in a sensible place on your computer. You can do this by going to the Files tab (in the Files, Packages, etc. pane) and clicking the “Create a new folder” icon. Place each weekly set of weekly files in their own weekly folders.\nOnce you have created the “statistics” folder on the desktop, go to the menu to set the default working directory to the new “statistics” folder. The easiest way is to go to the menu, RStudio &gt; Preferences. This should call up the following window.\nIn the window, click the Browse button and set the default working directory to the “statistics” folder in the desktop."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-4-loading-data",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-4-loading-data",
    "title": "2. Data management and data wrangling",
    "section": "Step 4: Loading data",
    "text": "Step 4: Loading data\nWhen we are dealing with data in our analyses, we usually begin by importing a data file. R allows you to important data files in many different formats, but the most likely ones are .csv and .xlsx.\nI have uploaded several data files to our Moodle page. Please go to folder called “Data sets to download for this session” in the section for today’s session, then download the files in the folder and place them in your working directory (the statistics folder you just created). The files are from Winter (2019) and Fogarty (2019).\nLet’s try out loading data files. In the examples below, you will import three types of files: .csv, .txt, and .xlsx. Remember: You need to download the data files from our Moodle page and place them in our working directory first. Otherwise, you cannot import the files from our directory into R.\n\nCSV\nWe can use the read_csv() function from dplyr (part of the tidyverse) to load data that is in .csv format. The command below will load the data set (‘nettle_1999_climate.csv’) and create a new label for this data set (languages). There exists a read.csv() function in base, but it is slower and not as ‘smart’ as read_csv().\n\nlanguages &lt;- read.csv('nettle_1999_climate.csv')\n\nAlternatively, you can load data files by clicking File &gt; Import Dataset &gt; From Text (readr). In the dialogue window, then click browse and select the file nettle_1999_climate.csv. You can change the name of the data set in the text box at the bottom left, below Import Options, where it says Name.\n\n\n\n\n\n\nNote\n\n\n\nI am giving you these alternative GUI-based methods for carrying out the same steps as what is written in the script. I offer these to highlight how things can be done in many ways, but preferably you will use the script for pretty much everything. This creates a record of the commands needed to reproduce your analysis, which is better for future researchers (which includes you in a week’s time)\n\n\n\n\nTXT\nThe data file you just imported is in the .csv format. You can important data from files in other formats, too. If the data is in .txt format, you can simply use the following command.\n\ntext_file &lt;- read_table('example_file.txt') #(Note: Ignore the warning message in the console.)\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  Participant = col_character(),\n  Test_1 = col_double(),\n  Test_2 = col_double()\n)\n\n\nThe command creates a new data set called text_file.\n\n\nxlsx\nIf the data is an Excel spreadsheet (e.g., .xlsx format), you can proceed as follows. Ideally it shouldn’t be, as csv are a universal file format that can be read across many machines. As a general rule, it is important to use these universal filetypes (csv, txt, pdf, html…) for better reproducibility and data management (Towse et al., 2021)1\n\nlibrary(readxl) #you may need to run install.packages(\"readxl\") first\n\nspreadsheet_exl &lt;- read_excel('simd.xlsx', sheet = 'simd')\n\nWarning: Expecting numeric in O2646 / R2646C15: got 'NA'\n\n\nWarning: Expecting numeric in E3702 / R3702C5: got 'NA'\n\n\nWarning: Expecting numeric in F3702 / R3702C6: got 'NA'\n\n\nWarning: Expecting numeric in I3702 / R3702C9: got 'NA'\n\n\nWarning: Expecting numeric in J3702 / R3702C10: got 'NA'\n\n\nWarning: Expecting numeric in K3702 / R3702C11: got 'NA'\n\n\nWarning: Expecting numeric in M3702 / R3702C13: got 'NA'\n\n\nWarning: Expecting numeric in N3702 / R3702C14: got 'NA'\n\n\nWarning: Expecting numeric in E3723 / R3723C5: got 'NA'\n\n\nWarning: Expecting numeric in F3723 / R3723C6: got 'NA'\n\n\nWarning: Expecting numeric in I3723 / R3723C9: got 'NA'\n\n\nWarning: Expecting numeric in J3723 / R3723C10: got 'NA'\n\n\nWarning: Expecting numeric in K3723 / R3723C11: got 'NA'\n\n\nWarning: Expecting numeric in M3723 / R3723C13: got 'NA'\n\n\nWarning: Expecting numeric in N3723 / R3723C14: got 'NA'\n\n\nFirst, you need to install the readxl package. Then, you create a new data set called spreadsheet_exl by using the read_excel() function.\nNote: Since spreadsheets have multiple sheets, you need to specify the name of the sheet you would like to import by using the sheet argument. In our case, the sheet is called simd, hence sheet = ‘simd’.\nRStudio can handle many other file extensions to import datasets. You can find out information on how to import other file types by using the R help function (or by searching on Google)."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-5-examining-datasets",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-5-examining-datasets",
    "title": "2. Data management and data wrangling",
    "section": "Step 5: Examining datasets",
    "text": "Step 5: Examining datasets\nIf you have followed the steps above, you will have imported three data sets, languages, spreadsheet_exl, and text_file. You can now start exploring the data. We will focus on languages as an example.\nEvery time you import data, it’s good to check the content, just to make sure you imported the correct file.\nThe easiest way to do this is by using the View() function. This allows you to inspect the data set in the script editor. Note: The function requires a capital V. If you have tidyverse loaded, which we do, then there is a view() function as well. These are functionally equivalent. Use whichever, but View() will always work\nIf you run the command below, you will see that this shows the data (a table) in a tab of the script editor. It will also be displayed in the console.\n\n\n\n\n\n\nNote\n\n\n\nRemember what I have said previously about some content being better off in the console rather than the script? This is another example of what to put in the console instead (like class() or install.packages().\nWhy? Great question, because it’s a one-off command that we don’t need in our script. It’s a sanity check, like class(), and it doesn’t add anything of value to the script. The script should be the minimum series of commands that are required to go from one stage to another. Taking a visual look at a dataframe is superfluous to the actual analysis\n\n\n\nView(spreadsheet_exl) \nView(languages)\n\nYou can also inspect your data by visiting the Environment tab in the Environment, History, Connections, etc. pane. As you can see in the figure below, this will tell you thatlanguageshas 74 observations (rows) and five variables (columns).\nIf you would like to examine variables, you can start by using the str() function (str for structure), as in the example below.\n\nstr(languages)\n\n'data.frame':   74 obs. of  5 variables:\n $ Country   : chr  \"Algeria\" \"Angola\" \"Australia\" \"Bangladesh\" ...\n $ Population: num  4.41 4.01 4.24 5.07 3.69 3.88 3.13 5.19 3.97 3.5 ...\n $ Area      : num  6.38 6.1 6.89 5.16 5.05 6.04 5.76 6.93 5.44 5.79 ...\n $ MGS       : num  6.6 6.22 6 7.4 7.14 6.92 4.6 9.71 5.17 8.08 ...\n $ Langs     : int  18 42 234 37 52 38 27 209 75 94 ...\n\n\nAs you can see above, the str() function will tell you many useful things about your dataset. For example, it will reveal the number of observations (rows, 74) and variables (columns, 5), and then list the variables (Country, Population, Area, MGS, Langs). For each variable, it will also indicate the variable type (chr = character strings, num = numeric, intd = integer). The str() function will also display the first observations of each variable (Algeria, Angola, Australia, Bangladesh, etc.).\nYou can also check the names of variables separately by using the names() function, or check the variable type by checking the class() function, but it’s easier to just use the str() function as in the example above.\nIf you prefer, you can restrict your inspection of to the first or final rows of the data set. You can do this by using the head() and tail() function. This is helpful if your tables has lots of rows. It complements str() as it shows you a sample of the actual data, not just the structure.\n\nhead(languages) #default is six rows to display\n\n     Country Population Area  MGS Langs\n1    Algeria       4.41 6.38 6.60    18\n2     Angola       4.01 6.10 6.22    42\n3  Australia       4.24 6.89 6.00   234\n4 Bangladesh       5.07 5.16 7.40    37\n5      Benin       3.69 5.05 7.14    52\n6    Bolivia       3.88 6.04 6.92    38\n\ntail(languages, n = 5) #show last five rows\n\n    Country Population Area  MGS Langs\n70  Vietnam       4.83 5.52 8.80    88\n71    Yemen       4.09 5.72 0.00     6\n72    Zaire       4.56 6.37 9.44   219\n73   Zambia       3.94 5.88 5.43    38\n74 Zimbabwe       4.00 5.59 5.29    18\n\n\nHow could you show the first 10 rows?\n\n\n        Country Population Area  MGS Langs\n1       Algeria       4.41 6.38 6.60    18\n2        Angola       4.01 6.10 6.22    42\n3     Australia       4.24 6.89 6.00   234\n4    Bangladesh       5.07 5.16 7.40    37\n5         Benin       3.69 5.05 7.14    52\n6       Bolivia       3.88 6.04 6.92    38\n7      Botswana       3.13 5.76 4.60    27\n8        Brazil       5.19 6.93 9.71   209\n9  Burkina Faso       3.97 5.44 5.17    75\n10          CAR       3.50 5.79 8.08    94\n\n\nThere is also a very helpful function called summary(). As you can see in the example below, this function will provide you with summary information for each of your variables.\nFor numeric/integer variables such as Populations, Area, MGS, and Langs, this command will calculate the minimum and maximum values, quartiles, median and mean. (We will discuss summary statistics in more detail later.)\nFor character variables, as in Country, the command will simply provide you with the number of observations (length) for this variable.\n\nsummary(languages)\n\n   Country            Population         Area            MGS        \n Length:74          Min.   :2.010   Min.   :4.090   Min.   : 0.000  \n Class :character   1st Qu.:3.607   1st Qu.:5.223   1st Qu.: 5.348  \n Mode  :character   Median :3.990   Median :5.640   Median : 7.355  \n                    Mean   :3.992   Mean   :5.618   Mean   : 7.029  \n                    3rd Qu.:4.393   3rd Qu.:6.032   3rd Qu.: 9.193  \n                    Max.   :5.930   Max.   :6.930   Max.   :12.000  \n     Langs       \n Min.   :  1.00  \n 1st Qu.: 17.25  \n Median : 40.00  \n Mean   : 89.73  \n 3rd Qu.: 93.75  \n Max.   :862.00  \n\n\nIn large datasets, you might want to examine only a specific variable. You can do this by using the $ as an index. For example, if you would just like to examine the variable Population in the languages dataset, you could proceed as follows.\n\nstr(languages)\n\n'data.frame':   74 obs. of  5 variables:\n $ Country   : chr  \"Algeria\" \"Angola\" \"Australia\" \"Bangladesh\" ...\n $ Population: num  4.41 4.01 4.24 5.07 3.69 3.88 3.13 5.19 3.97 3.5 ...\n $ Area      : num  6.38 6.1 6.89 5.16 5.05 6.04 5.76 6.93 5.44 5.79 ...\n $ MGS       : num  6.6 6.22 6 7.4 7.14 6.92 4.6 9.71 5.17 8.08 ...\n $ Langs     : int  18 42 234 37 52 38 27 209 75 94 ...\n\nstr(languages$Population)\n\n num [1:74] 4.41 4.01 4.24 5.07 3.69 3.88 3.13 5.19 3.97 3.5 ...\n\nclass(languages$Population)\n\n[1] \"numeric\"\n\nhead(languages$Population)\n\n[1] 4.41 4.01 4.24 5.07 3.69 3.88\n\ntail(languages$Population)\n\n[1] 4.31 4.83 4.09 4.56 3.94 4.00\n\nsummary(languages$Population)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.010   3.607   3.990   3.992   4.393   5.930 \n\n\nWhich of the above six commands are best placed in the script or console?\n\n\n\n\n\n\nNote\n\n\n\n\n\nUltimately, there is no right or wrong answer. Personally,\nstr() belongs in the console because it should just be a quick check that it is the expected shape. It could go in the script if it was part of a more formal test. A sanity check is something that makes you go “oh, I should just make sure”, whereas a test is more in line with thoughts of “if it isn’t have an identical shape to dataframe2, none of this works” - a nuanced difference that we may perhaps explore in later sessions.\nclass() goes in the console - it is very much a sanity check. If it transpires the class isn’t what you wanted, we can coerce them into different classes, which we would include as a step in the script, but we don’t need to run the check everytime in the script if we are just going to coerce it anyway…\nhead() and tails() depends. If you’re just having a little look, then console. If it is something you are then using in the analysis, the script. Most likely the console though. If you can exit RStudio and reopen the script and it runs without errors, then it’s fine to leave in the console. If it fails, maybe you need things in the script?\nsummary() is one I usually keep in the script - particularly if I am reporting the summary of statistics (see a later session) because it is meaningful content that I need."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-6-closing-your-r-session",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#step-6-closing-your-r-session",
    "title": "2. Data management and data wrangling",
    "section": "Step 6: Closing your R session",
    "text": "Step 6: Closing your R session\nThe last step is to close your R session. When you quit RStudio, a prompt will ask whether you want to save the content of your workspace. It is better to NOT save the workspace. When you start RStudio again, you will have a clean workspace. You then just re-run your scripts.\nIf you have written your scripts well, upon re-open, you should be able to produce the exact same steps without error and without odd additional windows opening (because we put View() in a script…).\nSo, I would save R scripts (especially if these are very long and are relevant to your analyses), but I would not the workspace contents."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#take-home-task",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#take-home-task",
    "title": "2. Data management and data wrangling",
    "section": "Take home task",
    "text": "Take home task\nTo complete this homework task, you will need to download the language_exams data file from our Moodle page into your working directory.\nIn the file, you will find the (fictional) scores and ages of 475 students who took an intermediate Portuguese language course at university. Students were tested three times: first in September to check their Portuguese proficiency at the beginning of the course, then again in January as part of their mid-term examination, and finally in June as part of their final examination. On each occasion, students had to complete three subtests to respectively assess their Portuguese vocabulary, grammar and pronunciation. The scores for exams 1, 2 and 3 are composite scores, i.e. each combines the results of the three subtests.\nYour task is to run a basic analysis of the exam data using an R script.\nIn your script, please include all the steps, including the command that loaded the data.\nPlease also include sections to make your script very clear, as well as comments.\n\nHow many observations and columns does the datafile contain?\n\n\n\n'data.frame':   474 obs. of  5 variables:\n $ student_id: int  17970 13785 15457 13336 10990 14877 12433 12922 13031 16772 ...\n $ age       : int  18 19 19 25 23 22 25 24 18 24 ...\n $ exam_1    : int  57 92 63 40 25 84 93 90 41 54 ...\n $ exam_2    : int  52 76 60 24 13 76 85 85 23 44 ...\n $ exam_3    : int  59 81 66 30 19 82 94 90 28 52 ...\n\n\n\nRun commands to display the first and the last five lines of the table.\n\n\n\n  student_id age exam_1 exam_2 exam_3\n1      17970  18     57     52     59\n2      13785  19     92     76     81\n3      15457  19     63     60     66\n4      13336  25     40     24     30\n5      10990  23     25     13     19\n\n\n    student_id age exam_1 exam_2 exam_3\n470      12747  23     38     47     40\n471      16685  21     46     65     59\n472      18452  19     57     64     55\n473      15087  25     44     54     50\n474      19762  25     88    102     96\n\n\n\nWhat is the average age of participants? Report this as a whole number\n\n\n\n[1] 21.5865\n\n\n[1] 22\n\n\n\nWhat type of variable is student_id?\n\n\n\n[1] \"integer\"\n\n\n\nWhat is the rounded mean score on exam 3 to 2 decimal places?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNot sure how? Type ?round() into the console and read the help page. Specifically look under the Arguments section and the examples (the second to last is the best one)\n\n\n\n\n\n[1] 61\n\n\n\nWhat is the difference between the mean scores on exams1 and 2?\n\n\n\n[1] 3.253165\n\n\nPlease save the script to discuss at the next session."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk2_Answers.html#footnotes",
    "href": "Worksheets/Answers/Worksheet_wk2_Answers.html#footnotes",
    "title": "2. Data management and data wrangling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTowse, A. S., Ellis, D. A., & Towse, J. (2021). Making data meaningful: Guidelines for good quality open data. The Journal of Social Psychology, 161(4), 395–402. https://doi.org/10.1080/00224545.2021.1938811↩︎"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "",
    "text": "This week, we will do our first steps in R. Please work through the following handout at your own pace.\nThree important things to remember:"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-1-using-the-r-console",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-1-using-the-r-console",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 1: Using the R console",
    "text": "Step 1: Using the R console\nR is a command-based system. This means: You type commands (such as the ones highlighted below), R translates the commands into machine instructions, which your computer then executes.\nYou can type the R commands directly into the console. Or, as you will see later, you can also type commands into the script editor and run the sequence of commands as a batch or collection of lines.\nIn the next section, we will try out writing commands in the Console pane.\nCommands are typed at the command prompt &gt;. We then press Return (Mac) / Enter (Windows), and our command is executed. The output of the command, if there is any output, will be displayed on the next line(s)."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-2-using-r-as-a-calculator",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-2-using-r-as-a-calculator",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 2: Using R as a Calculator",
    "text": "Step 2: Using R as a Calculator\nMost textbooks recommend familiarizing yourself with R and RStudio by first using R as a calculator. Let’s try this out.\nFor example, if you type 10 + 10 in the command prompt and press Return (Mac) / Return (Mac) / Enter (Windows), the result will be displayed underneath:\n\n10 + 10\n\n[1] 20\n\n\nPlease try out the following commands.\nIn the task below, just type the commands in the shaded area, then press Return (Mac) / Enter (Windows).\nNote: You don’t have the leave spaces around the operators (+, -, *, /, etc.), but the lines are more readable if you do.\nSo it’s better if you get used to writing 10 + 10 rather than 10+10, even though the output is the same.\nThe exception are negative values.\nHere, it is recommended not to leave a space between the minus sign - and the value we are negating. So, we would write -3, not - 3, even though it’s the same.\nPlease try out all of the commands on your computer now.\n\nThis is how we do addition\n\n\n10 + 10\n\n[1] 20\n\n\n\nSubtraction\n\n\n8 - 2\n\n[1] 6\n\n\n\nMultiplication\n\n\n10 * 14\n\n[1] 140\n\n\n\nDivision\n\n\n112/8\n\n[1] 14\n\n\n\nWe can also use exponents, i.e. raising a number to the power of another number, e.g., 2^8, as in the example below\n\n\n2 ^ 8\n\n[1] 256\n\n\n\nSquare root. This is done via a function called sqrt(). We will discuss functions later. For now, just add a numerical value in the parentheses of sqrt()\n\n\nsqrt(64)\n\n[1] 8\n\n\n\nYou can also combine +, -, *, /, ^ operators in your commands. By default, the precedence order of operations will be ^ followed by * or /, followed by + or -, just like in a calculator.\n\n\n2+3-4/2\n\n[1] 3\n\n\nor\n\n3+9/3*2^8\n\n[1] 771\n\n\n\nBut: You can use brackets () to overcome the default order to operations: Test the effect of bracketing on the precedence order of operations in the two examples below.\n\n\n#example a\n2 + 3 - 4 / 2\n\n[1] 3\n\n#example b\n(2 + 3 - 4) / 2\n\n[1] 0.5\n\n\nor\n\n#example a\n3 + 9 / 3 * 2 ^ 8\n\n[1] 771\n\n#Example b\n(3 + 9) / 3 * 2 ^ 8\n\n[1] 1024"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-3-history",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-3-history",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 3: History",
    "text": "Step 3: History\nIn the Console pane, have you noticed that pressing the up and down arrows does not allow you to go through the different lines (as would happen in a text file, e.g. Word)? Instead, when you’re at the command prompt &gt;, pressing the up and down arrows allows you to move through the history of executed commands. This can save you a lot of time if you want to re- run one of the previous commands.\nGo ahead and rerun the last line using this method, but change the last number to a 4 (instead of an 8)\nIn the Environment, History, etc. pane, you can use the History tab to see your entire command history. If you click on any line in the History tab, it will re-run the command. Again, very helpful as it saves you a lot of typing. Let’s try this out.\nGo into the History pane and find the line where you ran sqrt(64) and rerun it"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-4-incomplete-commands-and-escaping",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-4-incomplete-commands-and-escaping",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 4: Incomplete commands, and escaping",
    "text": "Step 4: Incomplete commands, and escaping\nWhat happens if you try to execute an incomplete command such as the one below?\n\n\n\n\n10 +\n\nError: &lt;text&gt;:2:0: unexpected end of input\n1: 10 +\n   ^\n\n\nYou will notice there is something missing (another number for the addition). Rather than giving us the result of the addition, R will just display a plus sign + in the console instead of the usual &gt;. This means that the command is incomplete. And: If you keep hitting Return (Mac) / Enter (Windows), you will just get more plus signs…\nYou can either complete the command on the next line (try adding a number to complete the addition), or you can just press Esc to exit the command"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-5-variables",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-5-variables",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 5: Variables",
    "text": "Step 5: Variables\nThe next important step is to learn how to create variables and assign values to variables. In general, the assignment rule is:\nname &lt;- expression/value\nExpression - An expression is any R code that returns some value. This can be a single number, the result of a calculation, or a complex statistical analysis.\nAssignment operator - The &lt;- is called the assignment operator. This assigns everything that is to its right (the expression) to the variable on its left. Rather than typing &lt; and the minus sign, you can also simply press the shortcut Option+- (Mac) or Alt+- (Windows).\nName - The name is simply the name of the variable.\n\nrun the following\n\n\nx &lt;- 4 * 8\n\nIt appears that nothing happened; after all, there seems to be no output in the command prompt. However, something did happen after we executed the command x &lt;- 4 * 8.\nYou will see this when you execute the following command.\n\nx\n\n[1] 32\n\n\nAs you see, the previous command x &lt;- 4 * 8 assigned the multiplication 4 * 8 to the variable x.\nBy typing the name of the variable x in the command line and running it, the value of the variable will be displayed, in this case 32 (being the product of 4 * 8).\nThere is another way to confirm that you created a variable. If you check the Environment tab in the Environment, History, Connections, etc. pane at the top right of your RStudio window, you will now see that new variable listed.\nOnce you have created a variable, you can use it for other calculations just like you would with any other number\n\n\n\n\nx * 36\n\n[1] 1152\n\n\nWe can also assign any of these values to new variables.\n\n\n\n\ny&lt;-x*28\n\ny\n\n[1] 896"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-6.-naming-your-variables",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-6.-naming-your-variables",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 6. Naming your variables",
    "text": "Step 6. Naming your variables\nThe name has to follow certain naming conventions. The variable name can consist of letters (upper or lower case), numbers, dots, and underscores. However, it must begin with a letter, or a dot that is not followed by a number. That is, a dot not followed by a number, OR a letter. If it is a dot and then number it will think of it as a decimal.\n\nWhich of the following would be okay?\n\n\ny157 &lt;- 2\nx_y_z &lt;- 2\nabc_123 &lt;- 2\n_x &lt;- 2\n.1px &lt;- 2\na_b_c &lt;- 2\nx-y-z &lt;- 2\n123 &lt;- 2\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nthese variable names would work:\n\ny157\nx_y_z\nabc_123\na_b_c\n\nthese will not:\n\n_x starts with an underscore\n.1px starts with a number\nx-y-z is trying to subtract z from y from x (it thinks you want to run a function)\n123 is just a number\n\n\n\n\nEven though you can use nonsense sequences such as the ones above, it is good practice to select variable names that are meaningful, short, without dots (use underscore _ instead), and ideally in lowercase characters. For example:\n\nage &lt;- 56\nincome &lt;- 101034\nis_married &lt;- TRUE\nyears_married &lt;- 27"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-7-data-types",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-7-data-types",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 7: Data Types",
    "text": "Step 7: Data Types\nData types are variables that refer to collections of values. There are different types of data types (e.g., lists, matrices, arrays), but we will focus on two particularly important ones: vectors and data frames.\n\nVectors\nVectors are one-dimensional sequences of values. They are very simple but fundamental data structures, as you will see below when we talk about data frames. For this reason, it’s worth learning about vectors, how to create and manipulate them. Below we will cover numeric and character vectors.\nYou can create vectors by using the c() function. The c stands for combine. All the items within brackets, separated by commas, will be assigned to the variable on the left of the assignment operator.\nIf you type the following command, you will create a vector with seven elements. This is called a numeric vector as the elements within the brackets are numbers.\n\n\n\n\nnumbers &lt;- c(2, 3, 5, 7, 11, 13, 17)\n\nWe can now use this vector to perform all kinds of operations. Try out the following, for example.\n\n\n\n\nnumbers + 1\n\n[1]  3  4  6  8 12 14 18\n\nnumbers / 2\n\n[1] 1.0 1.5 2.5 3.5 5.5 6.5 8.5\n\nnumbers^2\n\n[1]   4   9  25  49 121 169 289\n\n\nNote how the operations are applied to each number in the vector.\nFor any vector (number sequence), we can also refer to individual numbers that form the vector. We do this by means of indexing operations []. For example, to get the first element of the vector, we can type the following. This will display the first element in the vector.\n\nnumbers[1]\n\n[1] 2\n\n\nYou can also extract more than one element from the vector, and even specify the order. For example:\nNote the difference in the example above and the one below. Above, we just used [1] and that was fine, but because of how indexing works (and it gets more complex when handling different datatypes, such as 2-dimensional tables), we need to use the c() function to demonstrate what we are after.\n\nnumbers[c(4,2,1)]\n\n[1] 7 3 2\n\n\nThis will retrieve the fourth element in the vector (the number 7), the first element (2) and the second (3).\n\n\n\n\n\n\nWhy is it different?\n\n\n\n\n\nWhat happens if you don’t use the c() function? Try it out and see what happens.\n\nnumbers[4,2,1]\n\nError in numbers[4, 2, 1]: incorrect number of dimensions\n\n\nYou get an error! Now, in this particular situation, the error message isn’t the most helpful, but it is important to get familiar with errors (you will be seeing a lot of them in the next 10 weeks!), and note that they are useful. R cannot carry out operations that don’t make sense, and as it happens, the above command is telling it to look for the item in three dimensions (imagine a cube made of vectors). When we get errors it is useful to check our code to see what might be wrong.\n\n\n\nOr you can refer to consecutive set of elements in the vector, such as the fourth to the seventh elements. For this, simply type:\n\nnumbers[4:7]\n\n[1]  7 11 13 17\n\n\nWe can also retrieve all elements with the exception of one. For this, we use the minus sign to exclude the vector element that we want to exclude, as in the following example.\n\nnumbers [-1]\n\n[1]  3  5  7 11 13 17\n\n\nFinally, we can also exclude a sequence of elements by adding the minus sign before the c() function. This will exclude from the output all elements that are specified within the brackets.\n\nnumbers [-c(1, 3, 5, 7)]\n\n[1]  3  7 13\n\n\nThe numbers vector is a sequence of numbers. We can find out the type of vector by using the function class(). This will confirm that numbers is a numeric vector.\n\nclass(numbers)\n\n[1] \"numeric\"\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nthe class() command is really useful, and one worth remembering for future troubleshooting. Sometimes commands don’t run as you want them to, and checking the class is what you want is a great sanity check. It has saved me on many occasions.\n\n\n\nWe can also create vectors with elements that are character strings. Here, each element needs to be surrounded by quotation marks (single or double), as in the example below\n\ncolleges &lt;- c('bowland', 'cartmel', 'county', 'furness', 'fylde', 'graduate', 'grizedale', 'lonsdale', 'pendle')\n\ncolleges\n\n[1] \"bowland\"   \"cartmel\"   \"county\"    \"furness\"   \"fylde\"     \"graduate\" \n[7] \"grizedale\" \"lonsdale\"  \"pendle\"   \n\n\nThis type of vector is character, how would you verify this?\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nclass(colleges)\n\n[1] \"character\"\n\n\n\n\n\nYou can index character vectors, just like numeric vectors.\n\ncolleges[3]\n\n[1] \"county\"\n\n\nBut you cannot perform arithmetic functions on character vectors, of course.\n\ncolleges*2\n\nError in colleges * 2: non-numeric argument to binary operator\n\n\n\nCoercing vectors\nIn vectors, all of the elements must be of the same type. For example, you cannot have a vector that has both numbers and character strings as elements. If you try to create a vector with both numbers and character strings, then some of your elements will coerced into other types.\nIf you type the following, you will see that the attempt to create a mixed vector with character strings (bowland, cartmel, county, fylde) and numbers (1, 2, 5, 7, 8) converted the numbers into character strings, as evidenced by the quotation marks. You cannot perform calculations on these numbers as R interprets them as text strings.\n\nc('bowland', 'cartmel', 'county', 'furness', 'fylde', 1, 2, 5, 7, 8)\n\n [1] \"bowland\" \"cartmel\" \"county\"  \"furness\" \"fylde\"   \"1\"       \"2\"      \n [8] \"5\"       \"7\"       \"8\"      \n\n\nFinally, you can also combine vectors using thec()function. For example, we can create a new vector called new_numbers by combining the original numbers vectors and adding the squares and cubes of numbers.\n\nnew_numbers &lt;- c(numbers, numbers ^ 2, numbers ^ 3)\n\nnew_numbers\n\n [1]    2    3    5    7   11   13   17    4    9   25   49  121  169  289    8\n[16]   27  125  343 1331 2197 4913\n\n\nWe have now produced a new vector new_numbers with 21 elements. These don’t fit all in a line and so are wrapped over two lines. The first row displays elements 1 to 12, and the second row begins with element 13. Now you can also see the meaning of the [1] on the output. The [1] is just the index of the first element of the vector show on the corresponding line. [1] refers to the first element in our vector (the number 2), and [13] refers to the 13th element in our vector (169).\n\n\nNaming Vectors\nThe elements of a vector can be named, too. Each element in our vector can have a distinct label, which can be useful.\n\nages &lt;- c(bob = 27, bill = 34, charles = 76)\n\nages\n\n    bob    bill charles \n     27      34      76 \n\n\nWe can now access the values of the vector by the label or by the index as before.\n\nages['bill']\n\nbill \n  34 \n\nages[2]\n\nbill \n  34 \n\n\nWe can also add names to existing vectors by using the names() function. In the following example, we first assign new values to the vector ages. This will delete the previous numbers and labels. We then assign names to this vector using the names() function.\n\nages &lt;- c(23, 54, 8)\nnames(ages) &lt;- c(\"michaela\", \"jane\", \"jacques\")\nages\n\nmichaela     jane  jacques \n      23       54        8 \n\n\n\n\nMissing Values\nLast but not least. Sometimes, we have missing values in our data. In R, missing values are denoted by NA. This is not treated as a character string but as a special symbol.\nYou can insert a placeholder for a missing value into a numeric or character vector by simply typing NA in the list of elements.\n\na&lt;-c(1,5,7,NA,11,14)\na\n\n[1]  1  5  7 NA 11 14\n\nb &lt;- c('michaela', 'bill', NA, 'jane')\nb\n\n[1] \"michaela\" \"bill\"     NA         \"jane\"    \n\n\n\n\n\nDataframes\nData frames are probably the most important data structure in R. They are the default form for representing data sets for statistical analyses.\nData frames have a certain number of columns, and each column has the same number of rows. Each column is a vector, and so data frames are essentially collections of equal-length vectors. (This is also why we spent so much time on vectors above…)\nThere are two ways of creating data frames. We can create a data frame in R by importing a data file, usually in .csv or .xlsx format. (We will discuss how to import files next week.)\nOr we can use the data.frame() function to create a data frame from scratch, as in the following example.\n\ndata_df &lt;- data.frame(name = c('bill', 'jane', 'jacques'), age = c(23, 54, 8))\n\ndata_df\n\n     name age\n1    bill  23\n2    jane  54\n3 jacques   8\n\n\nAs you can see, we have now created a data frame with two columns (name, age) and three rows (displaying the name and age of each person, Bill, Jane and Jacques). The columns are our variables and the rows are our observations of these variables.\nWe can refer to specific elements of the data frame by using indices. In the example below, there are two elements within the index [ ], one for the rows, one for the columns. These are separated by a comma [ , ].\nFor example, to refer to the element that is in the second row, first column, you would type the following.\n\ndata_df[2 ,1]\n\n[1] \"jane\"\n\n\nYou can also retrieve multiple elements. One way of doing this is by leaving one of the indices blank.\nIf you leave the first index blank (e.g., [ , 1]), then you are telling R that you want the information from all the rows. In the example below, you retrieve the information that is in all the rows that are in column 1.\n\ndata_df[ ,1]\n\n[1] \"bill\"    \"jane\"    \"jacques\"\n\n\nIn contrast, if you leave the second index blank ([2, ], you will retrieve the information found in the second row across the two columns.\n\ndata_df[2 , ]\n\n  name age\n2 jane  54\n\n\nWe can also be more specific. For example, you can refer to the first and third row of the second column, we would type:\n\ndata_df[c(1, 3), 2]\n\n[1] 23  8\n\n\nOn the other hand, we can also refer to a column by name. To do this, we need to use the $ notation.\n\ndata_df$name\n\n[1] \"bill\"    \"jane\"    \"jacques\"\n\ndata_df$age\n\n[1] 23 54  8\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nDid you notice that RStudio will automatically suggest the variable names after you typed the $? The code completion feature in RStudio makes writing and executing code much easier!\nIt will do this for pretty much everything that is either a function, a variable, or even an argument (we come to those later), provided that you have typed at least three characters (or press Tab to get there faster)"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-8-functions",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-8-functions",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 8: Functions",
    "text": "Step 8: Functions\nWhile data structures hold data in R, functions are used to do things with the data. You have already encountered a few functions above, namely sqrt(), c(), and data.frame().\nAcross all R packages and R’s standard library, there are tens of thousands of functions available for you to use. However, most of our analyses in this course will require only a relatively small number of functions.\nBelow is a general introduction to functions; we will cover functions in more detail as we progress through this course.\nFunctions tend to have the following structure:\nfunction(argument 1, argument 2, argument 3, ...)\nWe can think of functions as actions and arguments as the inputs, i.e. something the functions act on. Most functions require at least one argument. If they have more than one argument, these are separated by commas as in the example above.\nFor example, see what happens when you type the following two commands.\n\nsqrt()\n\nError in sqrt(): 0 arguments passed to 'sqrt' which requires 1\n\nsqrt(4)\n\n[1] 2\n\n\nThe function sqrt() requires an argument; if you fail to supply an argument you will get an error message (Error in sqrt()…)\nHere are another few functions that are helpful for our analyses.\nWe can count the number of elements in a given vector by using the length() function.\n\nlength(new_numbers)\n\n[1] 21\n\n\nWe can calculate sum, mean, median, and standard deviation as follows. (More on this in future sessions when we discuss exploratory data analysis.)\n\nsum(new_numbers)\n\n[1] 9668\n\nmean(new_numbers)\n\n[1] 460.381\n\nmedian(new_numbers)\n\n[1] 25\n\nsd(new_numbers)\n\n[1] 1152.162\n\n\nYou can also nest functions inside each other, such as:\n\nround(sqrt(mean(new_numbers)))\n\n[1] 21\n\n\nHere, we use three functions, each nested within the other. In the example, we first calculated the mean of the vector new_numbers (460.381), then the square root of this value and finally rounded it. We could have done the same calculation in three steps, as in the example below, but nesting the functions in a single command allows us to be more efficient.\nNow, I don’t like nesting functions and neither should you. Next session I will cover this more clearly, and introduce you to a set of functions and stylistic choices that are the gold standard in psychology and have a huge user base (meaning there’s plenty of help out there). For now, just be in awe of the complexity of carrying out multiple functions in R.\n\nOptional arguments\nIn some cases, functions can also take an additional argument. A good example is the mean() function, which can an additional argument called trim. If we add the trim argument to the mean function, the command will first remove a certain proportion of the extreme values of the vector and then calculate the mean. This is very useful when we are dealing with outliers in our data, for example. (We will talk more about outliers in future sessions.)\nIn order to trim observations, we need to specify a value between 0 to 0.5. This will trim the highest and the lowest values before calculating the mean. Naturally, a trim value of 0 means you’re not trimming anything, so the value assigned to trim should be greater than 0. For example, a value of 0.1 means you’re trimming the 10% highest and lowest observations, 0.2 means you’re trimming the 20% highest and lowest, and so forth.\n\nmean(new_numbers)\n\n[1] 460.381\n\nmean(new_numbers, trim=0.0)\n\n[1] 460.381\n\nmean(new_numbers, trim=0.1)\n\n[1] 150.1765\n\nmean(new_numbers, trim=0.2)\n\n[1] 66.92308\n\nmean(new_numbers, trim=0.3)\n\n[1] 44.11111\n\nmean(new_numbers, trim=0.4)\n\n[1] 26.2\n\nmean(new_numbers, trim=0.5)\n\n[1] 25"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-9-help-pages",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#step-9-help-pages",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Step 9: Help Pages",
    "text": "Step 9: Help Pages\nRStudio has very helpful pages for the available functions. This is useful when you’re not sure if a function requires an argument, or if you’re in doubt about the use of arguments such as trim.\nYou can access the help page for a given function in different ways.\nThe most efficient one is by typing a question mark and the function name in the command line. If you now press Return (Mac) / Enter (Windows), this command will also open the help page for the function. Alternatively, you can use thehelp()function in the command line, as below.\n\n?mean()\n\nhelp('mean')\n\nThen there is my preferred option (and again, when we start using the script pane, I will make this clear):\nYou can also go to the search line of the Help tab in the Files, Plots, Packages, Help pane (bottom right of the screen) and type the name of the function there (mean). There is a useful shortcut to search R Help, namely Ctrl+Option+F1 (Mac) and Ctrl+Alt+F1 (Windows).\nIn each of the cases above, RStudio will open the help page for the function in question in the Help tab."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk1_Answers.html#take-home-task",
    "href": "Worksheets/Answers/Worksheet_wk1_Answers.html#take-home-task",
    "title": "1. Introduction to quantitative research methods using R - Answers",
    "section": "Take home task",
    "text": "Take home task\nThe following table displays the scores of students in two foreign language exams, one administered at the beginning of term, the other at the end of term.\nCreate a data frame called language_exams with the information provided in the table, then answer the questions below using R. To save you the headache of tediously typing it all out, you can highlight and paste the code below as-is into your own script.\n\nlanguage_exams &lt;- data.frame(\n  student_id = c('Elin', 'Spencer', 'Crystal', 'Arun', 'Lina', 'Maximilian', 'Leyton', 'Alexandra', 'Valentina', 'Lola', 'Garfield', 'Lucy', 'Shania', 'Arnold', 'Julie', 'Michaela', 'Nicholas'), \n  exam_1 = c(93, 89, 75, 52, 34, 50, 46, 62, 84, 68, 74, 51, 84, 34, 57, 25, 72), \n  exam_2 = c(98, 96, 94, 65, 50, 68, 58, 77, 95, 86, 89, 70, 90, 50, 67, 37, 90))\n\n\nWhat are the mean scores for exam 1 and exam 2?\n\n\nmean(language_exams$exam_1) \n\n[1] 61.76471\n\nmean(language_exams$exam_2)\n\n[1] 75.29412\n\n\n\nWhat is the difference between the two means?\n\n\nmean(language_exams$exam_2) - mean(language_exams$exam_1)\n\n[1] 13.52941\n\n\n\nWhat are the mean scores for the two exams if you remove extreme values (the top and bottom 20%) from each?\n\n\nmean(language_exams$exam_1, trim=0.2) \n\n[1] 62.81818\n\nmean(language_exams$exam_2, trim=0.2)\n\n[1] 77.63636\n\n\n\nBased on the previous step (with outliers removed): What is the difference between the two means now? Please round the value before reporting the result.\n\n\nmean(language_exams$exam_1, trim=0.2) # Calculate mean scores exam 1 without outliers\n\n[1] 62.81818\n\nmean(language_exams$exam_2, trim=0.2) # Calculate mean scores exam 2 without outliers\n\n[1] 77.63636\n\n77.63636 - 62.81818 # Difference between the trimmed mean exam 2 and trimmed mean exam 1\n\n[1] 14.81818\n\nround(14.81818) #Rounds the value\n\n[1] 15\n\n\n\nCan you do steps 3 and 4 in a single command?\n\n\n#the short version\nround(mean(language_exams$exam_2, trim=0.2) - mean(language_exams$exam_1, trim=0.2))\n\n[1] 15"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html",
    "href": "Worksheets/Answers/Worksheet_wk3.html",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "",
    "text": "Three important things to remember:"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html#step-0-preparing-your-environment",
    "href": "Worksheets/Answers/Worksheet_wk3.html#step-0-preparing-your-environment",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "Step 0: Preparing your Environment",
    "text": "Step 0: Preparing your Environment\nFirt things first, open up a new R script and load in the Tidyverse library\n\n\n\n\n\n\nNeed a reminder?\n\n\n\n\n\n\nlibrary(tidyverse)\n\n\n\n\nIn addition, please download the following data files from Moodle (see folder for session 3) and place them in your working directory.\n\nnettle_1999_climate.csv\nlanguage_exams_new.csv\nscores.csv"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html#step-1-tibbles",
    "href": "Worksheets/Answers/Worksheet_wk3.html#step-1-tibbles",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "Step 1: Tibbles?",
    "text": "Step 1: Tibbles?\nIn the last session, you have learned how to install the tidyverse package (Wickham, 2017).\ntidyverse is a collection of packages that great facilitates data handling in R. In our session on data visualization, you will encounter the ggplot2 package (Wickham, 2016), which is part of tidyverse. Today, we will use functions from other important packages of the tidyverse, namely tibble (Müller & Wickham, 2018), readr (Wickham et al., 2022), and dplyr (Wickham et al., 2018). These are all automatically installed when you install the tidyverse.\nWe have actually used tibbles last week. When we use the function read_csv(), this reads dataframes and gives them a class of tibble as well as dataframe. We can interpret this as meaning we can apply functions or operations that can apply to both classes.\nTibbles are like the data frames but better. For example, they load much faster, which is important when you are dealing with lots of data.\nFirst, let us load in a tibble/dataframe called languages. The data set comes from Winter’s (2019) textbook.\n\nlanguages &lt;- read_csv('nettle_1999_climate.csv')\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nclass(languages)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n\nWhat classes are associated with the object languages? Which one means it has been read in as a tibble?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n“tbl” is short for tibble!\n\n\n\nRealistically, in future steps/worksheets/discussions, provided we are all on the same page and using read_csv() not read.csv(), then the terms tibble and dataframe are interchangeable.\nFor completeness sake, and so we can see why working with tibbles is easier, let us read the data again using read.csv(), have a look and compare it against the stored langages object.\nFor this, let us just read the csv without saving it to an object, you may recall that in week 1, we played about getting R to output various things, we told it to print 2 + 2 and it did just that. It gave us the number 4 in the output. And notice that when we ran languages &lt;- read_csv('nettle_1999_climate.csv') above, we did not get any output. This is because R did what we asked, which was to assign the values of the file to the object called “languages”. Got it? Cool, we can get rid of the left hand side of the assignment operator and just have R read (and print) the values of a file to us. In practice, this is not a useful exercise, but as an educational step, it’s convenient.\nLet us run the following command again to have it stored in the environment properly, notice the function is read_csv.\n\nlanguages &lt;- read_csv('nettle_1999_climate.csv')\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAnd now:\n\nlanguages\n\n# A tibble: 74 × 5\n   Country      Population  Area   MGS Langs\n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Algeria            4.41  6.38  6.6     18\n 2 Angola             4.01  6.1   6.22    42\n 3 Australia          4.24  6.89  6      234\n 4 Bangladesh         5.07  5.16  7.4     37\n 5 Benin              3.69  5.05  7.14    52\n 6 Bolivia            3.88  6.04  6.92    38\n 7 Botswana           3.13  5.76  4.6     27\n 8 Brazil             5.19  6.93  9.71   209\n 9 Burkina Faso       3.97  5.44  5.17    75\n10 CAR                3.5   5.79  8.08    94\n# ℹ 64 more rows\n\n\nWhat’s the difference? As you can see above, the tibble has information about the number of observations (74) and variables (5), the names of the variables: Country, Population, Area, MGS (mean growing season, measured by number of months when crops grow), Langs, and the variable types (character: chr, doubles: dbl, which is a type of numeric vector, and integer: int, also a numeric vector). In addition, the command will display the first ten observations of the variables, lines 1 to 10."
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html#step-2-data-wrangling",
    "href": "Worksheets/Answers/Worksheet_wk3.html#step-2-data-wrangling",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "Step 2: Data wrangling",
    "text": "Step 2: Data wrangling\nWe will now use tidyverse functions for data wrangling. As discussed in our last session, data wrangling is also referred to as data pre-processing or data cleaning. It simply means preparing your raw data (e.g., the data files from experimental software) for statistical analyses. This entails, for example, dealing with missing values, relabeling variables, changing the variable types, etc.\nIn this part of the handout, we will look at a few tidyverse function that you can use for data wrangling. For more information, I recommend Chapter 3 of Andrews (2021), which provides a comprehensive introduction to data wrangling using tidyverse.\nLet’s look at five useful functions for data wrangling with tibbles: filter, select, rename, mutate, and arrange.\n\nFilter\nThe filter() function can be used, unsurprisingly, to filter rows in your tibble. The filter() function takes the input tibble as its first argument. The second argument is then a logical statement that you can use to filter the data as you please.\n\n\n\n\n\n\nNote\n\n\n\nWe are using pipes, as introduced last week. So here’s some more practice with them coming up. filter() takes the input as the first argument, which means we can pipe the tibble into the filter function.\n\n\nIn the following example, we are reducing the languages tibble to only those rows with countries that have more than 500 languages.\n\nlanguages |&gt; #pipe object languages\n  filter(Langs &gt; 500) # filter rows where variable (column) Langs is greater than 500\n\n# A tibble: 2 × 5\n  Country          Population  Area   MGS Langs\n  &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Indonesia              5.27  6.28  10.7   701\n2 Papua New Guinea       3.58  5.67  10.9   862\n\n\nOr if you are interested in the data from a specific country (say, Angola), you could simply run the following command. This will only display the rows for Angola.\n\nlanguages |&gt; \n  filter(Country == \"Angola\")\n\n# A tibble: 1 × 5\n  Country Population  Area   MGS Langs\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Angola        4.01   6.1  6.22    42\n\n\nWe can even start to get a little bit more adventurous and filter on more than one argument. What about finding countries with more than 500 languages and Population greater than 4?\n\n\n\n\n\n\nWarning\n\n\n\nWait! Before running the next line, think about what we are trying to find, look at the previous code we have run in this section, and decide what the expected output should be.\nHow many rows should be returned? What countries are they going to be?\nThis kind of mental engagement is critical for your own development - we should also have some kind of mental representation of the information we are getting. It won’t always be super specific, but even just being aware of the shape of a tibble, or general description of the information is important - it means we can check for issues quicker.\n\n\n\nlanguages |&gt; \n  filter(Langs &gt; 500, Population &gt; 4)\n\n# A tibble: 1 × 5\n  Country   Population  Area   MGS Langs\n  &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Indonesia       5.27  6.28  10.7   701\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIndonesia. Look at the output for the code below and notice that it is the same code except we filtered it one step further.\n\nlanguages |&gt; #pipe object languages\n  filter(Langs &gt; 500)\n\n# A tibble: 2 × 5\n  Country          Population  Area   MGS Langs\n  &lt;chr&gt;                 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Indonesia              5.27  6.28  10.7   701\n2 Papua New Guinea       3.58  5.67  10.9   862\n\n\n\n\n\n\n\nSelect\nIn contrast, you can use the select() function to select specific columns. To do this, simply add the columns you wish to select, separated by commas, as arguments in the function.\n\nlanguages |&gt; \n  select(Langs, Country)\n\n# A tibble: 74 × 2\n   Langs Country     \n   &lt;dbl&gt; &lt;chr&gt;       \n 1    18 Algeria     \n 2    42 Angola      \n 3   234 Australia   \n 4    37 Bangladesh  \n 5    52 Benin       \n 6    38 Bolivia     \n 7    27 Botswana    \n 8   209 Brazil      \n 9    75 Burkina Faso\n10    94 CAR         \n# ℹ 64 more rows\n\n\nAs you might notice, the select() function can also be used to change the sequence of the columns. (In the original tibble, Country came first, followed by Langs.)\nOn the other hand, if you wish to exclude a column, you can do this by using a minus sign in front of the column in question. The command below will select the four columns Country, Population, Area and MGS, but excluded Langs as requested.\n\nlanguages |&gt; \n  select(-Langs)\n\n# A tibble: 74 × 4\n   Country      Population  Area   MGS\n   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Algeria            4.41  6.38  6.6 \n 2 Angola             4.01  6.1   6.22\n 3 Australia          4.24  6.89  6   \n 4 Bangladesh         5.07  5.16  7.4 \n 5 Benin              3.69  5.05  7.14\n 6 Bolivia            3.88  6.04  6.92\n 7 Botswana           3.13  5.76  4.6 \n 8 Brazil             5.19  6.93  9.71\n 9 Burkina Faso       3.97  5.44  5.17\n10 CAR                3.5   5.79  8.08\n# ℹ 64 more rows\n\n\nYou can also select consecutive columns using :. Let’s take the columns from and including Population, to and including MGS.\n\nlanguages |&gt; \n  select(Population:MGS)\n\n# A tibble: 74 × 3\n   Population  Area   MGS\n        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1       4.41  6.38  6.6 \n 2       4.01  6.1   6.22\n 3       4.24  6.89  6   \n 4       5.07  5.16  7.4 \n 5       3.69  5.05  7.14\n 6       3.88  6.04  6.92\n 7       3.13  5.76  4.6 \n 8       5.19  6.93  9.71\n 9       3.97  5.44  5.17\n10       3.5   5.79  8.08\n# ℹ 64 more rows\n\n\nIt is worth noting that getting filter() and select() mixed up is pretty common. I personally do it a lot. A vaguely helpful way to remember is that filteR is for Rows and select is not. Or seleCt is for Columns? Or jsut do what I do, and get it wrong 50% of the time, and then just change it when you get the error!\n\n\nRename\nA third useful function is called rename(). This function can be used to change the name of columns. To do this, you first write the new column (here, Population) followed by an equal sign (=) and the old column name (Pop).\nrename() is useful for when we have really messy taking that comes from an online survey, government statistics, or even a PsychoPy study. We could tidy data in excel before reading into R, but that defeats the point of using R and being a successful data scientist (which is you!) - it reduces the reproduciblity and transparency of your analyses from start to finish.\n\nlanguages &lt;- languages |&gt; #here we are manipulating in place the object languages. We are overwriting the existing object\n  rename(Pop = Population)\n\n\n\n\n\n\n\nWarning\n\n\n\nWoah, woah, woah - what did I just do to the object languages? I assigned the object languages to languages? Not quite. I assigned the entire of the right hand side of the assignment operator to overwrite the same object. So I renamed a column and saved it to the existing object. Analogy: like saving over the top of a word document. Or, to see a basic example in action, make sure you have the environment pane selected in the top right and run the next command, see what shows, and then run the second and see what changed. It should be pretty clear what will happen, but just extrapolate that to tibbles and renaming (we could have also reassigned any of the previous actions we took using filter or select).\n\nx &lt;- 32\n\nx &lt;- 64\n\n\n\n\n\nMutate\nThe mutate() function can be used to change the content of a tibble. For example, you can add an additional column, which in the example below will be the Langs column divided by 100.\n\nlanguages &lt;- languages |&gt; \n  mutate(Langs100 = Langs/100)\n\nhead(languages) # show me the top 6 rows\n\n# A tibble: 6 × 6\n  Country      Pop  Area   MGS Langs Langs100\n  &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Algeria     4.41  6.38  6.6     18     0.18\n2 Angola      4.01  6.1   6.22    42     0.42\n3 Australia   4.24  6.89  6      234     2.34\n4 Bangladesh  5.07  5.16  7.4     37     0.37\n5 Benin       3.69  5.05  7.14    52     0.52\n6 Bolivia     3.88  6.04  6.92    38     0.38\n\n\nWe can also use mutate() to change specific values to something else. Look at this example dataset:\n\n#let's create a 2x3 tibble with two participants, who both took part in a study where we tested their working memory, and one was in the control group (1 for yes, 0 for no) and the other was not\ntest_data &lt;- tibble(name = c(\"Jenny\", \"Jonny\"), \n                    score = c(45, 23),\n                    control_group = c(1,0))\n\ntest_data\n\n# A tibble: 2 × 3\n  name  score control_group\n  &lt;chr&gt; &lt;dbl&gt;         &lt;dbl&gt;\n1 Jenny    45             1\n2 Jonny    23             0\n\n\nLooking at the variable control_group it may not be clear to everyone what 1 or 0 means, so let’s use mutate() to update this variable\n\ntest_data_update &lt;- test_data |&gt; \n  mutate(control_group = str_replace(control_group, \"1\",  \"yes\"),\n         control_group = str_replace(control_group, \"0\",  \"no\"))\n\nLooks pretty complicated! Let’s break it down:\n\nThe first line tells us what the new object will be, and what data we are starting with, we are then piping that into:\nmutate() which then tells us we want to update the control_group variable. and we want to apply a new function called str_replace which replaces strings. We are saying “look in the variable control group, and if we find a ‘1’, replace it with the string ‘yes’. We end the second line with a comma telling R we are doing something more\nline three then repeats line two (still inside mutate if you follow the parentheses), and looks for a ‘0’ and replaces it with ‘no’. And we finish there.\n\nCheck out both obhjects, what’s changed?\n\ntest_data\n\n# A tibble: 2 × 3\n  name  score control_group\n  &lt;chr&gt; &lt;dbl&gt;         &lt;dbl&gt;\n1 Jenny    45             1\n2 Jonny    23             0\n\ntest_data_update\n\n# A tibble: 2 × 3\n  name  score control_group\n  &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;        \n1 Jenny    45 yes          \n2 Jonny    23 no           \n\n\nThe arguments in str_replace() want three things: the column it is checking, the strong it is looking for, and the string to replace it with. What if we wanted 1 to equal “control” and 0 to equal “experiment” instead? Try it out.\nWe will explore mutate() more in later weeks, but know that it is a very useful and powerful tool. It will be a common tool in your data science belt. It can be used in conjunction with other functions to do some really cool things. As a quick teaser, what if we wanted to know the population density per area unit?\n\nlanguages &lt;- languages |&gt; \n  mutate(density = Pop/Area) #We divide the total population by the area\n\nIf you took the time to calculate each row, you will see that for every row mutate() has taken the specific value of Pop and divided it by Area. Neat, that will save us a lot of time! Just know that we can make these even more complex…\n\n\nArrange\nFinally, the arrange() function can be used to order a tibble in ascending or descending order. In the example below, we are use this function to first look at the countries with the smallest number of languages (Cuba, Madagascar, etc.), followed by the countries with the largest numbers of languages (Papua New Guinea, Indonesia, Nigeria, etc.).\n\nlanguages |&gt; \n  arrange(Langs)\n\n# A tibble: 74 × 7\n   Country        Pop  Area   MGS Langs Langs100 density\n   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 Cuba          4.03  5.04  7.46     1     0.01   0.800\n 2 Madagascar    4.06  5.77  7.33     4     0.04   0.704\n 3 Yemen         4.09  5.72  0        6     0.06   0.715\n 4 Nicaragua     3.6   5.11  8.13     7     0.07   0.705\n 5 Sri Lanka     4.24  4.82  9.59     7     0.07   0.880\n 6 Mauritania    3.31  6.01  0.75     8     0.08   0.551\n 7 Oman          3.19  5.33  0        8     0.08   0.598\n 8 Saudi Arabia  4.17  6.33  0.4      8     0.08   0.659\n 9 Honduras      3.72  5.05  8.54     9     0.09   0.737\n10 UAE           3.21  4.92  0.83     9     0.09   0.652\n# ℹ 64 more rows\n\n\nor in descending order?\n\nlanguages |&gt; \n  arrange(desc(Langs))\n\n# A tibble: 74 × 7\n   Country            Pop  Area   MGS Langs Langs100 density\n   &lt;chr&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n 1 Papua New Guinea  3.58  5.67 10.9    862     8.62   0.631\n 2 Indonesia         5.27  6.28 10.7    701     7.01   0.839\n 3 Nigeria           5.05  5.97  7      427     4.27   0.846\n 4 India             5.93  6.52  5.32   405     4.05   0.910\n 5 Cameroon          4.09  5.68  9.17   275     2.75   0.720\n 6 Mexico            4.94  6.29  5.84   243     2.43   0.785\n 7 Australia         4.24  6.89  6      234     2.34   0.615\n 8 Zaire             4.56  6.37  9.44   219     2.19   0.716\n 9 Brazil            5.19  6.93  9.71   209     2.09   0.749\n10 Philippines       4.8   5.48 10.3    168     1.68   0.876\n# ℹ 64 more rows\n\n#which is functionally equivalent to:\n#\n#languages |&gt; \n# arrange(-Langs)\n\nBefore we move on, let’s clean up our environment and we are wanting to start with a fresh one for the rest of the worksheet.\nWe can use the function rm() to remove items from the environment pane. We should have two items, x and languages.\n\nrm(x)\nrm(languages)"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html#step-3-exploratory-data-analysis",
    "href": "Worksheets/Answers/Worksheet_wk3.html#step-3-exploratory-data-analysis",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "Step 3: Exploratory Data Analysis",
    "text": "Step 3: Exploratory Data Analysis\nWe are now ready for some exploratory data analysis in R. First, let’s load the three data files as tibbles. To load the data sets as tibbles, we use the read_csv() function\n\n\nRows: 74 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Country\ndbl (4): Population, Area, MGS, Langs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 1000 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (5): student_id, age, exam_1, exam_2, exam_3\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 21 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): scores\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOnce you have loaded the data sets and created the new tibbles, it’s good to inspect the data to make sure all was imported properly. This is important before you do any analyses. Remember: “Garbage in, garbage out.”\nYou can use the View(), head(), and str() functions. Personally I suggest using head() to get a first idea.\nWe are now ready to calculate a few summary statistics! We did some of this in prior worksheets, but we will see some more here.\n\nMean\nTo calculate the arithmetic mean, you can use the mean() function.\n\nmean(test_scores$scores)\n\n[1] 612.2381\n\n\nIn the case of language_exams_new, we have three exams for which we might want to know the mean.\n\nmean(language_exams_new$exam_1)\n\n[1] 68.052\n\nmean(language_exams_new$exam_2)\n\n[1] 75.055\n\nmean(language_exams_new$exam_3)\n\n[1] 87.918\n\n\nBut rather than calculating the mean for each column separately (exam_1 to exam_3), we can use the colMeans() function to calculate the mean for all columns.\n\ncolMeans(language_exams_new)\n\nstudent_id        age     exam_1     exam_2     exam_3 \n 16326.612     24.705     68.052     75.055     87.918 \n\n\nNote that for student_id the output is essentially meaningless; it might be worth to filter out this variable (well, unselect the column. We could do this using two pipes:\n\nlanguage_exams_new |&gt; # take the object language_exams_new\n  select(-student_id) |&gt; # deselect the column student_id\n  colMeans() # apply the function colMeans()\n\n   age exam_1 exam_2 exam_3 \n24.705 68.052 75.055 87.918 \n\n\nIf the above looks really complicated, it isn’t - don’t worry! Let us break it down. Look at the first two lines of code: we take the object language_exams_new and pipe it into the select function and remove the column student_id. We’ve done this before, this isn’t new. We are then seeing another pipe! This means that everything on the LHS of that pipe is shifted into the first spot of the RHS, so we are taken the object minus student_id and applying col_means(). That wasn’t so bad, it’s quite clear when we think about it programmatically.\nConsider that we can take this same approach and keep adding pipes for ever and ever, always doing the same thing: evaluate the first line and the bit between two pipes, then all of the LHS goes through the next pipe into the next function, and then so on, ever building in its pipeline, creating something complex at the end. That’s enough of this for now, we can get more practice later on, but it will help you to structure and read complicated code and make you into the great data scientist that you are.\n\n\nTrimmed Mean\nThe trimmed mean is useful when we want to exclude extreme values. Remember though that any data exclusion needs to be justified and it needs to be described in your report. There is a significant degree of trust that you report everything that you carried out in your analysis transparently.\nCompare the two outputs, with and without the extreme values. The trim argument here deletes the bottom and top 10% of scores.\n\nmean(test_scores$scores)\n\n[1] 612.2381\n\nmean(test_scores$scores, trim = 0.1)\n\n[1] 508.5882\n\n\n\n\nMedian\nThe median is calculated by using the following command.\n\nmedian(test_scores$scores)\n\n[1] 465\n\nmedian (language_exams_new$exam_1)\n\n[1] 68\n\n\n\n\nStandard Deviation\n\nsd(test_scores$scores)\n\n[1] 552.2874\n\nsd(language_exams_new$exam_1)\n\n[1] 2.049755\n\n\n\n\nRange\nThe range can provide useful information about our sample data. For example, let’s calculate the age range of participants in language_exams_new.\nThe range() function does not give you the actual range. It only provides the minimum and maximum values.\n\nrange(language_exams_new$age)\n\n[1] 17 38\n\n\nTo calculate the range, we can ask R to give us the different between the two values reported by range\n\nrange(language_exams_new$age) |&gt; \n  diff()\n\n[1] 21\n\n\ndiff() is a new function, and one we probably won’t use too much more, so it doesn’t deserve much space, diff is short for difference, so it calculates the difference between two values. That’s all really, but look how we take one output that wasn’t useful by itself and applied a new function to get something useful!\n\n\n\n\n\n\nNote\n\n\n\nIf you want to know a (not-so) fun fact, before writing this worksheet, I didn’t even know that diff() existed. I guessed it would (which is based off experience, so not helpful for you to know), but I then checked it did what I thought it did by running ?diff (in the console, NOT script) and it confirmed my suspicions. I could also have just googled “R difference between two values” and read the top two results.\n\n\n\n\nQuantiles\nQuantiles can easily be displayed by means of the quantile() function, as you can see in the example below.\n\nquantile(language_exams_new$exam_1)\n\n  0%  25%  50%  75% 100% \n  62   67   68   69   74 \n\n\nIn our exam_1 data, each of the quantiles above tells us how many scores are below the given the value. For example, 0% of scores are below 62, meaning that 62 is the lowest score. 50% of scores are below 68 and 50% above 68. (The 50% quantile is the median.) And 100% of scores are below 74, meaning that 74 is the highest score in the data set.\nWe can confirm that this is true by using the range() function, which confirms 62 and 74 as minimum and maximum values. Can you remember (or look back) to see how we would do this?\n\n\n[1] 62 74\n\n\nSometimes, we want to calculate a specific one, e.g. a percentile. For this, you can add the following arguments to the quantile() function. For example, to display the 10% and 90% quantiles, you would add 0.1 and 0.9 respectively, as in the examples below.\n\nquantile(language_exams_new$exam_1, 0.1)\n\n10% \n 65 \n\nquantile(language_exams_new$exam_1, 0.9)\n\n90% \n 71 \n\n\n\n\nSummary\nThe summary() function is a fast way to get the key summary statistics.\n\nsummary(language_exams_new)\n\n   student_id         age           exam_1          exam_2          exam_3     \n Min.   :10011   Min.   :17.0   Min.   :62.00   Min.   :70.00   Min.   :81.00  \n 1st Qu.:13028   1st Qu.:20.0   1st Qu.:67.00   1st Qu.:74.00   1st Qu.:87.00  \n Median :15988   Median :23.0   Median :68.00   Median :75.00   Median :88.00  \n Mean   :16327   Mean   :24.7   Mean   :68.05   Mean   :75.06   Mean   :87.92  \n 3rd Qu.:19070   3rd Qu.:28.0   3rd Qu.:69.00   3rd Qu.:76.00   3rd Qu.:89.00  \n Max.   :24996   Max.   :38.0   Max.   :74.00   Max.   :81.00   Max.   :97.00  \n\n\nsummary() is actually quite messy, but it is quick and sometimes that’s all we need, just to get a rough idea of the shape of the data.\n\n\nFrequencies\nSometimes it is helpful to observe the frequencies in our sample data. The freq() function is really helpful for this. Note: This function requires the descr package, which we will need to install and then load. Can you remember where we put these two respective commands? One goes in the console, and one at the top of the script.\n\ninstall.packages(\"descr\")\n\nlibrary(descr)\n\n\nlibrary(descr)\n\nWarning: package 'descr' was built under R version 4.2.3\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\ninstall.packages(\"descr\") #in the console because it is temporary\n\nlibrary(descr) #at the top of the script because we need it to show everyone what tools they need\n\n\n\n\nThe following command will create a frequency table. On the left, you will see the score, in the middle the frequency with which the score occurs, and to the right this is express in percentage points. This tells you, for example, that the most frequent score (the mode) is 68, the least frequent score is 62.\n\nfreq(language_exams_new$exam_1, plot = FALSE)\n\nlanguage_exams_new$exam_1 \n      Frequency Percent\n62            2     0.2\n63           13     1.3\n64           27     2.7\n65           68     6.8\n66          109    10.9\n67          168    16.8\n68          196    19.6\n69          175    17.5\n70          139    13.9\n71           56     5.6\n72           32     3.2\n73           12     1.2\n74            3     0.3\nTotal      1000   100.0\n\n\n\n\nFrequencies with a twist\nIf you omit the argument plot = FALSE in the freq() function (which just default the argument plot = TRUE, check it out in the help pane and searching for the function name), R will produce both a table and a visual display of your data. Compare the table and the histogram (the graph). Which one is more informative? What are the relative advantages of either?\n\nfreq(language_exams_new$exam_1)\n\n\n\n\nlanguage_exams_new$exam_1 \n      Frequency Percent\n62            2     0.2\n63           13     1.3\n64           27     2.7\n65           68     6.8\n66          109    10.9\n67          168    16.8\n68          196    19.6\n69          175    17.5\n70          139    13.9\n71           56     5.6\n72           32     3.2\n73           12     1.2\n74            3     0.3\nTotal      1000   100.0\n\n\nFor now, we can keep the colour grey. Next week we can play with colours properly, but for now - just know you can make some great plots, but for basic exploration, let’s keep them fast and basic because we just need to know the basic shape of the data"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html#step-4-our-first-graphic-explorations",
    "href": "Worksheets/Answers/Worksheet_wk3.html#step-4-our-first-graphic-explorations",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "Step 4: Our first graphic explorations",
    "text": "Step 4: Our first graphic explorations\nTo conclude, let’s try out a few basic graphics. Next week, we will go into much more detail, but here’s a preview of data visualization. The graphics below are available in the R base package. By and large, this will be your only exposure to base plots, because they aren’t as useful or smart as tidy plots, but for fast visualisation, they’re “just ok”. Don’t get too attached to them, next week we get some real exposure to graphics.\n\nBoxplot\nBoxplots are helpful to inspect the data (Tukey, 1977), as discussed in our lecture today. The following command creates a boxplot, based on exam_1 from the data set language_exams_new.\n\nboxplot(language_exams_new$exam_1)\n\n\n\n\nWhat if we want to compare performance on all three exams (exam_1, exam_2, exam_3) next to each other?\nOne way of doing this (there are other ways) is to first create three new objects exam_1, exam_2, exam_3, and then used the boxplot() function on the three.\nHave a go.\n\nexam_1 &lt;- c(language_exams_new$exam_1) \n\nexam_2 &lt;- c(language_exams_new$exam_2) \n\nexam_3 &lt;- c(language_exams_new$exam_3) \n\nboxplot(exam_1, exam_2, exam_3)\n\n\n\n\nCould you run the above using just one line? What is easier to read? What do you prefer?\n\n\nHistograms\nLast but not least, histograms are helpful ways to visually inspect your data. To create a histogram, simply use the hist() function, as in the following examples.\n\nhist(language_exams_new$exam_3)"
  },
  {
    "objectID": "Worksheets/Answers/Worksheet_wk3.html#take-home-task",
    "href": "Worksheets/Answers/Worksheet_wk3.html#take-home-task",
    "title": "3. Exploratory Data Analysis - Answers",
    "section": "Take home task",
    "text": "Take home task\nNone this week. You’ve worked hard and learnt a lot of complicated aspects of R - your task can be relish in your new found knowledge and be impressed with what you can now do in R.\nNext week we take on graphs, plots, and visualisations!"
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html",
    "href": "Worksheets/Worksheet_wk2.html",
    "title": "2. Data management and data wrangling",
    "section": "",
    "text": "Three important things to remember:"
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-0-installing-tidyverse",
    "href": "Worksheets/Worksheet_wk2.html#step-0-installing-tidyverse",
    "title": "2. Data management and data wrangling",
    "section": "Step 0: Installing tidyverse",
    "text": "Step 0: Installing tidyverse\nI mentioned tidyverse in the lecture, and now we will intall and load it, before using it (mainly for pipes!)\nAs a one-off (on a per machine basis) the first command only needs to be run when we first want a package. As noted before, there are thousands of functions available to R, having them all pre-packaged would break your computer and you don’t need every single one.\n\ninstall.packages(\"tidyverse\")\n\nThere is little to know about this at this stage, as the function does a lot of the legwork for us. It looks on the CRAN (The Comprehensive R Archive Network) which contains the R approved packages. It downloads it so you can use all the functions contained in a spacific package.\nAs stated before, tidyverse is a collection of packages, and we will need to understand that later on, but for now: no need.\nNow to load the package so we can use the functions:\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.4     ✔ purrr   1.0.2\n✔ tibble  3.2.1     ✔ dplyr   1.1.2\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nAs above, you will get a bunch of messages in the console, we can reasonably ignore these for now.\n\n\n\n\n\n\nNote\n\n\n\nAs a general point, we would run install.packages() in the console, and place library() at the top of a script. The next section should make this a bit clearer as to the difference"
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-1-scripts",
    "href": "Worksheets/Worksheet_wk2.html#step-1-scripts",
    "title": "2. Data management and data wrangling",
    "section": "Step 1: Scripts",
    "text": "Step 1: Scripts\nA script is essentially a sequence of commands that we want R to execute. As Winter (2019) points out, we can think of our R script as the recipe and the R console as the kitchen that cooks according to this recipe. Let’s try out the script editor and write our first script. Typing commands in the console is good for one off commands (maybe to check the class() or to install.packages()), but the script is better for keeping the steps in order.\nWhen working in R, try to work as much as possible in the script. This will be a summary of all of your analyses, which can then be shared with other researchers, together with your data. This way, others can reproduce your analyses.\nThus far, you have typed your command lines in the console. This was useful to illustrate the functioning of our R, but in most of your analyses you won’t type much in the console. Instead, we will use the script editor.\nThe script editor is the pane on the top left of your window. If you don’t see it, you need to open a new script first. For this, press Cmd+Shift+N (Mac) or Ctrl+Shift+N (Windows). Alternatively, in the menu, click File &gt; New File &gt; RScript.)\nIn the script editor (not the console), type the following command in line 1 press Return (Mac) / Enter (Windows).\n\n2 + 3\n\nAs you can see, nothing happened. There is no output in the Console pane; the cursor just moved to the next line in the script editor (line 2). This is because you did not execute the script.\nTo execute a command in the script editor, you need to place your cursor anywhere on the line you wish to execute and then click the Run icon in the Script editor pane. If you do this, then the following output will appear in your Console.\nYou can also run the current command line or selection in the script by pressing Cmd+Return (Mac) or Ctrl+Enter (Windows). This will also send your command from the script editor to the console. (I suggest using the shortcut, it’s much more efficient.)\nIn the script, you can have as many lines of code as you wish. For example, you can add the following three commands to your script.\n\nscores &lt;- c(145, 234, 653, 876, 456) \n\nmean(scores)\n\nsd(scores)\n\nTo execute each one separately, just go to the line in question and click the Run icon or, even better, press the keyboard shortcut.\nYou can also run multiple commands in one go. For this, you either highlight several lines and then press the Run icon (or keyboard shortcut). Try it with the above three lines.\nTo execute all commands in the script, you click the Source icon (next to the Run icon) in the Script editor pane. Or just use the shortcut Cmd+Option+R (Mac) or Ctrl+Alt+R (Windows).\n\nMultiline commands\nUsing the script editor is particularly useful when we write long and complex commands. The example below illustrates this nicely.\nThis is a fairly long command, written in the console in one line.\n\ndf &lt;- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), age = c(23, 25, 46, 19), occupation = c('doctor', 'director', 'student', 'spy'))\n\nbut in a multiline format:\n\ndf &lt;- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), \n                 age = c(23, 25, 46, 19), \n                 occupation = c('doctor', 'director', 'student', 'spy'))\n\nNote the indentations, this is done automatically by RStudio as it recognises what is grouped according to parentheses.\n\n\nComments\nAn important feature of R (and other programming languages) is the option to write comments in the code files. Comments are notes, written around the code, that are ignored when the script is executed. In R, anything followed by the # symbol on any line is treated as a comment. This means that a line starting with # is ignored when the code is being run. And if we place a # at any point in a line, anything after the hash tag is also ignored. The following code illustrates this.\nComments are really useful for writing explanatory notes to ourselves or others.\n\n# Here is data frame with three variables.\n# The variables refer to the names, ages, and occupations of the participants.\ndf &lt;- data.frame(name = c('jane', 'michaela', 'laurel', 'jaques'), \n                 age = c(23, 25, 46, 19),\n                 occupation = c('doctor', 'director', 'student', 'spy'))\n\nor\n\n2 + 3 #This is addition in R.\n\n\n\nCode sections\nTo make your script even clearer, you can use code sections. These divide up your script into sections as in the example below. To create a code section, go the line in the script editor where you would like to create the new section, then press Cmd+Shift+R (Mac) or Ctrl+Shift+R (Windows). Alternatively, in the Menu, select Code &gt; Insert Section.\nThe lines with the many hypens create the sections\n\n# Create vectors ---------------------------------------------------\n\nscores_test1 &lt;- c(1, 5, 6, 8, 10) # These are the scores on the pre-test.\nscores_test2 &lt;- c(25, 23, 52, 63) # These are the scores on the post-test.\n\n# A few calculations -----------------------------------------------\n\nmean_test1 &lt;- mean(scores_test1)\nmean_test2 &lt;- mean(scores_test2)\n\nround(mean_test1 - mean_test2) # The difference between pre and post-tests.\n\nOnce you have created a section, you can ask R to run only the code in a specific region. This is because R recognizes script sections as distinct regions of code.\nTo run the code in a specific section, first go to the section in question (e.g., the section called # A few calculations ————) and then either press Cmd+Option+T (Mac) or Ctrl+Alt+T (Windows). You can also use the menu, Code &gt; Run Region &gt; Run Section. Have a go to see if this works out well.\n\n\nSaving scripts\nFinally, you can also save your script. To do this, just click the Save icon in the Script editor pane or press Cmd+S (Mac) or Ctrl+S (Windows). The script can be named anything, but it is often recommended to use lowercase letters, numbers and underscores only. (That is, no spaces, hyphens, dots, etc.)\nThe script is saved in the .R format in your directory. If you later double click it, the file will open in RStudio by default, but you can also view and edit the file in Word and similar programs."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-2-a-bit-more-on-packages",
    "href": "Worksheets/Worksheet_wk2.html#step-2-a-bit-more-on-packages",
    "title": "2. Data management and data wrangling",
    "section": "Step 2: A bit more on packages",
    "text": "Step 2: A bit more on packages\nIt’s important to acknowledge the important work done by the developers who make R packages available for free and open source. When you use a package for your analyses (e.g., tidyverse or lme4), you should acknowledge their work by citing them in your output (dissertation, presentation, articles, etc.). You can find the reference for each package via the citation() function, as in the examples below.\n\ncitation(\"tidyverse\")\n\ncitation(\"lme4\")\n\nYou can also install packages by using the Packages tab in the Files, Plots, Packages, etc. pane. As you see in the figure below, the base package is already installed. You can install more packages by scrolling through the list (or using the search option to narrow down the choices) and then selecting the tick box to the left of the package. If you do this, you will see that the click will run the install.packages() command in the console.\nAs I mentioned above, run install.packages() in the console as a one-off command, you do not need to run this every time you want to use a package. Everytime we want to use a package in a given session, we need to tell R to load it up, which is why we put library() at the top of the script, so we can use the functions."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-3-working-directories-and-clean-workspaces",
    "href": "Worksheets/Worksheet_wk2.html#step-3-working-directories-and-clean-workspaces",
    "title": "2. Data management and data wrangling",
    "section": "Step 3: Working directories and clean workspaces",
    "text": "Step 3: Working directories and clean workspaces\nEvery R session has a working directory. This is essentially the directory or folder from which files are read and to which files are written.\nYou can find out your working directory by typing the following command. Your output will obviously look different from the one below, which refers to my machine\n\ngetwd()\n\n[1] \"/Users/ivorym/Documents/PhD/Teaching/23_24/FASS512/Worksheets\"\n\n\nYou can also use a command to list the content in the working directory. (Alternatively, you can see your direct by using the Files tab in the Files, Packages, Plot, etc. pane.)\n\nlist.files()\n\nI suggest you create a new working directory on your computer desktop and then use it for the entire course. Important files related to your R tasks (scripts, data, etc.) should later be downloaded to this folder.\nThe first step is for you to create a folder called FASS512 (or similar) in a sensible place on your computer. You can do this by going to the Files tab (in the Files, Packages, etc. pane) and clicking the “Create a new folder” icon. Place each weekly set of weekly files in their own weekly folders.\nOnce you have created the “statistics” folder on the desktop, go to the menu to set the default working directory to the new “statistics” folder. The easiest way is to go to the menu, RStudio &gt; Preferences. This should call up the following window.\nIn the window, click the Browse button and set the default working directory to the “statistics” folder in the desktop."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-4-loading-data",
    "href": "Worksheets/Worksheet_wk2.html#step-4-loading-data",
    "title": "2. Data management and data wrangling",
    "section": "Step 4: Loading data",
    "text": "Step 4: Loading data\nWhen we are dealing with data in our analyses, we usually begin by importing a data file. R allows you to important data files in many different formats, but the most likely ones are .csv and .xlsx.\nI have uploaded several data files to our Moodle page. Please go to folder called “Data sets to download for this session” in the section for today’s session, then download the files in the folder and place them in your working directory (the statistics folder you just created). The files are from Winter (2019) and Fogarty (2019).\nLet’s try out loading data files. In the examples below, you will import three types of files: .csv, .txt, and .xlsx. Remember: You need to download the data files from our Moodle page and place them in our working directory first. Otherwise, you cannot import the files from our directory into R.\n\nCSV\nWe can use the read_csv() function from dplyr (part of the tidyverse) to load data that is in .csv format. The command below will load the data set (‘nettle_1999_climate.csv’) and create a new label for this data set (languages). There exists a read.csv() function in base, but it is slower and not as ‘smart’ as read_csv().\n\nlanguages &lt;- read.csv('nettle_1999_climate.csv')\n\nAlternatively, you can load data files by clicking File &gt; Import Dataset &gt; From Text (readr). In the dialogue window, then click browse and select the file nettle_1999_climate.csv. You can change the name of the data set in the text box at the bottom left, below Import Options, where it says Name.\n\n\n\n\n\n\nNote\n\n\n\nI am giving you these alternative GUI-based methods for carrying out the same steps as what is written in the script. I offer these to highlight how things can be done in many ways, but preferably you will use the script for pretty much everything. This creates a record of the commands needed to reproduce your analysis, which is better for future researchers (which includes you in a week’s time)\n\n\n\n\nTXT\nThe data file you just imported is in the .csv format. You can important data from files in other formats, too. If the data is in .txt format, you can simply use the following command.\n\ntext_file &lt;- read_table('example_file.txt') #(Note: Ignore warning message in the console.)\n\nThe command creates a new data set called text_file.\n\n\nxlsx\nIf the data is an Excel spreadsheet (e.g., .xlsx format), you can proceed as follows. Ideally it shouldn’t be, as csv are a universal file format that can be read across many machines. As a general rule, it is important to use these universal filetypes (csv, txt, pdf, html…) for better reproducibility and data management (Towse et al., 2021)1\n\nlibrary(readxl) #you may need to run install.packages(\"readxl\") first\n\nspreadsheet_exl &lt;- read_excel('simd.xlsx', sheet = 'simd')\n\nFirst, you need to install the readxl package. Then, you create a new data set called spreadsheet_exl by using the read_excel() function.\nNote: Since spreadsheets have multiple sheets, you need to specify the name of the sheet you would like to import by using the sheet argument. In our case, the sheet is called simd, hence sheet = ‘simd’.\nRStudio can handle many other file extensions to import datasets. You can find out information on how to import other file types by using the R help function (or by searching on Google)."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-5-examining-datasets",
    "href": "Worksheets/Worksheet_wk2.html#step-5-examining-datasets",
    "title": "2. Data management and data wrangling",
    "section": "Step 5: Examining datasets",
    "text": "Step 5: Examining datasets\nIf you have followed the steps above, you will have imported three data sets, languages, spreadsheet_exl, and text_file. You can now start exploring the data. We will focus on languages as an example.\nEvery time you import data, it’s good to check the content, just to make sure you imported the correct file.\nThe easiest way to do this is by using the View() function. This allows you to inspect the data set in the script editor. Note: The function requires a capital V. If you have tidyverse loaded, which we do, then there is a view() function as well. These are functionally equivalent. Use whichever, but View() will always work\nIf you run the command below, you will see that this shows the data (a table) in a tab of the script editor. It will also be displayed in the console.\n\n\n\n\n\n\nNote\n\n\n\nRemember what I have said previously about some content being better off in the console rather than the script? This is another example of what to put in the console instead (like class() or install.packages().\nWhy? Great question, because it’s a one-off command that we don’t need in our script. It’s a sanity check, like class(), and it doesn’t add anything of value to the script. The script should be the minimum series of commands that are required to go from one stage to another. Taking a visual look at a dataframe is superfluous to the actual analysis\n\n\n\nView(spreadsheet_exl) \nView(languages)\n\nYou can also inspect your data by visiting the Environment tab in the Environment, History, Connections, etc. pane. As you can see in the figure below, this will tell you thatlanguageshas 74 observations (rows) and five variables (columns).\nIf you would like to examine variables, you can start by using the str() function (str for structure), as in the example below.\n\nstr(languages)\n\nAs you can see above, the str() function will tell you many useful things about your dataset. For example, it will reveal the number of observations (rows, 74) and variables (columns, 5), and then list the variables (Country, Population, Area, MGS, Langs). For each variable, it will also indicate the variable type (chr = character strings, num = numeric, intd = integer). The str() function will also display the first observations of each variable (Algeria, Angola, Australia, Bangladesh, etc.).\nYou can also check the names of variables separately by using the names() function, or check the variable type by checking the class() function, but it’s easier to just use the str() function as in the example above.\nIf you prefer, you can restrict your inspection of to the first or final rows of the data set. You can do this by using the head() and tail() function. This is helpful if your tables has lots of rows. It complements str() as it shows you a sample of the actual data, not just the structure.\n\nhead(languages) #default is six rows to display\ntail(languages, n = 5) #show last five rows\n\nHow could you show the first 10 rows?\nThere is also a very helpful function called summary(). As you can see in the example below, this function will provide you with summary information for each of your variables.\nFor numeric/integer variables such as Populations, Area, MGS, and Langs, this command will calculate the minimum and maximum values, quartiles, median and mean. (We will discuss summary statistics in more detail later.)\nFor character variables, as in Country, the command will simply provide you with the number of observations (length) for this variable.\n\nsummary(languages)\n\nIn large datasets, you might want to examine only a specific variable. You can do this by using the $ as an index. For example, if you would just like to examine the variable Population in the languages dataset, you could proceed as follows.\n\nstr(languages)\n\nstr(languages$Population)\n\nclass(languages$Population)\n\nhead(languages$Population)\n\ntail(languages$Population)\n\nsummary(languages$Population)\n\nWhich of the above six commands are best placed in the script or console?\n\n\n\n\n\n\nNote\n\n\n\n\n\nUltimately, there is no right or wrong answer. Personally,\nstr() belongs in the console because it should just be a quick check that it is the expected shape. It could go in the script if it was part of a more formal test. A sanity check is something that makes you go “oh, I should just make sure”, whereas a test is more in line with thoughts of “if it isn’t have an identical shape to dataframe2, none of this works” - a nuanced difference that we may perhaps explore in later sessions.\nclass() goes in the console - it is very much a sanity check. If it transpires the class isn’t what you wanted, we can coerce them into different classes, which we would include as a step in the script, but we don’t need to run the check everytime in the script if we are just going to coerce it anyway…\nhead() and tails() depends. If you’re just having a little look, then console. If it is something you are then using in the analysis, the script. Most likely the console though. If you can exit RStudio and reopen the script and it runs without errors, then it’s fine to leave in the console. If it fails, maybe you need things in the script?\nsummary() is one I usually keep in the script - particularly if I am reporting the summary of statistics (see a later session) because it is meaningful content that I need."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#step-6-closing-your-r-session",
    "href": "Worksheets/Worksheet_wk2.html#step-6-closing-your-r-session",
    "title": "2. Data management and data wrangling",
    "section": "Step 6: Closing your R session",
    "text": "Step 6: Closing your R session\nThe last step is to close your R session. When you quit RStudio, a prompt will ask whether you want to save the content of your workspace. It is better to NOT save the workspace. When you start RStudio again, you will have a clean workspace. You then just re-run your scripts.\nIf you have written your scripts well, upon re-open, you should be able to produce the exact same steps without error and without odd additional windows opening (because we put View() in a script…).\nSo, I would save R scripts (especially if these are very long and are relevant to your analyses), but I would not the workspace contents."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#take-home-task",
    "href": "Worksheets/Worksheet_wk2.html#take-home-task",
    "title": "2. Data management and data wrangling",
    "section": "Take home task",
    "text": "Take home task\nTo complete this homework task, you will need to download the language_exams data file from our Moodle page into your working directory.\nIn the file, you will find the (fictional) scores and ages of 475 students who took an intermediate Portuguese language course at university. Students were tested three times: first in September to check their Portuguese proficiency at the beginning of the course, then again in January as part of their mid-term examination, and finally in June as part of their final examination. On each occasion, students had to complete three subtests to respectively assess their Portuguese vocabulary, grammar and pronunciation. The scores for exams 1, 2 and 3 are composite scores, i.e. each combines the results of the three subtests.\nYour task is to run a basic analysis of the exam data using an R script.\nIn your script, please include all the steps, including the command that loaded the data.\nPlease also include sections to make your script very clear, as well as comments.\n\nHow many observations and columns does the datafile contain?\n\n\nRun commands to display the first and the last five lines of the table.\n\n\nWhat is the average age of participants? Report this as a whole number\n\n\nWhat type of variable is student_id?\n\n\nWhat is the rounded mean score on exam 3 to 2 decimal places?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNot sure how? Type ?round() into the console and read the help page. Specifically look under the Arguments section and the examples (the second to last is the best one)\n\n\n\n\nWhat is the difference between the mean scores on exams1 and 2?\n\nPlease save the script to discuss at the next session."
  },
  {
    "objectID": "Worksheets/Worksheet_wk2.html#footnotes",
    "href": "Worksheets/Worksheet_wk2.html#footnotes",
    "title": "2. Data management and data wrangling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTowse, A. S., Ellis, D. A., & Towse, J. (2021). Making data meaningful: Guidelines for good quality open data. The Journal of Social Psychology, 161(4), 395–402. https://doi.org/10.1080/00224545.2021.1938811↩︎"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html",
    "href": "Worksheets/Worksheet_wk1.html",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "",
    "text": "This week, we will do our first steps in R. Please work through the following handout at your own pace.\nThree important things to remember:"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-1-using-the-r-console",
    "href": "Worksheets/Worksheet_wk1.html#step-1-using-the-r-console",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 1: Using the R console",
    "text": "Step 1: Using the R console\nR is a command-based system. This means: You type commands (such as the ones highlighted below), R translates the commands into machine instructions, which your computer then executes.\nYou can type the R commands directly into the console. Or, as you will see later, you can also type commands into the script editor and run the sequence of commands as a batch or collection of lines.\nIn the next section, we will try out writing commands in the Console pane.\nCommands are typed at the command prompt &gt;. We then press Return (Mac) / Enter (Windows), and our command is executed. The output of the command, if there is any output, will be displayed on the next line(s)."
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-2-using-r-as-a-calculator",
    "href": "Worksheets/Worksheet_wk1.html#step-2-using-r-as-a-calculator",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 2: Using R as a Calculator",
    "text": "Step 2: Using R as a Calculator\nMost textbooks recommend familiarizing yourself with R and RStudio by first using R as a calculator. Let’s try this out.\nFor example, if you type 10 + 10 in the command prompt and press Return (Mac) / Return (Mac) / Enter (Windows), the result will be displayed underneath:\n\n10 + 10\n\n[1] 20\n\n\nPlease try out the following commands.\nIn the task below, just type the commands in the shaded area, then press Return (Mac) / Enter (Windows).\nNote: You don’t have the leave spaces around the operators (+, -, *, /, etc.), but the lines are more readable if you do.\nSo it’s better if you get used to writing 10 + 10 rather than 10+10, even though the output is the same.\nThe exception are negative values.\nHere, it is recommended not to leave a space between the minus sign - and the value we are negating. So, we would write -3, not - 3, even though it’s the same.\nPlease try out all of the commands on your computer now.\n\nThis is how we do addition\n\n\n10 + 10\n\n\nSubtraction\n\n\n8 - 2\n\n\nMultiplication\n\n\n10 * 14\n\n\nDivision\n\n\n112/8\n\n\nWe can also use exponents, i.e. raising a number to the power of another number, e.g., 2^8, as in the example below\n\n\n2 ^ 8\n\n\nSquare root. This is done via a function called sqrt(). We will discuss functions later. For now, just add a numerical value in the parentheses of sqrt()\n\n\nsqrt(64)\n\n\nYou can also combine +, -, *, /, ^ operators in your commands. By default, the precedence order of operations will be ^ followed by * or /, followed by + or -, just like in a calculator.\n\n\n2+3-4/2\n\nor\n\n3+9/3*2^8\n\n\nBut: You can use brackets () to overcome the default order to operations: Test the effect of bracketing on the precedence order of operations in the two examples below.\n\n\n#example a\n2 + 3 - 4 / 2\n\n#example b\n(2 + 3 - 4) / 2\n\nor\n\n#example a\n3 + 9 / 3 * 2 ^ 8\n\n#Example b\n(3 + 9) / 3 * 2 ^ 8"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-3-history",
    "href": "Worksheets/Worksheet_wk1.html#step-3-history",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 3: History",
    "text": "Step 3: History\nIn the Console pane, have you noticed that pressing the up and down arrows does not allow you to go through the different lines (as would happen in a text file, e.g. Word)? Instead, when you’re at the command prompt &gt;, pressing the up and down arrows allows you to move through the history of executed commands. This can save you a lot of time if you want to re- run one of the previous commands.\nGo ahead and rerun the last line using this method, but change the last number to a 4 (instead of an 8)\nIn the Environment, History, etc. pane, you can use the History tab to see your entire command history. If you click on any line in the History tab, it will re-run the command. Again, very helpful as it saves you a lot of typing. Let’s try this out.\nGo into the History pane and find the line where you ran sqrt(64) and rerun it"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-4-incomplete-commands-and-escaping",
    "href": "Worksheets/Worksheet_wk1.html#step-4-incomplete-commands-and-escaping",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 4: Incomplete commands, and escaping",
    "text": "Step 4: Incomplete commands, and escaping\nWhat happens if you try to execute an incomplete command such as the one below?\n\n\n\n\n10 +\n\nYou will notice there is something missing (another number for the addition). Rather than giving us the result of the addition, R will just display a plus sign + in the console instead of the usual &gt;. This means that the command is incomplete. And: If you keep hitting Return (Mac) / Enter (Windows), you will just get more plus signs…\nYou can either complete the command on the next line (try adding a number to complete the addition), or you can just press Esc to exit the command"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-5-variables",
    "href": "Worksheets/Worksheet_wk1.html#step-5-variables",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 5: Variables",
    "text": "Step 5: Variables\nThe next important step is to learn how to create variables and assign values to variables. In general, the assignment rule is:\nname &lt;- expression/value\nExpression - An expression is any R code that returns some value. This can be a single number, the result of a calculation, or a complex statistical analysis.\nAssignment operator - The &lt;- is called the assignment operator. This assigns everything that is to its right (the expression) to the variable on its left. Rather than typing &lt; and the minus sign, you can also simply press the shortcut Option+- (Mac) or Alt+- (Windows).\nName - The name is simply the name of the variable.\n\nrun the following\n\n\nx &lt;- 4 * 8\n\nIt appears that nothing happened; after all, there seems to be no output in the command prompt. However, something did happen after we executed the command x &lt;- 4 * 8.\nYou will see this when you execute the following command.\n\nx\n\nAs you see, the previous command x &lt;- 4 * 8 assigned the multiplication 4 * 8 to the variable x.\nBy typing the name of the variable x in the command line and running it, the value of the variable will be displayed, in this case 32 (being the product of 4 * 8).\nThere is another way to confirm that you created a variable. If you check the Environment tab in the Environment, History, Connections, etc. pane at the top right of your RStudio window, you will now see that new variable listed.\nOnce you have created a variable, you can use it for other calculations just like you would with any other number\n\n\n\n\nx * 36\n\nWe can also assign any of these values to new variables.\n\n\n\n\ny&lt;-x*28\n\ny"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-6.-naming-your-variables",
    "href": "Worksheets/Worksheet_wk1.html#step-6.-naming-your-variables",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 6. Naming your variables",
    "text": "Step 6. Naming your variables\nThe name has to follow certain naming conventions. The variable name can consist of letters (upper or lower case), numbers, dots, and underscores. However, it must begin with a letter, or a dot that is not followed by a number. That is, a dot not followed by a number, OR a letter. If it is a dot and then number it will think of it as a decimal.\n\nWhich of the following would be okay?\n\n\ny157 &lt;- 2\nx_y_z &lt;- 2\nabc_123 &lt;- 2\n_x &lt;- 2\n.1px &lt;- 2\na_b_c &lt;- 2\nx-y-z &lt;- 2\n123 &lt;- 2\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nthese variable names would work:\n\ny157\nx_y_z\nabc_123\na_b_c\n\nthese will not:\n\n_x starts with an underscore\n.1px starts with a number\nx-y-z is trying to subtract z from y from x (it thinks you want to run a function)\n123 is just a number\n\n\n\n\nEven though you can use nonsense sequences such as the ones above, it is good practice to select variable names that are meaningful, short, without dots (use underscore _ instead), and ideally in lowercase characters. For example:\n\nage &lt;- 56\nincome &lt;- 101034\nis_married &lt;- TRUE\nyears_married &lt;- 27"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-7-data-types",
    "href": "Worksheets/Worksheet_wk1.html#step-7-data-types",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 7: Data Types",
    "text": "Step 7: Data Types\nData types are variables that refer to collections of values. There are different types of data types (e.g., lists, matrices, arrays), but we will focus on two particularly important ones: vectors and data frames.\n\nVectors\nVectors are one-dimensional sequences of values. They are very simple but fundamental data structures, as you will see below when we talk about data frames. For this reason, it’s worth learning about vectors, how to create and manipulate them. Below we will cover numeric and character vectors.\nYou can create vectors by using the c() function. The c stands for combine. All the items within brackets, separated by commas, will be assigned to the variable on the left of the assignment operator.\nIf you type the following command, you will create a vector with seven elements. This is called a numeric vector as the elements within the brackets are numbers.\n\n\n\n\nnumbers &lt;- c(2, 3, 5, 7, 11, 13, 17)\n\nWe can now use this vector to perform all kinds of operations. Try out the following, for example.\n\n\n\n\nnumbers + 1\n\nnumbers / 2\n\nnumbers^2\n\nNote how the operations are applied to each number in the vector.\nFor any vector (number sequence), we can also refer to individual numbers that form the vector. We do this by means of indexing operations []. For example, to get the first element of the vector, we can type the following. This will display the first element in the vector.\n\nnumbers[1]\n\nYou can also extract more than one element from the vector, and even specify the order. For example:\nNote the difference in the example above and the one below. Above, we just used [1] and that was fine, but because of how indexing works (and it gets more complex when handling different datatypes, such as 2-dimensional tables), we need to use the c() function to demonstrate what we are after.\n\nnumbers[c(4,2,1)]\n\nThis will retrieve the fourth element in the vector (the number 7), the first element (2) and the second (3).\n\n\n\n\n\n\nWhy is it different?\n\n\n\n\n\nWhat happens if you don’t use the c() function? Try it out and see what happens.\n\nnumbers[4,2,1]\n\nError in numbers[4, 2, 1]: incorrect number of dimensions\n\n\nYou get an error! Now, in this particular situation, the error message isn’t the most helpful, but it is important to get familiar with errors (you will be seeing a lot of them in the next 10 weeks!), and note that they are useful. R cannot carry out operations that don’t make sense, and as it happens, the above command is telling it to look for the item in three dimensions (imagine a cube made of vectors). When we get errors it is useful to check our code to see what might be wrong.\n\n\n\nOr you can refer to consecutive set of elements in the vector, such as the fourth to the seventh elements. For this, simply type:\n\nnumbers[4:7]\n\nWe can also retrieve all elements with the exception of one. For this, we use the minus sign to exclude the vector element that we want to exclude, as in the following example.\n\nnumbers [-1]\n\nFinally, we can also exclude a sequence of elements by adding the minus sign before the c() function. This will exclude from the output all elements that are specified within the brackets.\n\nnumbers [-c(1, 3, 5, 7)]\n\nThe numbers vector is a sequence of numbers. We can find out the type of vector by using the function class(). This will confirm that numbers is a numeric vector.\n\nclass(numbers)\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nthe class() command is really useful, and one worth remembering for future troubleshooting. Sometimes commands don’t run as you want them to, and checking the class is what you want is a great sanity check. It has saved me on many occasions.\n\n\n\nWe can also create vectors with elements that are character strings. Here, each element needs to be surrounded by quotation marks (single or double), as in the example below\n\ncolleges &lt;- c('bowland', 'cartmel', 'county', 'furness', 'fylde', 'graduate', 'grizedale', 'lonsdale', 'pendle')\n\ncolleges\n\nThis type of vector is character, how would you verify this?\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nclass(colleges)\n\n\n\n\nYou can index character vectors, just like numeric vectors.\n\ncolleges[3]\n\nBut you cannot perform arithmetic functions on character vectors, of course.\n\ncolleges*2\n\n\nCoercing vectors\nIn vectors, all of the elements must be of the same type. For example, you cannot have a vector that has both numbers and character strings as elements. If you try to create a vector with both numbers and character strings, then some of your elements will coerced into other types.\nIf you type the following, you will see that the attempt to create a mixed vector with character strings (bowland, cartmel, county, fylde) and numbers (1, 2, 5, 7, 8) converted the numbers into character strings, as evidenced by the quotation marks. You cannot perform calculations on these numbers as R interprets them as text strings.\n\nc('bowland', 'cartmel', 'county', 'furness', 'fylde', 1, 2, 5, 7, 8)\n\nFinally, you can also combine vectors using thec()function. For example, we can create a new vector called new_numbers by combining the original numbers vectors and adding the squares and cubes of numbers.\n\nnew_numbers &lt;- c(numbers, numbers ^ 2, numbers ^ 3)\n\nnew_numbers\n\nWe have now produced a new vector new_numbers with 21 elements. These don’t fit all in a line and so are wrapped over two lines. The first row displays elements 1 to 12, and the second row begins with element 13. Now you can also see the meaning of the [1] on the output. The [1] is just the index of the first element of the vector show on the corresponding line. [1] refers to the first element in our vector (the number 2), and [13] refers to the 13th element in our vector (169).\n\n\nNaming Vectors\nThe elements of a vector can be named, too. Each element in our vector can have a distinct label, which can be useful.\n\nages &lt;- c(bob = 27, bill = 34, charles = 76)\n\nages\n\nWe can now access the values of the vector by the label or by the index as before.\n\nages['bill']\n\nages[2]\n\nWe can also add names to existing vectors by using the names() function. In the following example, we first assign new values to the vector ages. This will delete the previous numbers and labels. We then assign names to this vector using the names() function.\n\nages &lt;- c(23, 54, 8)\nnames(ages) &lt;- c(\"michaela\", \"jane\", \"jacques\")\nages\n\n\n\nMissing Values\nLast but not least. Sometimes, we have missing values in our data. In R, missing values are denoted by NA. This is not treated as a character string but as a special symbol.\nYou can insert a placeholder for a missing value into a numeric or character vector by simply typing NA in the list of elements.\n\na&lt;-c(1,5,7,NA,11,14)\na\n\n\nb &lt;- c('michaela', 'bill', NA, 'jane')\nb\n\n\n\n\nDataframes\nData frames are probably the most important data structure in R. They are the default form for representing data sets for statistical analyses.\nData frames have a certain number of columns, and each column has the same number of rows. Each column is a vector, and so data frames are essentially collections of equal-length vectors. (This is also why we spent so much time on vectors above…)\nThere are two ways of creating data frames. We can create a data frame in R by importing a data file, usually in .csv or .xlsx format. (We will discuss how to import files next week.)\nOr we can use the data.frame() function to create a data frame from scratch, as in the following example.\n\ndata_df &lt;- data.frame(name = c('bill', 'jane', 'jacques'), age = c(23, 54, 8))\n\ndata_df\n\nAs you can see, we have now created a data frame with two columns (name, age) and three rows (displaying the name and age of each person, Bill, Jane and Jacques). The columns are our variables and the rows are our observations of these variables.\nWe can refer to specific elements of the data frame by using indices. In the example below, there are two elements within the index [ ], one for the rows, one for the columns. These are separated by a comma [ , ].\nFor example, to refer to the element that is in the second row, first column, you would type the following.\n\ndata_df[2 ,1]\n\nYou can also retrieve multiple elements. One way of doing this is by leaving one of the indices blank.\nIf you leave the first index blank (e.g., [ , 1]), then you are telling R that you want the information from all the rows. In the example below, you retrieve the information that is in all the rows that are in column 1.\n\ndata_df[ ,1]\n\nIn contrast, if you leave the second index blank ([2, ], you will retrieve the information found in the second row across the two columns.\n\ndata_df[2 , ]\n\nWe can also be more specific. For example, you can refer to the first and third row of the second column, we would type:\n\ndata_df[c(1, 3), 2]\n\nOn the other hand, we can also refer to a column by name. To do this, we need to use the $ notation.\n\ndata_df$name\n\ndata_df$age\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nDid you notice that RStudio will automatically suggest the variable names after you typed the $? The code completion feature in RStudio makes writing and executing code much easier!\nIt will do this for pretty much everything that is either a function, a variable, or even an argument (we come to those later), provided that you have typed at least three characters (or press Tab to get there faster)"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-8-functions",
    "href": "Worksheets/Worksheet_wk1.html#step-8-functions",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 8: Functions",
    "text": "Step 8: Functions\nWhile data structures hold data in R, functions are used to do things with the data. You have already encountered a few functions above, namely sqrt(), c(), and data.frame().\nAcross all R packages and R’s standard library, there are tens of thousands of functions available for you to use. However, most of our analyses in this course will require only a relatively small number of functions.\nBelow is a general introduction to functions; we will cover functions in more detail as we progress through this course.\nFunctions tend to have the following structure:\nfunction(argument 1, argument 2, argument 3, ...)\nWe can think of functions as actions and arguments as the inputs, i.e. something the functions act on. Most functions require at least one argument. If they have more than one argument, these are separated by commas as in the example above.\nFor example, see what happens when you type the following two commands.\n\nsqrt()\nsqrt(4)\n\nThe function sqrt() requires an argument; if you fail to supply an argument you will get an error message (Error in sqrt()…)\nHere are another few functions that are helpful for our analyses.\nWe can count the number of elements in a given vector by using the length() function.\n\nlength(new_numbers)\n\nWe can calculate sum, mean, median, and standard deviation as follows. (More on this in future sessions when we discuss exploratory data analysis.)\n\nsum(new_numbers)\n\nmean(new_numbers)\n\nmedian(new_numbers)\n\nsd(new_numbers)\n\nYou can also nest functions inside each other, such as:\n\nround(sqrt(mean(new_numbers)))\n\nHere, we use three functions, each nested within the other. In the example, we first calculated the mean of the vector new_numbers (460.381), then the square root of this value and finally rounded it. We could have done the same calculation in three steps, as in the example below, but nesting the functions in a single command allows us to be more efficient.\nNow, I don’t like nesting functions and neither should you. Next session I will cover this more clearly, and introduce you to a set of functions and stylistic choices that are the gold standard in psychology and have a huge user base (meaning there’s plenty of help out there). For now, just be in awe of the complexity of carrying out multiple functions in R.\n\nOptional arguments\nIn some cases, functions can also take an additional argument. A good example is the mean() function, which can an additional argument called trim. If we add the trim argument to the mean function, the command will first remove a certain proportion of the extreme values of the vector and then calculate the mean. This is very useful when we are dealing with outliers in our data, for example. (We will talk more about outliers in future sessions.)\nIn order to trim observations, we need to specify a value between 0 to 0.5. This will trim the highest and the lowest values before calculating the mean. Naturally, a trim value of 0 means you’re not trimming anything, so the value assigned to trim should be greater than 0. For example, a value of 0.1 means you’re trimming the 10% highest and lowest observations, 0.2 means you’re trimming the 20% highest and lowest, and so forth.\n\nmean(new_numbers)\n\nmean(new_numbers, trim=0.0)\n\nmean(new_numbers, trim=0.1)\n\nmean(new_numbers, trim=0.2)\n\nmean(new_numbers, trim=0.3)\n\nmean(new_numbers, trim=0.4)\n\nmean(new_numbers, trim=0.5)"
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#step-9-help-pages",
    "href": "Worksheets/Worksheet_wk1.html#step-9-help-pages",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Step 9: Help Pages",
    "text": "Step 9: Help Pages\nRStudio has very helpful pages for the available functions. This is useful when you’re not sure if a function requires an argument, or if you’re in doubt about the use of arguments such as trim.\nYou can access the help page for a given function in different ways.\nThe most efficient one is by typing a question mark and the function name in the command line. If you now press Return (Mac) / Enter (Windows), this command will also open the help page for the function. Alternatively, you can use thehelp()function in the command line, as below.\n\n?mean()\n\nhelp('mean')\n\nThen there is my preferred option (and again, when we start using the script pane, I will make this clear):\nYou can also go to the search line of the Help tab in the Files, Plots, Packages, Help pane (bottom right of the screen) and type the name of the function there (mean). There is a useful shortcut to search R Help, namely Ctrl+Option+F1 (Mac) and Ctrl+Alt+F1 (Windows).\nIn each of the cases above, RStudio will open the help page for the function in question in the Help tab."
  },
  {
    "objectID": "Worksheets/Worksheet_wk1.html#take-home-task",
    "href": "Worksheets/Worksheet_wk1.html#take-home-task",
    "title": "1. Introduction to quantitative research methods using R",
    "section": "Take home task",
    "text": "Take home task\nThe following table displays the scores of students in two foreign language exams, one administered at the beginning of term, the other at the end of term.\nCreate a data frame called language_exams with the information provided in the table, then answer the questions below using R. To save you the headache of tediously typing it all out, you can highlight and paste the code below as-is into your own script.\n\nlanguage_exams &lt;- data.frame(\n  student_id = c('Elin', 'Spencer', 'Crystal', 'Arun', 'Lina', 'Maximilian', 'Leyton', 'Alexandra', 'Valentina', 'Lola', 'Garfield', 'Lucy', 'Shania', 'Arnold', 'Julie', 'Michaela', 'Nicholas'), \n  exam_1 = c(93, 89, 75, 52, 34, 50, 46, 62, 84, 68, 74, 51, 84, 34, 57, 25, 72), \n  exam_2 = c(98, 96, 94, 65, 50, 68, 58, 77, 95, 86, 89, 70, 90, 50, 67, 37, 90))\n\n\nWhat are the mean scores for exam 1 and exam 2?\n\n\nWhat is the difference between the two means?\n\n\nWhat are the mean scores for the two exams if you remove extreme values (the top and bottom 20%) from each?\n\n\nBased on the previous step (with outliers removed): What is the difference between the two means now? Please round the value before reporting the result.\n\n\nCan you do steps 3 and 4 in a single command?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome\nWelcome to FASS512, Quantitative Research Methods for 2023/2024. In the sidebar you will see each week’s worksheets. This is a one-stop shop for all your worksheets, and each week the previous content will have answers incorporated into the content for easier revision.\nSee Moodle for course slides and recordings.\n\n\nHelpful links:\n\nInstalling R and RStudio\nThe Tidyverse Style guide\nHow to search for help on the internet\nAnything you think should be here? Let me know!\n\nContent written by Matthew Ivory, built on Patrick Rebuschat’s previous content; website developed and maintained by Matthew Ivory.\n\n\n\n\n Back to top"
  }
]